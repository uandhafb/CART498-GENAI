{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Coded with @ChatGPT ---\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "def remove_last_word_per_line(poem: str) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Treat each line as a phrase.\n",
        "    Removes the last word of each non-empty line.\n",
        "    Returns (new_poem, removed_words).\n",
        "\n",
        "    Notes:\n",
        "    - If line ends with punctuation, we remove the last word but keep trailing punctuation.\n",
        "      Example: \"hello, world!\" -> \"hello, !\" (you can change this behavior below)\n",
        "    - Lines with 0 or 1 word become \"\" (or just punctuation if it existed).\n",
        "    \"\"\"\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    # Pattern: capture everything up to last \"word\", then that last word, then trailing non-word chars\n",
        "    # \"word\" here = letters/digits/underscore; works well for most poems.\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)   # keep blank line as-is\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            # If nothing matches (e.g., line is only punctuation), keep as-is\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        # Remove possible extra spaces before trailing punctuation nicely\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "\n",
        "# --- Paste the poem here ---\n",
        "poem = \"\"\"Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá;\n",
        "As aves, que aqui gorjeiam,\n",
        "Não gorjeiam como lá.\n",
        "\n",
        "Nosso céu tem mais estrelas,\n",
        "Nossas várzeas têm mais flores,\n",
        "Nossos bosques têm mais vida,\n",
        "Nossa vida mais amores.\n",
        "\n",
        "Em  cismar, sozinho, à noite,\n",
        "Mais prazer eu encontro lá;\n",
        "Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá.\n",
        "\n",
        "Minha terra tem primores,\n",
        "Que tais não encontro eu cá;\n",
        "Em cismar –sozinho, à noite–\n",
        "Mais prazer eu encontro lá;\n",
        "Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá.\n",
        "\n",
        "Não permita Deus que eu morra,\n",
        "Sem que eu volte para lá;\n",
        "Sem que disfrute os primores\n",
        "Que não encontro por cá;\n",
        "Sem qu'inda aviste as palmeiras,\n",
        "Onde canta o Sabiá. \"\"\"\n",
        "\n",
        "new_poem, removed_words = remove_last_word_per_line(poem)\n",
        "\n",
        "print(\"=== Original ===\")\n",
        "print(poem)\n",
        "print(\"\\n=== Without last word per line ===\")\n",
        "print(new_poem)\n",
        "print(\"\\n=== Removed last words ===\")\n",
        "print(removed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aacsl2leO090",
        "outputId": "1c965505-8805-4fdd-da33-2984d06f1b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Original ===\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá;\n",
            "As aves, que aqui gorjeiam,\n",
            "Não gorjeiam como lá.\n",
            "\n",
            "Nosso céu tem mais estrelas,\n",
            "Nossas várzeas têm mais flores,\n",
            "Nossos bosques têm mais vida,\n",
            "Nossa vida mais amores.\n",
            "\n",
            "Em  cismar, sozinho, à noite,\n",
            "Mais prazer eu encontro lá;\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá.\n",
            "\n",
            "Minha terra tem primores,\n",
            "Que tais não encontro eu cá;\n",
            "Em cismar –sozinho, à noite–\n",
            "Mais prazer eu encontro lá;\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá.\n",
            "\n",
            "Não permita Deus que eu morra,\n",
            "Sem que eu volte para lá;\n",
            "Sem que disfrute os primores\n",
            "Que não encontro por cá;\n",
            "Sem qu'inda aviste as palmeiras,\n",
            "Onde canta o Sabiá. \n",
            "\n",
            "=== Without last word per line ===\n",
            "Minha terra tem ,\n",
            "Onde canta o ;\n",
            "As aves, que aqui ,\n",
            "Não gorjeiam como .\n",
            "\n",
            "Nosso céu tem mais ,\n",
            "Nossas várzeas têm mais ,\n",
            "Nossos bosques têm mais ,\n",
            "Nossa vida mais .\n",
            "\n",
            "Em  cismar, sozinho, à ,\n",
            "Mais prazer eu encontro ;\n",
            "Minha terra tem ,\n",
            "Onde canta o .\n",
            "\n",
            "Minha terra tem ,\n",
            "Que tais não encontro eu ;\n",
            "Em cismar –sozinho, à –\n",
            "Mais prazer eu encontro ;\n",
            "Minha terra tem ,\n",
            "Onde canta o .\n",
            "\n",
            "Não permita Deus que eu ,\n",
            "Sem que eu volte para ;\n",
            "Sem que disfrute os\n",
            "Que não encontro por ;\n",
            "Sem qu'inda aviste as ,\n",
            "Onde canta o .\n",
            "\n",
            "=== Removed last words ===\n",
            "['palmeiras', 'Sabiá', 'gorjeiam', 'lá', '', 'estrelas', 'flores', 'vida', 'amores', '', 'noite', 'lá', 'palmeiras', 'Sabiá', '', 'primores', 'cá', 'noite', 'lá', 'palmeiras', 'Sabiá', '', 'morra', 'lá', 'primores', 'cá', 'palmeiras', 'Sabiá']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# This script: CODE 1\n",
        "\n",
        "# 1. Takes a poem\n",
        "\n",
        "# 2. Treats each line as a phrase\n",
        "\n",
        "# 3. Removes the last word of each line, but keep the punctution\n",
        "\n",
        "# 4. Asks GPT-2:“Given this incomplete line, what is the most likely next word?”\n",
        "\n",
        "# 5. Prints the top 7 most probable next words per line, according to GPT-2\n",
        "\n",
        "#This is a \"probabilistic poetry\".\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "#re: regular expressions (used to manipulate text)\n",
        "\n",
        "#AutoTokenizer: converts text → tokens (numbers)\n",
        "\n",
        "#AutoModelForCausalLM: GPT-2 model that predicts the next token\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste the poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove the last word of each line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "\n",
        "        # keep trailing punctuation (if any) but remove the last word\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (for reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# --- 3) Load GPT-2 (\"openai-community/gpt2\") ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- 4) Get the 7 highest-probability \"next-word\" candidates per line ---\n",
        "# Note: GPT-2 predicts next *token*, so it filters for \"word-like\" tokens and return 7 of them.\n",
        "word_like = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "def top7_next_words(prompt: str, k: int = 7):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "        logits = out.logits[0, -1, :]  # next-token logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    candidates = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])  # decoded token string (often begins with a space)\n",
        "        candidate = piece.strip()\n",
        "\n",
        "        # filter for word-like candidates\n",
        "        if word_like.match(candidate):\n",
        "            candidates.append((candidate, float(probs[tid].cpu())))\n",
        "            if len(candidates) == k:\n",
        "                break\n",
        "\n",
        "    return candidates\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 next-word predictions per line ===\")\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"\\nLine {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    preds = top7_next_words(line, k=7)\n",
        "    print(f\"\\nLine {i} prompt: {line!r}\")\n",
        "    for rank, (w, p) in enumerate(preds, start=1):\n",
        "        print(f\"  {rank}. {w}   (p≈{p:.6f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HF03skkVHUb",
        "outputId": "4c08dec1-d678-4256-cab4-cc7c4c368cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (for reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 next-word predictions per line ===\n",
            "\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. their   (p≈0.327742)\n",
            "  2. its   (p≈0.134323)\n",
            "  3. his   (p≈0.130412)\n",
            "  4. your   (p≈0.024782)\n",
            "  5. a   (p≈0.020237)\n",
            "  6. our   (p≈0.016856)\n",
            "  7. her   (p≈0.016227)\n",
            "\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold   (p≈0.019574)\n",
            "  2. snow   (p≈0.015065)\n",
            "  3. frost   (p≈0.011847)\n",
            "  4. ice   (p≈0.011417)\n",
            "  5. fire   (p≈0.009118)\n",
            "  6. wind   (p≈0.007472)\n",
            "  7. death   (p≈0.006405)\n",
            "\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. the   (p≈0.115517)\n",
            "  2. and   (p≈0.036429)\n",
            "  3. the   (p≈0.015668)\n",
            "  4. a   (p≈0.015343)\n",
            "  5. but   (p≈0.011335)\n",
            "  6. he   (p≈0.008077)\n",
            "  7. it   (p≈0.007911)\n",
            "\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time   (p≈0.923336)\n",
            "  2. while   (p≈0.044233)\n",
            "  3. enough   (p≈0.002422)\n",
            "  4. long   (p≈0.002420)\n",
            "  5. day   (p≈0.001997)\n",
            "  6. way   (p≈0.001524)\n",
            "  7. few   (p≈0.000694)\n",
            "\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. and   (p≈0.084944)\n",
            "  2. the   (p≈0.055765)\n",
            "  3. they   (p≈0.026530)\n",
            "  4. a   (p≈0.022741)\n",
            "  5. which   (p≈0.014570)\n",
            "  6. as   (p≈0.013563)\n",
            "  7. I   (p≈0.012816)\n",
            "\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills   (p≈0.063551)\n",
            "  2. past   (p≈0.058286)\n",
            "  3. mountains   (p≈0.029670)\n",
            "  4. sky   (p≈0.024388)\n",
            "  5. future   (p≈0.019752)\n",
            "  6. horizon   (p≈0.019710)\n",
            "  7. night   (p≈0.014906)\n",
            "\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. be   (p≈0.163062)\n",
            "  2. mention   (p≈0.082309)\n",
            "  3. the   (p≈0.048059)\n",
            "  4. say   (p≈0.046895)\n",
            "  5. forget   (p≈0.024347)\n",
            "  6. speak   (p≈0.021671)\n",
            "  7. have   (p≈0.012935)\n",
            "\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. the   (p≈0.055677)\n",
            "  2. and   (p≈0.030254)\n",
            "  3. you   (p≈0.024980)\n",
            "  4. it   (p≈0.022849)\n",
            "  5. I   (p≈0.022692)\n",
            "  6. or   (p≈0.020128)\n",
            "  7. which   (p≈0.015042)\n",
            "\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. the   (p≈0.098786)\n",
            "  2. you   (p≈0.064024)\n",
            "  3. I   (p≈0.061768)\n",
            "  4. it   (p≈0.042075)\n",
            "  5. a   (p≈0.029483)\n",
            "  6. there   (p≈0.024765)\n",
            "  7. we   (p≈0.019941)\n",
            "\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind   (p≈0.011728)\n",
            "  2. car   (p≈0.010731)\n",
            "  3. door   (p≈0.009443)\n",
            "  4. engine   (p≈0.008490)\n",
            "  5. water   (p≈0.008186)\n",
            "  6. sound   (p≈0.007511)\n",
            "  7. voice   (p≈0.007308)\n",
            "\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind   (p≈0.017899)\n",
            "  2. name   (p≈0.015471)\n",
            "  3. thing   (p≈0.014833)\n",
            "  4. type   (p≈0.014472)\n",
            "  5. day   (p≈0.011899)\n",
            "  6. material   (p≈0.009552)\n",
            "  7. story   (p≈0.009409)\n",
            "\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot   (p≈0.033189)\n",
            "  2. feet   (p≈0.028551)\n",
            "  3. chest   (p≈0.028061)\n",
            "  4. hands   (p≈0.027312)\n",
            "  5. air   (p≈0.021669)\n",
            "  6. shoulders   (p≈0.019035)\n",
            "  7. footed   (p≈0.018051)\n",
            "\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. the   (p≈0.107719)\n",
            "  2. you   (p≈0.094248)\n",
            "  3. it   (p≈0.061220)\n",
            "  4. listen   (p≈0.033752)\n",
            "  5. then   (p≈0.031616)\n",
            "  6. and   (p≈0.024582)\n",
            "  7. this   (p≈0.020407)\n",
            "\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. but   (p≈0.144305)\n",
            "  2. nothing   (p≈0.068906)\n",
            "  3. except   (p≈0.050083)\n",
            "  4. no   (p≈0.032543)\n",
            "  5. and   (p≈0.031650)\n",
            "  6. he   (p≈0.027037)\n",
            "  7. I   (p≈0.023098)\n",
            "\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. It   (p≈0.007830)\n",
            "  2. I   (p≈0.006189)\n",
            "  3. The   (p≈0.004710)\n",
            "  4. That   (p≈0.004307)\n",
            "  5. You   (p≈0.003553)\n",
            "  6. This   (p≈0.003549)\n",
            "  7. And   (p≈0.003511)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose and print P7.txt\n",
        "#This is a \"probabilistic poetry\".\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Build prompts AND keep structured parts per line:\n",
        "#    before (everything before last word),\n",
        "#    last_word (removed),\n",
        "#    trailing (punctuation after last word)\n",
        "# -----------------------------------------------------\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []  # list of dicts: {original, before, last_word, trailing}\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "# Prompt must be EXACTLY \"before + trailing\" (this matches your original logic/output)\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(\"\\n\".join(prompts_lines))\n",
        "print(\"\\n=== Removed last words (for reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Load GPT-2\n",
        "# -----------------------------------------------------\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Top-7 predictions (word-like tokens)\n",
        "# -----------------------------------------------------\n",
        "word_like = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "def top7_next_words(prompt: str, k: int = 7):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "        logits = out.logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    candidates = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        candidate = tokenizer.decode([tid]).strip()\n",
        "        if word_like.match(candidate):\n",
        "            candidates.append((candidate, float(probs[tid].cpu())))\n",
        "            if len(candidates) == k:\n",
        "                break\n",
        "    return candidates\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild CORRECTLY:\n",
        "#    [before] + chosen_word + [trailing]\n",
        "#    (word goes BEFORE punctuation)\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Interactive: print top-7, choose 1-7, rebuild poem, save txt\n",
        "# -----------------------------------------------------\n",
        "new_lines = []\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 next-word predictions per line (and choose 1-7) ===\")\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"\\nLine {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    preds = top7_next_words(prompt_line, k=7)\n",
        "\n",
        "    print(f\"\\nLine {i} prompt: {prompt_line!r}\")\n",
        "    for rank, (w, p) in enumerate(preds, start=1):\n",
        "        print(f\"  {rank}. {w}   (p≈{p:.6f})\")\n",
        "\n",
        "    while True:\n",
        "        raw = input(\"Choose an option (1-7): \").strip()\n",
        "        if raw.isdigit():\n",
        "            n = int(raw)\n",
        "            if 1 <= n <= 7:\n",
        "                chosen_word = preds[n - 1][0]\n",
        "                break\n",
        "        print(\"Invalid choice. Type a number from 1 to 7.\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"P7_poem_probabilistic.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDKNn8o6EsN",
        "outputId": "70f301b6-13d9-4eb2-81e0-d1747a44a120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (for reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 next-word predictions per line (and choose 1-7) ===\n",
            "\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. their   (p≈0.327742)\n",
            "  2. its   (p≈0.134323)\n",
            "  3. his   (p≈0.130412)\n",
            "  4. your   (p≈0.024782)\n",
            "  5. a   (p≈0.020237)\n",
            "  6. our   (p≈0.016856)\n",
            "  7. her   (p≈0.016227)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold   (p≈0.019574)\n",
            "  2. snow   (p≈0.015065)\n",
            "  3. frost   (p≈0.011847)\n",
            "  4. ice   (p≈0.011417)\n",
            "  5. fire   (p≈0.009118)\n",
            "  6. wind   (p≈0.007472)\n",
            "  7. death   (p≈0.006405)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. the   (p≈0.115517)\n",
            "  2. and   (p≈0.036429)\n",
            "  3. the   (p≈0.015668)\n",
            "  4. a   (p≈0.015343)\n",
            "  5. but   (p≈0.011335)\n",
            "  6. he   (p≈0.008077)\n",
            "  7. it   (p≈0.007911)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time   (p≈0.923336)\n",
            "  2. while   (p≈0.044233)\n",
            "  3. enough   (p≈0.002422)\n",
            "  4. long   (p≈0.002420)\n",
            "  5. day   (p≈0.001997)\n",
            "  6. way   (p≈0.001524)\n",
            "  7. few   (p≈0.000694)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. and   (p≈0.084944)\n",
            "  2. the   (p≈0.055765)\n",
            "  3. they   (p≈0.026530)\n",
            "  4. a   (p≈0.022741)\n",
            "  5. which   (p≈0.014570)\n",
            "  6. as   (p≈0.013563)\n",
            "  7. I   (p≈0.012816)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills   (p≈0.063551)\n",
            "  2. past   (p≈0.058286)\n",
            "  3. mountains   (p≈0.029670)\n",
            "  4. sky   (p≈0.024388)\n",
            "  5. future   (p≈0.019752)\n",
            "  6. horizon   (p≈0.019710)\n",
            "  7. night   (p≈0.014906)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. be   (p≈0.163062)\n",
            "  2. mention   (p≈0.082309)\n",
            "  3. the   (p≈0.048059)\n",
            "  4. say   (p≈0.046895)\n",
            "  5. forget   (p≈0.024347)\n",
            "  6. speak   (p≈0.021671)\n",
            "  7. have   (p≈0.012935)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. the   (p≈0.055677)\n",
            "  2. and   (p≈0.030254)\n",
            "  3. you   (p≈0.024980)\n",
            "  4. it   (p≈0.022849)\n",
            "  5. I   (p≈0.022692)\n",
            "  6. or   (p≈0.020128)\n",
            "  7. which   (p≈0.015042)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. the   (p≈0.098786)\n",
            "  2. you   (p≈0.064024)\n",
            "  3. I   (p≈0.061768)\n",
            "  4. it   (p≈0.042075)\n",
            "  5. a   (p≈0.029483)\n",
            "  6. there   (p≈0.024765)\n",
            "  7. we   (p≈0.019941)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind   (p≈0.011728)\n",
            "  2. car   (p≈0.010731)\n",
            "  3. door   (p≈0.009443)\n",
            "  4. engine   (p≈0.008490)\n",
            "  5. water   (p≈0.008186)\n",
            "  6. sound   (p≈0.007511)\n",
            "  7. voice   (p≈0.007308)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind   (p≈0.017899)\n",
            "  2. name   (p≈0.015471)\n",
            "  3. thing   (p≈0.014833)\n",
            "  4. type   (p≈0.014472)\n",
            "  5. day   (p≈0.011899)\n",
            "  6. material   (p≈0.009552)\n",
            "  7. story   (p≈0.009409)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot   (p≈0.033189)\n",
            "  2. feet   (p≈0.028551)\n",
            "  3. chest   (p≈0.028061)\n",
            "  4. hands   (p≈0.027312)\n",
            "  5. air   (p≈0.021669)\n",
            "  6. shoulders   (p≈0.019035)\n",
            "  7. footed   (p≈0.018051)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. the   (p≈0.107719)\n",
            "  2. you   (p≈0.094248)\n",
            "  3. it   (p≈0.061220)\n",
            "  4. listen   (p≈0.033752)\n",
            "  5. then   (p≈0.031616)\n",
            "  6. and   (p≈0.024582)\n",
            "  7. this   (p≈0.020407)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. but   (p≈0.144305)\n",
            "  2. nothing   (p≈0.068906)\n",
            "  3. except   (p≈0.050083)\n",
            "  4. no   (p≈0.032543)\n",
            "  5. and   (p≈0.031650)\n",
            "  6. he   (p≈0.027037)\n",
            "  7. I   (p≈0.023098)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. It   (p≈0.007830)\n",
            "  2. I   (p≈0.006189)\n",
            "  3. The   (p≈0.004710)\n",
            "  4. That   (p≈0.004307)\n",
            "  5. You   (p≈0.003553)\n",
            "  6. This   (p≈0.003549)\n",
            "  7. And   (p≈0.003511)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "=== NEW POEM ===\n",
            "One must have a mind of her\n",
            "To regard the frost and the death\n",
            "Of the pine-trees crusted with it;\n",
            "And have been cold a long few\n",
            "To behold the junipers shagged with I,\n",
            "The spruces rough in the distant night\n",
            "Of the January sun; and not to have\n",
            "Of any misery in the sound of the which,\n",
            "In the sound of a few we,\n",
            "Which is the sound of the voice\n",
            "Full of the same story\n",
            "That is blowing in the same bare footed\n",
            "For the listener, who listens in the this,\n",
            "And, nothing himself, I\n",
            "Nothing that is not there and the nothing that And.\n",
            "\n",
            "Saved to: P7_poem_probabilistic.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# VERSION 1 — For each line: show TOP-7 next-word candidates in ENGLISH + TOP-7 in PORTUGUESE\n",
        "# (same GPT-2 model; we just filter the ranked next-token list into 2 language buckets)\n",
        "#NOTE: discovered that GPT-2 model does not work in Portuguese\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove the last word of each line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "\n",
        "        # keep trailing punctuation (if any) but remove the last word\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "\n",
        "# --- 3) Load GPT-2 ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# --- 4) Language-ish filters (heuristics) ---\n",
        "# \"word-like\": letters (incl. accents) + optional internal - or '\n",
        "WORDLIKE = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "# English-ish: only basic Latin letters (no accents)\n",
        "ENGLISHISH = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# Portuguese-ish: either has a Portuguese diacritic or contains common PT letter combos\n",
        "# (still a heuristic; GPT-2 is not a Portuguese-specialized model)\n",
        "PT_DIACRITIC = re.compile(r\"[áàâãéêíóôõúçÁÀÂÃÉÊÍÓÔÕÚÇ]\")\n",
        "PT_COMBOS = re.compile(r\"(nh|lh|ção|ções|mente|ões|ões|que|pra|não|uma|uma|para|com|dos|das|ção)$\", re.IGNORECASE)\n",
        "\n",
        "def is_portugueseish(word: str) -> bool:\n",
        "    return bool(WORDLIKE.match(word) and (PT_DIACRITIC.search(word) or PT_COMBOS.search(word)))\n",
        "\n",
        "def is_englishish(word: str) -> bool:\n",
        "    return bool(ENGLISHISH.match(word))\n",
        "\n",
        "# --- 5) Get ranked next-token list once, then filter into EN/PT buckets ---\n",
        "def get_ranked_next_tokens(prompt: str, top_n: int = 500):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:top_n]\n",
        "\n",
        "    ranked = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])\n",
        "        candidate = piece.strip()\n",
        "        if candidate and WORDLIKE.match(candidate):\n",
        "            ranked.append((candidate, float(probs[tid].cpu())))\n",
        "    return ranked\n",
        "\n",
        "def pick_top_k_by_lang(ranked, k=7):\n",
        "    en = []\n",
        "    pt = []\n",
        "    for w, p in ranked:\n",
        "        if len(en) < k and is_englishish(w):\n",
        "            en.append((w, p))\n",
        "        if len(pt) < k and is_portugueseish(w):\n",
        "            pt.append((w, p))\n",
        "        if len(en) >= k and len(pt) >= k:\n",
        "            break\n",
        "    return en, pt\n",
        "\n",
        "# --- Run ---\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    ranked = get_ranked_next_tokens(line, top_n=1500)  # increase if PT bucket is too sparse\n",
        "    top_en, top_pt = pick_top_k_by_lang(ranked, k=7)\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "\n",
        "    print(\"\\nTop-7 (English-ish) next words:\")\n",
        "    if top_en:\n",
        "        for r, (w, p) in enumerate(top_en, start=1):\n",
        "            print(f\"  {r}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (none found — try increasing top_n)\")\n",
        "\n",
        "    print(\"\\nTop-7 (Portuguese-ish) next words:\")\n",
        "    if top_pt:\n",
        "        for r, (w, p) in enumerate(top_pt, start=1):\n",
        "            print(f\"  {r}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (none found — try increasing top_n)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vRbTJoaDdv",
        "outputId": "cc34aba0-391c-4afa-ccb0-e50be1fd0d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. their              p≈0.327749\n",
            "  2. its                p≈0.134322\n",
            "  3. his                p≈0.130409\n",
            "  4. your               p≈0.024783\n",
            "  5. a                  p≈0.020238\n",
            "  6. our                p≈0.016856\n",
            "  7. her                p≈0.016227\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. uncom              p≈0.000121\n",
            "  2. pra                p≈0.000046\n",
            "  3. locom              p≈0.000032\n",
            "  4. Com                p≈0.000031\n",
            "  5. unique             p≈0.000024\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007471\n",
            "  7. death              p≈0.006405\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.115519\n",
            "  2. and                p≈0.036429\n",
            "  3. the                p≈0.015668\n",
            "  4. a                  p≈0.015343\n",
            "  5. but                p≈0.011335\n",
            "  6. he                 p≈0.008078\n",
            "  7. it                 p≈0.007911\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000496\n",
            "  2. com                p≈0.000330\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. time               p≈0.923361\n",
            "  2. while              p≈0.044236\n",
            "  3. enough             p≈0.002422\n",
            "  4. long               p≈0.002420\n",
            "  5. day                p≈0.001997\n",
            "  6. way                p≈0.001524\n",
            "  7. few                p≈0.000694\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. que                p≈0.000001\n",
            "  2. com                p≈0.000001\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. and                p≈0.084944\n",
            "  2. the                p≈0.055764\n",
            "  3. they               p≈0.026530\n",
            "  4. a                  p≈0.022741\n",
            "  5. which              p≈0.014570\n",
            "  6. as                 p≈0.013563\n",
            "  7. I                  p≈0.012816\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000110\n",
            "  2. com                p≈0.000093\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058288\n",
            "  3. mountains          p≈0.029669\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014907\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. pra                p≈0.000168\n",
            "  2. com                p≈0.000078\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. be                 p≈0.163060\n",
            "  2. mention            p≈0.082306\n",
            "  3. the                p≈0.048059\n",
            "  4. say                p≈0.046896\n",
            "  5. forget             p≈0.024347\n",
            "  6. speak              p≈0.021670\n",
            "  7. have               p≈0.012935\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000172\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.055678\n",
            "  2. and                p≈0.030254\n",
            "  3. you                p≈0.024981\n",
            "  4. it                 p≈0.022850\n",
            "  5. I                  p≈0.022692\n",
            "  6. or                 p≈0.020128\n",
            "  7. which              p≈0.015042\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000079\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.098783\n",
            "  2. you                p≈0.064026\n",
            "  3. I                  p≈0.061768\n",
            "  4. it                 p≈0.042074\n",
            "  5. a                  p≈0.029483\n",
            "  6. there              p≈0.024766\n",
            "  7. we                 p≈0.019942\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000068\n",
            "  2. Pokémon            p≈0.000066\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. locom              p≈0.000224\n",
            "  2. sque               p≈0.000129\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. technique          p≈0.000413\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028549\n",
            "  3. chest              p≈0.028062\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019036\n",
            "  7. footed             p≈0.018051\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.107716\n",
            "  2. you                p≈0.094248\n",
            "  3. it                 p≈0.061221\n",
            "  4. listen             p≈0.033752\n",
            "  5. then               p≈0.031615\n",
            "  6. and                p≈0.024581\n",
            "  7. this               p≈0.020407\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000036\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. but                p≈0.144313\n",
            "  2. nothing            p≈0.068909\n",
            "  3. except             p≈0.050082\n",
            "  4. no                 p≈0.032543\n",
            "  5. and                p≈0.031649\n",
            "  6. he                 p≈0.027037\n",
            "  7. I                  p≈0.023098\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. It                 p≈0.007830\n",
            "  2. I                  p≈0.006189\n",
            "  3. The                p≈0.004710\n",
            "  4. That               p≈0.004307\n",
            "  5. You                p≈0.003553\n",
            "  6. This               p≈0.003549\n",
            "  7. And                p≈0.003511\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.001090\n",
            "  2. Com                p≈0.000080\n",
            "  3. COM                p≈0.000056\n",
            "  4. com                p≈0.000040\n",
            "  5. Com                p≈0.000015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# This script: CODE 2\n",
        "# TOP-7 \"SEMANTIC\" next-word candidates per line (GPT-2)\n",
        "# Variant 1: filter out function words (articles, pronouns, conjunctions, etc.)\n",
        "# NOTE: GPT-2 doesn't provide POS (Part-of-Speech tags) tags,\n",
        "#so we use a strong stopword (remove very common function words as I, you, of, in, on,and, or, but, etc)\n",
        "#+ heuristic filter (Keep only tokens that look like real words removing very short tokensnumbers or symbols) .\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove last word per line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# --- 3) Load GPT-2 ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# --- 4) Filters: word-like + \"content word\" heuristic ---\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")  # keep simple English word forms\n",
        "\n",
        "# A compact but strong English stopword set to remove function words.\n",
        "# (Includes: articles, pronouns, conjunctions, auxiliaries, prepositions, etc.)\n",
        "STOPWORDS = {\n",
        "    # articles / determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # common prepositions\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\"before\",\"after\",\n",
        "    \"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    # auxiliaries / modals / copulas (often non-content)\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\n",
        "    \"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    # misc function-ish\n",
        "    \"not\",\"no\",\"yes\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\n",
        "    \"as\",\"up\",\"down\",\"out\",\"off\",\"again\",\"more\",\"most\",\"less\",\"least\"\n",
        "}\n",
        "\n",
        "# Additional heuristic: reject very short tokens & common suffix-only tokens that slip in\n",
        "def is_content_word(w: str) -> bool:\n",
        "    w_low = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(w_low) < 3:\n",
        "        return False\n",
        "    if w_low in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def top_k_content_words(prompt: str, k: int = 7, oversample: int = 5000):\n",
        "    \"\"\"\n",
        "    GPT-2 predicts next TOKEN. We'll rank all tokens by probability, then filter\n",
        "    to \"content words\" and return the first k.\n",
        "    oversample: how many top tokens to scan to find enough content words.\n",
        "    \"\"\"\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]  # next-token logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:oversample]\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for tid in sorted_ids.tolist():\n",
        "        cand = tokenizer.decode([tid]).strip()\n",
        "        if not cand:\n",
        "            continue\n",
        "\n",
        "        # keep unique lowercase words (avoid repeats with casing)\n",
        "        key = cand.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "\n",
        "        if is_content_word(cand):\n",
        "            out.append((cand, float(probs[tid].cpu())))\n",
        "            seen.add(key)\n",
        "            if len(out) == k:\n",
        "                break\n",
        "\n",
        "    return out\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line ===\")\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    preds = top_k_content_words(line, k=7, oversample=20000)\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if preds:\n",
        "        for rank, (w, p) in enumerate(preds, start=1):\n",
        "            print(f\"  {rank}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (No content-word candidates found; try increasing oversample.)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Gznc2oawu9",
        "outputId": "68bfcfd2-338e-4790-b1d6-ecdf2e3d02ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. balance            p≈0.005845\n",
            "  2. good               p≈0.003427\n",
            "  3. steel              p≈0.002962\n",
            "  4. self               p≈0.002643\n",
            "  5. order              p≈0.002605\n",
            "  6. thy                p≈0.002361\n",
            "  7. humility           p≈0.002285\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007471\n",
            "  7. death              p≈0.006405\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. other              p≈0.003645\n",
            "  2. leaves             p≈0.003549\n",
            "  3. red                p≈0.001984\n",
            "  4. pine               p≈0.001740\n",
            "  5. black              p≈0.001731\n",
            "  6. fruit              p≈0.001649\n",
            "  7. all                p≈0.001644\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time               p≈0.923361\n",
            "  2. enough             p≈0.002422\n",
            "  3. long               p≈0.002420\n",
            "  4. day                p≈0.001997\n",
            "  5. way                p≈0.001524\n",
            "  6. moment             p≈0.000526\n",
            "  7. year               p≈0.000512\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. like               p≈0.011911\n",
            "  2. all                p≈0.003200\n",
            "  3. two                p≈0.002965\n",
            "  4. who                p≈0.002274\n",
            "  5. black              p≈0.001814\n",
            "  6. saw                p≈0.001649\n",
            "  7. said               p≈0.001444\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058288\n",
            "  3. mountains          p≈0.029669\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014907\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. mention            p≈0.082306\n",
            "  2. say                p≈0.046896\n",
            "  3. forget             p≈0.024347\n",
            "  4. speak              p≈0.021670\n",
            "  5. think              p≈0.012622\n",
            "  6. look               p≈0.009680\n",
            "  7. take               p≈0.008001\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. like               p≈0.003123\n",
            "  2. who                p≈0.003045\n",
            "  3. voice              p≈0.002840\n",
            "  4. let                p≈0.002243\n",
            "  5. sound              p≈0.001899\n",
            "  6. all                p≈0.001682\n",
            "  7. well               p≈0.001651\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. people             p≈0.004512\n",
            "  2. all                p≈0.002143\n",
            "  3. let                p≈0.001983\n",
            "  4. two                p≈0.001953\n",
            "  5. well               p≈0.001833\n",
            "  6. please             p≈0.001478\n",
            "  7. sounds             p≈0.001393\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028549\n",
            "  3. chest              p≈0.028062\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019036\n",
            "  7. footed             p≈0.018051\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. listen             p≈0.033752\n",
            "  2. who                p≈0.008925\n",
            "  3. listens            p≈0.006015\n",
            "  4. see                p≈0.005703\n",
            "  5. please             p≈0.004795\n",
            "  6. listening          p≈0.003307\n",
            "  7. watch              p≈0.002817\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. except             p≈0.050082\n",
            "  2. however            p≈0.014229\n",
            "  3. really             p≈0.007516\n",
            "  4. save               p≈0.005937\n",
            "  5. let                p≈0.004823\n",
            "  6. nobody             p≈0.004076\n",
            "  7. other              p≈0.003865\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. com                p≈0.001090\n",
            "  2. org                p≈0.000582\n",
            "  3. Now                p≈0.000570\n",
            "  4. Let                p≈0.000488\n",
            "  5. All                p≈0.000423\n",
            "  6. Well               p≈0.000420\n",
            "  7. gov                p≈0.000381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# TOP-7 \"SEMANTIC\" next-word candidates per line (GPT-2)\n",
        "# + choose 1..7 for each line\n",
        "# + rebuild line correctly (word BEFORE punctuation)\n",
        "# + save new poem to P7_poem_semantic.txt\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Split each line into: before + last_word + trailing punctuation\n",
        "#    Build prompts exactly like your original: prompt = before + trailing\n",
        "# -----------------------------------------------------\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(\"\\n\".join(prompts_lines))\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Load GPT-2\n",
        "# -----------------------------------------------------\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Filters: word-like + \"content word\" heuristic\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles / determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # common prepositions\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\"before\",\"after\",\n",
        "    \"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    # auxiliaries / modals / copulas\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\n",
        "    \"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    # misc function-ish\n",
        "    \"not\",\"no\",\"yes\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\n",
        "    \"as\",\"up\",\"down\",\"out\",\"off\",\"again\",\"more\",\"most\",\"less\",\"least\"\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    w_low = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(w_low) < 3:\n",
        "        return False\n",
        "    if w_low in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def top_k_content_words(prompt: str, k: int = 7, oversample: int = 20000):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:oversample]\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for tid in sorted_ids.tolist():\n",
        "        cand = tokenizer.decode([tid]).strip()\n",
        "        if not cand:\n",
        "            continue\n",
        "\n",
        "        key = cand.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "\n",
        "        if is_content_word(cand):\n",
        "            out.append((cand, float(probs[tid].cpu())))\n",
        "            seen.add(key)\n",
        "            if len(out) == k:\n",
        "                break\n",
        "\n",
        "    return out\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Rebuild line correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive choose 1..7, build poem, save txt\n",
        "# -----------------------------------------------------\n",
        "new_lines = []\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line (choose 1-7) ===\")\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    preds = top_k_content_words(prompt_line, k=7, oversample=20000)\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "    if preds:\n",
        "        for rank, (w, p) in enumerate(preds, start=1):\n",
        "            print(f\"  {rank}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (No content-word candidates found; try increasing oversample.)\")\n",
        "        # keep original line if nothing found\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    while True:\n",
        "        raw = input(\"Choose an option (1-7): \").strip()\n",
        "        if raw.isdigit():\n",
        "            n = int(raw)\n",
        "            if 1 <= n <= 7:\n",
        "                chosen_word = preds[n - 1][0]\n",
        "                break\n",
        "        print(\"Invalid choice. Type a number from 1 to 7.\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (SEMANTIC FILTER) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"P7_poem_semantic.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlmRnZXb7pEN",
        "outputId": "79c2a161-50b4-479d-c2dd-9d2314cf695a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line (choose 1-7) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. balance            p≈0.005845\n",
            "  2. good               p≈0.003427\n",
            "  3. steel              p≈0.002962\n",
            "  4. self               p≈0.002643\n",
            "  5. order              p≈0.002605\n",
            "  6. thy                p≈0.002361\n",
            "  7. humility           p≈0.002285\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007472\n",
            "  7. death              p≈0.006405\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. other              p≈0.003645\n",
            "  2. leaves             p≈0.003549\n",
            "  3. red                p≈0.001984\n",
            "  4. pine               p≈0.001740\n",
            "  5. black              p≈0.001731\n",
            "  6. fruit              p≈0.001649\n",
            "  7. all                p≈0.001644\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time               p≈0.923336\n",
            "  2. enough             p≈0.002422\n",
            "  3. long               p≈0.002420\n",
            "  4. day                p≈0.001997\n",
            "  5. way                p≈0.001524\n",
            "  6. moment             p≈0.000526\n",
            "  7. year               p≈0.000512\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. like               p≈0.011912\n",
            "  2. all                p≈0.003200\n",
            "  3. two                p≈0.002965\n",
            "  4. who                p≈0.002274\n",
            "  5. black              p≈0.001814\n",
            "  6. saw                p≈0.001649\n",
            "  7. said               p≈0.001444\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058286\n",
            "  3. mountains          p≈0.029670\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014906\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. mention            p≈0.082309\n",
            "  2. say                p≈0.046895\n",
            "  3. forget             p≈0.024347\n",
            "  4. speak              p≈0.021671\n",
            "  5. think              p≈0.012622\n",
            "  6. look               p≈0.009681\n",
            "  7. take               p≈0.008001\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. like               p≈0.003123\n",
            "  2. who                p≈0.003045\n",
            "  3. voice              p≈0.002840\n",
            "  4. let                p≈0.002243\n",
            "  5. sound              p≈0.001899\n",
            "  6. all                p≈0.001682\n",
            "  7. well               p≈0.001651\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. people             p≈0.004512\n",
            "  2. all                p≈0.002143\n",
            "  3. let                p≈0.001983\n",
            "  4. two                p≈0.001952\n",
            "  5. well               p≈0.001833\n",
            "  6. please             p≈0.001478\n",
            "  7. sounds             p≈0.001393\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028551\n",
            "  3. chest              p≈0.028061\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019035\n",
            "  7. footed             p≈0.018051\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. listen             p≈0.033752\n",
            "  2. who                p≈0.008925\n",
            "  3. listens            p≈0.006015\n",
            "  4. see                p≈0.005703\n",
            "  5. please             p≈0.004795\n",
            "  6. listening          p≈0.003307\n",
            "  7. watch              p≈0.002817\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. except             p≈0.050083\n",
            "  2. however            p≈0.014230\n",
            "  3. really             p≈0.007516\n",
            "  4. save               p≈0.005937\n",
            "  5. let                p≈0.004823\n",
            "  6. nobody             p≈0.004076\n",
            "  7. other              p≈0.003865\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. com                p≈0.001090\n",
            "  2. org                p≈0.000582\n",
            "  3. Now                p≈0.000570\n",
            "  4. Let                p≈0.000488\n",
            "  5. All                p≈0.000423\n",
            "  6. Well               p≈0.000420\n",
            "  7. gov                p≈0.000381\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "=== NEW POEM (SEMANTIC FILTER) ===\n",
            "One must have a mind of humility\n",
            "To regard the frost and the death\n",
            "Of the pine-trees crusted with all;\n",
            "And have been cold a long year\n",
            "To behold the junipers shagged with said,\n",
            "The spruces rough in the distant night\n",
            "Of the January sun; and not to take\n",
            "Of any misery in the sound of the well,\n",
            "In the sound of a few sounds,\n",
            "Which is the sound of the voice\n",
            "Full of the same story\n",
            "That is blowing in the same bare footed\n",
            "For the listener, who listens in the watch,\n",
            "And, nothing himself, other\n",
            "Nothing that is not there and the nothing that gov.\n",
            "\n",
            "Saved to: P7_poem_semantic.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# This script: CODE 3\n",
        "#  WORDLIKE ranks 23–43, but ONLY \"content-word\" candidates\n",
        "# (filters out common function words: articles, pronouns, conjunctions, etc.)\n",
        "#\n",
        "# IMPORTANT:\n",
        "# - GPT-2 doesn't output POS tags, so \"nouns/verbs/adjectives\" is approximated by\n",
        "#   removing function words via a stopword list + simple heuristics.\n",
        "# - Ranks here are computed AFTER filtering to word-like tokens, then we keep only\n",
        "#   those that pass the content-word filter, and report the ones whose content-rank\n",
        "#   falls in 23..43.\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---- Remove last word per line (each line = one phrase) ----\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line); removed.append(last_word)\n",
        "    return new_lines, removed\n",
        "\n",
        "# ---- Word-like tokens (single \"word\") ----\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# ---- Function-word filter (remove articles/pronouns/conjunctions + more) ----\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # (extra common function words—optional but improves “semantic” feel)\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def ranked_content_window(prompt: str, tokenizer, model, start_rank: int = 23, end_rank: int = 43, max_wordlike_scan: int = 5000):\n",
        "    \"\"\"\n",
        "    1) Get GPT-2 next-token probabilities\n",
        "    2) Walk tokens by probability, keep WORDLIKE tokens\n",
        "    3) Among WORDLIKE tokens, keep only content-word ones\n",
        "    4) Return those whose *content-word rank* is in [start_rank, end_rank]\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])\n",
        "        w = piece.strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                # scanned a lot but not enough content words\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# ---- Load model ----\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# ---- Run per line ----\n",
        "lines, removed = remove_last_word_per_line(poem)\n",
        "START_R, END_R = 23, 43\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(lines):\n",
        "    print(f\"{i}: {l}\")\n",
        "\n",
        "print(f\"\\n=== CONTENT-WORD ranks {START_R}–{END_R} per line ===\")\n",
        "for i, line in enumerate(lines):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = ranked_content_window(\n",
        "        line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=20000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "    else:\n",
        "        for r, w, p in window:\n",
        "            print(f\"  content-rank {r:>2}: {w:<18} p≈{p:.6e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jGyRvbjfVsw",
        "outputId": "6a14034d-a546-4873-d258-6ead12ff0bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "0: One must have a mind of\n",
            "1: To regard the frost and the\n",
            "2: Of the pine-trees crusted with ;\n",
            "3: And have been cold a long\n",
            "4: To behold the junipers shagged with ,\n",
            "5: The spruces rough in the distant\n",
            "6: Of the January sun; and not to\n",
            "7: Of any misery in the sound of the ,\n",
            "8: In the sound of a few ,\n",
            "9: Which is the sound of the\n",
            "10: Full of the same\n",
            "11: That is blowing in the same bare\n",
            "12: For the listener, who listens in the ,\n",
            "13: And, nothing himself,\n",
            "14: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== CONTENT-WORD ranks 23–43 per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 0 prompt: 'One must have a mind of'\n",
            "  content-rank 23: integrity          p≈1.157843e-03\n",
            "  content-rank 24: common             p≈1.150411e-03\n",
            "  content-rank 25: humour             p≈1.136575e-03\n",
            "  content-rank 26: power              p≈1.088183e-03\n",
            "  content-rank 27: two                p≈1.083188e-03\n",
            "  content-rank 28: stone              p≈1.028237e-03\n",
            "  content-rank 29: matter             p≈9.090302e-04\n",
            "  content-rank 30: trust              p≈8.565321e-04\n",
            "  content-rank 31: transparency       p≈8.288884e-04\n",
            "  content-rank 32: harmony            p≈8.119575e-04\n",
            "  content-rank 33: peace              p≈7.843328e-04\n",
            "  content-rank 34: hard               p≈7.420420e-04\n",
            "  content-rank 35: mastery            p≈6.565556e-04\n",
            "  content-rank 36: flux               p≈6.524560e-04\n",
            "  content-rank 37: control            p≈6.425612e-04\n",
            "  content-rank 38: style              p≈6.351526e-04\n",
            "  content-rank 39: language           p≈6.303926e-04\n",
            "  content-rank 40: scale              p≈6.288986e-04\n",
            "  content-rank 41: action             p≈6.042109e-04\n",
            "  content-rank 42: gratitude          p≈6.024526e-04\n",
            "  content-rank 43: love               p≈6.002870e-04\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'To regard the frost and the'\n",
            "  content-rank 23: light              p≈2.565519e-03\n",
            "  content-rank 24: loss               p≈2.564619e-03\n",
            "  content-rank 25: lightning          p≈2.564580e-03\n",
            "  content-rank 26: weather            p≈2.524396e-03\n",
            "  content-rank 27: thunder            p≈2.411223e-03\n",
            "  content-rank 28: smoke              p≈2.401126e-03\n",
            "  content-rank 29: burning            p≈2.293549e-03\n",
            "  content-rank 30: fact               p≈2.262802e-03\n",
            "  content-rank 31: winter             p≈2.249153e-03\n",
            "  content-rank 32: chill              p≈2.229744e-03\n",
            "  content-rank 33: great              p≈2.218240e-03\n",
            "  content-rank 34: falling            p≈2.154212e-03\n",
            "  content-rank 35: ensuing            p≈2.051427e-03\n",
            "  content-rank 36: moon               p≈2.027775e-03\n",
            "  content-rank 37: war                p≈2.017944e-03\n",
            "  content-rank 38: fog                p≈1.972537e-03\n",
            "  content-rank 39: effect             p≈1.920401e-03\n",
            "  content-rank 40: consequ            p≈1.909866e-03\n",
            "  content-rank 41: black              p≈1.904206e-03\n",
            "  content-rank 42: rising             p≈1.826095e-03\n",
            "  content-rank 43: earth              p≈1.819948e-03\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 23: wood               p≈9.734706e-04\n",
            "  content-rank 24: three              p≈9.640399e-04\n",
            "  content-rank 25: words              p≈9.610656e-04\n",
            "  content-rank 26: branches           p≈8.977617e-04\n",
            "  content-rank 27: fire               p≈8.953265e-04\n",
            "  content-rank 28: poison             p≈8.852806e-04\n",
            "  content-rank 29: seeds              p≈8.509309e-04\n",
            "  content-rank 30: frost              p≈7.817165e-04\n",
            "  content-rank 31: like               p≈7.812633e-04\n",
            "  content-rank 32: green              p≈7.705723e-04\n",
            "  content-rank 33: ung                p≈7.601437e-04\n",
            "  content-rank 34: see                p≈7.405266e-04\n",
            "  content-rank 35: man                p≈7.067286e-04\n",
            "  content-rank 36: tobacco            p≈7.066315e-04\n",
            "  content-rank 37: rocks              p≈6.849221e-04\n",
            "  content-rank 38: ter                p≈6.650254e-04\n",
            "  content-rank 39: berries            p≈6.611401e-04\n",
            "  content-rank 40: grains             p≈6.564056e-04\n",
            "  content-rank 41: ing                p≈6.536371e-04\n",
            "  content-rank 42: notes              p≈6.363995e-04\n",
            "  content-rank 43: note               p≈6.309318e-04\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'And have been cold a long'\n",
            "  content-rank 23: term               p≈1.281507e-04\n",
            "  content-rank 24: winter             p≈1.232879e-04\n",
            "  content-rank 25: longer             p≈1.229863e-04\n",
            "  content-rank 26: haul               p≈1.079022e-04\n",
            "  content-rank 27: month              p≈1.076407e-04\n",
            "  content-rank 28: amount             p≈1.057397e-04\n",
            "  content-rank 29: wait               p≈1.045477e-04\n",
            "  content-rank 30: rest               p≈8.839200e-05\n",
            "  content-rank 31: Time               p≈8.501581e-05\n",
            "  content-rank 32: run                p≈8.098321e-05\n",
            "  content-rank 33: whilst             p≈7.479872e-05\n",
            "  content-rank 34: distance           p≈7.223074e-05\n",
            "  content-rank 35: little             p≈7.160415e-05\n",
            "  content-rank 36: fucking            p≈6.991077e-05\n",
            "  content-rank 37: summer             p≈6.987371e-05\n",
            "  content-rank 38: weekend            p≈6.295993e-05\n",
            "  content-rank 39: minute             p≈5.838366e-05\n",
            "  content-rank 40: career             p≈5.533013e-05\n",
            "  content-rank 41: morning            p≈5.366566e-05\n",
            "  content-rank 42: shot               p≈5.040480e-05\n",
            "  content-rank 43: bunch              p≈4.933626e-05\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 23: four               p≈9.007804e-04\n",
            "  content-rank 24: like               p≈8.807870e-04\n",
            "  content-rank 25: leaving            p≈8.667679e-04\n",
            "  content-rank 26: another            p≈8.471932e-04\n",
            "  content-rank 27: see                p≈8.464567e-04\n",
            "  content-rank 28: fire               p≈7.996319e-04\n",
            "  content-rank 29: most               p≈7.849496e-04\n",
            "  content-rank 30: ten                p≈7.491185e-04\n",
            "  content-rank 31: both               p≈7.188061e-04\n",
            "  content-rank 32: great              p≈6.673890e-04\n",
            "  content-rank 33: look               p≈6.336283e-04\n",
            "  content-rank 34: long               p≈5.995823e-04\n",
            "  content-rank 35: until              p≈5.839930e-04\n",
            "  content-rank 36: rose               p≈5.817074e-04\n",
            "  content-rank 37: blood              p≈5.776254e-04\n",
            "  content-rank 38: other              p≈5.761641e-04\n",
            "  content-rank 39: put                p≈5.746847e-04\n",
            "  content-rank 40: looking            p≈5.669676e-04\n",
            "  content-rank 41: along              p≈5.619978e-04\n",
            "  content-rank 42: out                p≈5.597897e-04\n",
            "  content-rank 43: suddenly           p≈5.424798e-04\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 23: north              p≈5.338973e-03\n",
            "  content-rank 24: blue               p≈5.140398e-03\n",
            "  content-rank 25: days               p≈4.798145e-03\n",
            "  content-rank 26: summer             p≈4.789331e-03\n",
            "  content-rank 27: dark               p≈4.757429e-03\n",
            "  content-rank 28: south              p≈4.624022e-03\n",
            "  content-rank 29: memory             p≈4.617958e-03\n",
            "  content-rank 30: skies              p≈4.493122e-03\n",
            "  content-rank 31: evening            p≈4.228182e-03\n",
            "  content-rank 32: wind               p≈4.197647e-03\n",
            "  content-rank 33: stars              p≈3.981111e-03\n",
            "  content-rank 34: black              p≈3.895184e-03\n",
            "  content-rank 35: world              p≈3.893401e-03\n",
            "  content-rank 36: fields             p≈3.550558e-03\n",
            "  content-rank 37: years              p≈3.535016e-03\n",
            "  content-rank 38: star               p≈3.496685e-03\n",
            "  content-rank 39: twilight           p≈3.292309e-03\n",
            "  content-rank 40: shadow             p≈3.151193e-03\n",
            "  content-rank 41: middle             p≈3.140896e-03\n",
            "  content-rank 42: darkness           p≈3.125787e-03\n",
            "  content-rank 43: countryside        p≈3.048049e-03\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 23: let                p≈3.104745e-03\n",
            "  content-rank 24: know               p≈3.072416e-03\n",
            "  content-rank 25: exceed             p≈2.852337e-03\n",
            "  content-rank 26: add                p≈2.846967e-03\n",
            "  content-rank 27: wonder             p≈2.815173e-03\n",
            "  content-rank 28: use                p≈2.749708e-03\n",
            "  content-rank 29: lose               p≈2.667997e-03\n",
            "  content-rank 30: light              p≈2.596983e-03\n",
            "  content-rank 31: return             p≈2.571275e-03\n",
            "  content-rank 32: ask                p≈2.288964e-03\n",
            "  content-rank 33: keep               p≈2.256160e-03\n",
            "  content-rank 34: write              p≈2.196594e-03\n",
            "  content-rank 35: blame              p≈2.167544e-03\n",
            "  content-rank 36: set                p≈2.137068e-03\n",
            "  content-rank 37: show               p≈2.075968e-03\n",
            "  content-rank 38: come               p≈2.058054e-03\n",
            "  content-rank 39: bring              p≈2.019726e-03\n",
            "  content-rank 40: disturb            p≈1.887381e-03\n",
            "  content-rank 41: talk               p≈1.845137e-03\n",
            "  content-rank 42: call               p≈1.795998e-03\n",
            "  content-rank 43: find               p≈1.790662e-03\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 23: especially         p≈8.445737e-04\n",
            "  content-rank 24: man                p≈8.119832e-04\n",
            "  content-rank 25: bell               p≈8.011041e-04\n",
            "  content-rank 26: voices             p≈7.925263e-04\n",
            "  content-rank 27: except             p≈7.780815e-04\n",
            "  content-rank 28: hear               p≈7.706788e-04\n",
            "  content-rank 29: whatever           p≈7.622582e-04\n",
            "  content-rank 30: thunder            p≈7.181269e-04\n",
            "  content-rank 31: drums              p≈7.039256e-04\n",
            "  content-rank 32: drum               p≈7.035497e-04\n",
            "  content-rank 33: music              p≈6.690922e-04\n",
            "  content-rank 34: anything           p≈6.425080e-04\n",
            "  content-rank 35: boom               p≈6.402278e-04\n",
            "  content-rank 36: another            p≈6.381698e-04\n",
            "  content-rank 37: making             p≈6.370023e-04\n",
            "  content-rank 38: make               p≈6.181580e-04\n",
            "  content-rank 39: suddenly           p≈6.173096e-04\n",
            "  content-rank 40: whether            p≈6.116744e-04\n",
            "  content-rank 41: thus               p≈6.074470e-04\n",
            "  content-rank 42: comes              p≈5.746456e-04\n",
            "  content-rank 43: saying             p≈5.694043e-04\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'In the sound of a few ,'\n",
            "  content-rank 23: words              p≈8.481996e-04\n",
            "  content-rank 24: loud               p≈7.721767e-04\n",
            "  content-rank 25: sometimes          p≈7.600429e-04\n",
            "  content-rank 26: suddenly           p≈6.847791e-04\n",
            "  content-rank 27: click              p≈6.808356e-04\n",
            "  content-rank 28: lines              p≈6.778864e-04\n",
            "  content-rank 29: right              p≈6.388007e-04\n",
            "  content-rank 30: especially         p≈6.213757e-04\n",
            "  content-rank 31: back               p≈5.950598e-04\n",
            "  content-rank 32: three              p≈5.911096e-04\n",
            "  content-rank 33: almost             p≈5.804333e-04\n",
            "  content-rank 34: players            p≈5.770511e-04\n",
            "  content-rank 35: shots              p≈5.628113e-04\n",
            "  content-rank 36: sound              p≈5.179089e-04\n",
            "  content-rank 37: make               p≈5.107009e-04\n",
            "  content-rank 38: high               p≈5.000061e-04\n",
            "  content-rank 39: voice              p≈4.881217e-04\n",
            "  content-rank 40: saying             p≈4.783411e-04\n",
            "  content-rank 41: using              p≈4.661814e-04\n",
            "  content-rank 42: making             p≈4.493976e-04\n",
            "  content-rank 43: look               p≈4.490891e-04\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'Which is the sound of the'\n",
            "  content-rank 23: sea                p≈2.954793e-03\n",
            "  content-rank 24: explosion          p≈2.944599e-03\n",
            "  content-rank 25: rain               p≈2.916806e-03\n",
            "  content-rank 26: horn               p≈2.768032e-03\n",
            "  content-rank 27: dog                p≈2.678287e-03\n",
            "  content-rank 28: trumpet            p≈2.674713e-03\n",
            "  content-rank 29: crowd              p≈2.597807e-03\n",
            "  content-rank 30: drums              p≈2.584719e-03\n",
            "  content-rank 31: earth              p≈2.546045e-03\n",
            "  content-rank 32: world              p≈2.486914e-03\n",
            "  content-rank 33: two                p≈2.482724e-03\n",
            "  content-rank 34: ocean              p≈2.313941e-03\n",
            "  content-rank 35: moon               p≈2.293256e-03\n",
            "  content-rank 36: police             p≈2.292609e-03\n",
            "  content-rank 37: war                p≈2.288816e-03\n",
            "  content-rank 38: ground             p≈2.261478e-03\n",
            "  content-rank 39: birds              p≈2.244084e-03\n",
            "  content-rank 40: ball               p≈2.242715e-03\n",
            "  content-rank 41: metal              p≈2.232489e-03\n",
            "  content-rank 42: machine            p≈2.177432e-03\n",
            "  content-rank 43: engines            p≈2.110439e-03\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Full of the same'\n",
            "  content-rank 23: amount             p≈2.584317e-03\n",
            "  content-rank 24: class              p≈2.573162e-03\n",
            "  content-rank 25: colors             p≈2.523835e-03\n",
            "  content-rank 26: level              p≈2.499404e-03\n",
            "  content-rank 27: things             p≈2.476701e-03\n",
            "  content-rank 28: game               p≈2.450089e-03\n",
            "  content-rank 29: order              p≈2.272021e-03\n",
            "  content-rank 30: spirit             p≈2.106830e-03\n",
            "  content-rank 31: quality            p≈2.095240e-03\n",
            "  content-rank 32: group              p≈2.061293e-03\n",
            "  content-rank 33: flavor             p≈1.974508e-03\n",
            "  content-rank 34: product            p≈1.892228e-03\n",
            "  content-rank 35: week               p≈1.775009e-03\n",
            "  content-rank 36: basic              p≈1.770018e-03\n",
            "  content-rank 37: effect             p≈1.725379e-03\n",
            "  content-rank 38: style              p≈1.708703e-03\n",
            "  content-rank 39: brand              p≈1.682135e-03\n",
            "  content-rank 40: problem            p≈1.677892e-03\n",
            "  content-rank 41: design             p≈1.664263e-03\n",
            "  content-rank 42: age                p≈1.656220e-03\n",
            "  content-rank 43: number             p≈1.626219e-03\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 23: spot               p≈7.919451e-03\n",
            "  content-rank 24: light              p≈7.382416e-03\n",
            "  content-rank 25: bones              p≈7.025083e-03\n",
            "  content-rank 26: toe                p≈6.820642e-03\n",
            "  content-rank 27: black              p≈6.659084e-03\n",
            "  content-rank 28: metal              p≈6.508104e-03\n",
            "  content-rank 29: white              p≈6.092657e-03\n",
            "  content-rank 30: pocket             p≈5.747414e-03\n",
            "  content-rank 31: blue               p≈5.241311e-03\n",
            "  content-rank 32: throat             p≈4.876651e-03\n",
            "  content-rank 33: wood               p≈4.485320e-03\n",
            "  content-rank 34: spots              p≈4.084523e-03\n",
            "  content-rank 35: dirt               p≈3.824895e-03\n",
            "  content-rank 36: hole               p≈3.581033e-03\n",
            "  content-rank 37: areas              p≈3.390169e-03\n",
            "  content-rank 38: body               p≈3.274578e-03\n",
            "  content-rank 39: shoulder           p≈3.245726e-03\n",
            "  content-rank 40: ground             p≈3.207961e-03\n",
            "  content-rank 41: front              p≈3.181297e-03\n",
            "  content-rank 42: middle             p≈3.166405e-03\n",
            "  content-rank 43: palms              p≈3.099362e-03\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 23: now                p≈1.437430e-03\n",
            "  content-rank 24: set                p≈1.430986e-03\n",
            "  content-rank 25: try                p≈1.419568e-03\n",
            "  content-rank 26: right              p≈1.371721e-03\n",
            "  content-rank 27: call               p≈1.316256e-03\n",
            "  content-rank 28: show               p≈1.271823e-03\n",
            "  content-rank 29: hear               p≈1.264190e-03\n",
            "  content-rank 30: check              p≈1.210429e-03\n",
            "  content-rank 31: both               p≈1.183318e-03\n",
            "  content-rank 32: instead            p≈1.062137e-03\n",
            "  content-rank 33: usually            p≈1.045231e-03\n",
            "  content-rank 34: expect             p≈9.945022e-04\n",
            "  content-rank 35: choose             p≈9.844168e-04\n",
            "  content-rank 36: audio              p≈9.584341e-04\n",
            "  content-rank 37: start              p≈9.532637e-04\n",
            "  content-rank 38: gets               p≈9.491778e-04\n",
            "  content-rank 39: take               p≈9.398748e-04\n",
            "  content-rank 40: like               p≈9.378548e-04\n",
            "  content-rank 41: select             p≈9.150188e-04\n",
            "  content-rank 42: next               p≈8.801395e-04\n",
            "  content-rank 43: says               p≈8.754116e-04\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'And, nothing himself,'\n",
            "  content-rank 23: like               p≈1.640816e-03\n",
            "  content-rank 24: little             p≈1.581682e-03\n",
            "  content-rank 25: actually           p≈1.518363e-03\n",
            "  content-rank 26: said               p≈1.488893e-03\n",
            "  content-rank 27: whether            p≈1.460708e-03\n",
            "  content-rank 28: according          p≈1.359070e-03\n",
            "  content-rank 29: certainly          p≈1.333516e-03\n",
            "  content-rank 30: especially         p≈1.288520e-03\n",
            "  content-rank 31: despite            p≈1.172254e-03\n",
            "  content-rank 32: quite              p≈1.166855e-03\n",
            "  content-rank 33: apparently         p≈1.056976e-03\n",
            "  content-rank 34: probably           p≈1.052117e-03\n",
            "  content-rank 35: aside              p≈1.035734e-03\n",
            "  content-rank 36: says               p≈1.012583e-03\n",
            "  content-rank 37: right              p≈1.008051e-03\n",
            "  content-rank 38: maybe              p≈1.003830e-03\n",
            "  content-rank 39: obviously          p≈9.602609e-04\n",
            "  content-rank 40: instead            p≈9.083664e-04\n",
            "  content-rank 41: sir                p≈9.031835e-04\n",
            "  content-rank 42: mind               p≈8.988871e-04\n",
            "  content-rank 43: now                p≈8.827596e-04\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 23: Everything         p≈1.206515e-04\n",
            "  content-rank 24: However            p≈1.183251e-04\n",
            "  content-rank 25: Whether            p≈1.168592e-04\n",
            "  content-rank 26: name               p≈1.163042e-04\n",
            "  content-rank 27: dll                p≈1.156132e-04\n",
            "  content-rank 28: put                p≈1.148229e-04\n",
            "  content-rank 29: list               p≈1.147538e-04\n",
            "  content-rank 30: Please             p≈1.147109e-04\n",
            "  content-rank 31: Sometimes          p≈1.124226e-04\n",
            "  content-rank 32: said               p≈1.123104e-04\n",
            "  content-rank 33: Remember           p≈1.114695e-04\n",
            "  content-rank 34: Rem                p≈1.112172e-04\n",
            "  content-rank 35: demon              p≈1.086127e-04\n",
            "  content-rank 36: asc                p≈1.069321e-04\n",
            "  content-rank 37: Come               p≈1.049078e-04\n",
            "  content-rank 38: get                p≈1.032223e-04\n",
            "  content-rank 39: Maybe              p≈1.012992e-04\n",
            "  content-rank 40: Another            p≈9.957208e-05\n",
            "  content-rank 41: put                p≈9.941116e-05\n",
            "  content-rank 42: text               p≈9.457480e-05\n",
            "  content-rank 43: Take               p≈9.084559e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CONTENT-WORD window ranks 23–43 per line (GPT-2)\n",
        "# Choose by CONTENT-RANK number (23..43)\n",
        "# Rebuild line word BEFORE punctuation\n",
        "# Save to \"PX_poem_semantic_r23_43.txt\"\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Split each line into: before + last_word + trailing punctuation\n",
        "#    (used to rebuild correctly later)\n",
        "# -----------------------------------------------------\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "# Prompts must match your original logic: prompt = before + trailing (punctuation kept)\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(prompts_lines, start=1):\n",
        "    print(f\"Line {i}: {l}\")\n",
        "\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Word-like + stopword filter (semantic-ish)\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # extra common function words\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Get content-word candidates whose CONTENT-RANK is in [start_rank, end_rank]\n",
        "# -----------------------------------------------------\n",
        "def ranked_content_window(prompt: str, tokenizer, model, start_rank: int = 23, end_rank: int = 43, max_wordlike_scan: int = 20000):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []  # list of (content_rank, word, prob)\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Load model\n",
        "# -----------------------------------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive: choose by CONTENT-RANK number (23..43)\n",
        "# -----------------------------------------------------\n",
        "START_R, END_R = 23, 43\n",
        "new_lines = []\n",
        "\n",
        "print(f\"\\n=== Choose by CONTENT-RANK number ({START_R}–{END_R}) ===\")\n",
        "\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = ranked_content_window(\n",
        "        prompt_line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=20000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    # show all ranks 23..43 that exist\n",
        "    rank_to_word = {}\n",
        "    for r, w, p in window:\n",
        "        rank_to_word[r] = (w, p)\n",
        "        print(f\"  content-rank {r:>2}: {w:<18} p≈{p:.6e}\")\n",
        "\n",
        "    valid_ranks = sorted(rank_to_word.keys())\n",
        "\n",
        "    while True:\n",
        "        raw = input(f\"Type the CONTENT-RANK you want ({valid_ranks[0]}–{valid_ranks[-1]}): \").strip()\n",
        "        if raw.isdigit():\n",
        "            chosen_rank = int(raw)\n",
        "            if chosen_rank in rank_to_word:\n",
        "                chosen_word = rank_to_word[chosen_rank][0]\n",
        "                break\n",
        "        print(f\"Invalid. Choose one of these ranks: {valid_ranks}\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (CONTENT-WINDOW FILTER) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"PX_poem_semantic_r23_43.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60mYK8znADCJ",
        "outputId": "4d8369e0-9536-4df6-8ace-5c06b8eb4d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "Line 1: One must have a mind of\n",
            "Line 2: To regard the frost and the\n",
            "Line 3: Of the pine-trees crusted with ;\n",
            "Line 4: And have been cold a long\n",
            "Line 5: To behold the junipers shagged with ,\n",
            "Line 6: The spruces rough in the distant\n",
            "Line 7: Of the January sun; and not to\n",
            "Line 8: Of any misery in the sound of the ,\n",
            "Line 9: In the sound of a few ,\n",
            "Line 10: Which is the sound of the\n",
            "Line 11: Full of the same\n",
            "Line 12: That is blowing in the same bare\n",
            "Line 13: For the listener, who listens in the ,\n",
            "Line 14: And, nothing himself,\n",
            "Line 15: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== Choose by CONTENT-RANK number (23–43) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  content-rank 23: integrity          p≈1.157843e-03\n",
            "  content-rank 24: common             p≈1.150411e-03\n",
            "  content-rank 25: humour             p≈1.136575e-03\n",
            "  content-rank 26: power              p≈1.088183e-03\n",
            "  content-rank 27: two                p≈1.083188e-03\n",
            "  content-rank 28: stone              p≈1.028237e-03\n",
            "  content-rank 29: matter             p≈9.090302e-04\n",
            "  content-rank 30: trust              p≈8.565321e-04\n",
            "  content-rank 31: transparency       p≈8.288884e-04\n",
            "  content-rank 32: harmony            p≈8.119575e-04\n",
            "  content-rank 33: peace              p≈7.843328e-04\n",
            "  content-rank 34: hard               p≈7.420420e-04\n",
            "  content-rank 35: mastery            p≈6.565556e-04\n",
            "  content-rank 36: flux               p≈6.524560e-04\n",
            "  content-rank 37: control            p≈6.425612e-04\n",
            "  content-rank 38: style              p≈6.351526e-04\n",
            "  content-rank 39: language           p≈6.303926e-04\n",
            "  content-rank 40: scale              p≈6.288986e-04\n",
            "  content-rank 41: action             p≈6.042109e-04\n",
            "  content-rank 42: gratitude          p≈6.024526e-04\n",
            "  content-rank 43: love               p≈6.002870e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  content-rank 23: light              p≈2.565519e-03\n",
            "  content-rank 24: loss               p≈2.564619e-03\n",
            "  content-rank 25: lightning          p≈2.564580e-03\n",
            "  content-rank 26: weather            p≈2.524396e-03\n",
            "  content-rank 27: thunder            p≈2.411223e-03\n",
            "  content-rank 28: smoke              p≈2.401126e-03\n",
            "  content-rank 29: burning            p≈2.293549e-03\n",
            "  content-rank 30: fact               p≈2.262802e-03\n",
            "  content-rank 31: winter             p≈2.249153e-03\n",
            "  content-rank 32: chill              p≈2.229744e-03\n",
            "  content-rank 33: great              p≈2.218240e-03\n",
            "  content-rank 34: falling            p≈2.154212e-03\n",
            "  content-rank 35: ensuing            p≈2.051427e-03\n",
            "  content-rank 36: moon               p≈2.027775e-03\n",
            "  content-rank 37: war                p≈2.017944e-03\n",
            "  content-rank 38: fog                p≈1.972537e-03\n",
            "  content-rank 39: effect             p≈1.920401e-03\n",
            "  content-rank 40: consequ            p≈1.909866e-03\n",
            "  content-rank 41: black              p≈1.904206e-03\n",
            "  content-rank 42: rising             p≈1.826095e-03\n",
            "  content-rank 43: earth              p≈1.819948e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 23: wood               p≈9.734706e-04\n",
            "  content-rank 24: three              p≈9.640399e-04\n",
            "  content-rank 25: words              p≈9.610656e-04\n",
            "  content-rank 26: branches           p≈8.977617e-04\n",
            "  content-rank 27: fire               p≈8.953265e-04\n",
            "  content-rank 28: poison             p≈8.852806e-04\n",
            "  content-rank 29: seeds              p≈8.509309e-04\n",
            "  content-rank 30: frost              p≈7.817165e-04\n",
            "  content-rank 31: like               p≈7.812633e-04\n",
            "  content-rank 32: green              p≈7.705723e-04\n",
            "  content-rank 33: ung                p≈7.601437e-04\n",
            "  content-rank 34: see                p≈7.405266e-04\n",
            "  content-rank 35: man                p≈7.067286e-04\n",
            "  content-rank 36: tobacco            p≈7.066315e-04\n",
            "  content-rank 37: rocks              p≈6.849221e-04\n",
            "  content-rank 38: ter                p≈6.650254e-04\n",
            "  content-rank 39: berries            p≈6.611401e-04\n",
            "  content-rank 40: grains             p≈6.564056e-04\n",
            "  content-rank 41: ing                p≈6.536371e-04\n",
            "  content-rank 42: notes              p≈6.363995e-04\n",
            "  content-rank 43: note               p≈6.309318e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  content-rank 23: term               p≈1.281507e-04\n",
            "  content-rank 24: winter             p≈1.232879e-04\n",
            "  content-rank 25: longer             p≈1.229863e-04\n",
            "  content-rank 26: haul               p≈1.079022e-04\n",
            "  content-rank 27: month              p≈1.076407e-04\n",
            "  content-rank 28: amount             p≈1.057397e-04\n",
            "  content-rank 29: wait               p≈1.045477e-04\n",
            "  content-rank 30: rest               p≈8.839200e-05\n",
            "  content-rank 31: Time               p≈8.501581e-05\n",
            "  content-rank 32: run                p≈8.098321e-05\n",
            "  content-rank 33: whilst             p≈7.479872e-05\n",
            "  content-rank 34: distance           p≈7.223074e-05\n",
            "  content-rank 35: little             p≈7.160415e-05\n",
            "  content-rank 36: fucking            p≈6.991077e-05\n",
            "  content-rank 37: summer             p≈6.987371e-05\n",
            "  content-rank 38: weekend            p≈6.295993e-05\n",
            "  content-rank 39: minute             p≈5.838366e-05\n",
            "  content-rank 40: career             p≈5.533013e-05\n",
            "  content-rank 41: morning            p≈5.366566e-05\n",
            "  content-rank 42: shot               p≈5.040480e-05\n",
            "  content-rank 43: bunch              p≈4.933626e-05\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 23: four               p≈9.007804e-04\n",
            "  content-rank 24: like               p≈8.807870e-04\n",
            "  content-rank 25: leaving            p≈8.667679e-04\n",
            "  content-rank 26: another            p≈8.471932e-04\n",
            "  content-rank 27: see                p≈8.464567e-04\n",
            "  content-rank 28: fire               p≈7.996319e-04\n",
            "  content-rank 29: most               p≈7.849496e-04\n",
            "  content-rank 30: ten                p≈7.491185e-04\n",
            "  content-rank 31: both               p≈7.188061e-04\n",
            "  content-rank 32: great              p≈6.673890e-04\n",
            "  content-rank 33: look               p≈6.336283e-04\n",
            "  content-rank 34: long               p≈5.995823e-04\n",
            "  content-rank 35: until              p≈5.839930e-04\n",
            "  content-rank 36: rose               p≈5.817074e-04\n",
            "  content-rank 37: blood              p≈5.776254e-04\n",
            "  content-rank 38: other              p≈5.761641e-04\n",
            "  content-rank 39: put                p≈5.746847e-04\n",
            "  content-rank 40: looking            p≈5.669676e-04\n",
            "  content-rank 41: along              p≈5.619978e-04\n",
            "  content-rank 42: out                p≈5.597897e-04\n",
            "  content-rank 43: suddenly           p≈5.424798e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 23: north              p≈5.338973e-03\n",
            "  content-rank 24: blue               p≈5.140398e-03\n",
            "  content-rank 25: days               p≈4.798145e-03\n",
            "  content-rank 26: summer             p≈4.789331e-03\n",
            "  content-rank 27: dark               p≈4.757429e-03\n",
            "  content-rank 28: south              p≈4.624022e-03\n",
            "  content-rank 29: memory             p≈4.617958e-03\n",
            "  content-rank 30: skies              p≈4.493122e-03\n",
            "  content-rank 31: evening            p≈4.228182e-03\n",
            "  content-rank 32: wind               p≈4.197647e-03\n",
            "  content-rank 33: stars              p≈3.981111e-03\n",
            "  content-rank 34: black              p≈3.895184e-03\n",
            "  content-rank 35: world              p≈3.893401e-03\n",
            "  content-rank 36: fields             p≈3.550558e-03\n",
            "  content-rank 37: years              p≈3.535016e-03\n",
            "  content-rank 38: star               p≈3.496685e-03\n",
            "  content-rank 39: twilight           p≈3.292309e-03\n",
            "  content-rank 40: shadow             p≈3.151193e-03\n",
            "  content-rank 41: middle             p≈3.140896e-03\n",
            "  content-rank 42: darkness           p≈3.125787e-03\n",
            "  content-rank 43: countryside        p≈3.048049e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 23: let                p≈3.104745e-03\n",
            "  content-rank 24: know               p≈3.072416e-03\n",
            "  content-rank 25: exceed             p≈2.852337e-03\n",
            "  content-rank 26: add                p≈2.846967e-03\n",
            "  content-rank 27: wonder             p≈2.815173e-03\n",
            "  content-rank 28: use                p≈2.749708e-03\n",
            "  content-rank 29: lose               p≈2.667997e-03\n",
            "  content-rank 30: light              p≈2.596983e-03\n",
            "  content-rank 31: return             p≈2.571275e-03\n",
            "  content-rank 32: ask                p≈2.288964e-03\n",
            "  content-rank 33: keep               p≈2.256160e-03\n",
            "  content-rank 34: write              p≈2.196594e-03\n",
            "  content-rank 35: blame              p≈2.167544e-03\n",
            "  content-rank 36: set                p≈2.137068e-03\n",
            "  content-rank 37: show               p≈2.075968e-03\n",
            "  content-rank 38: come               p≈2.058054e-03\n",
            "  content-rank 39: bring              p≈2.019726e-03\n",
            "  content-rank 40: disturb            p≈1.887381e-03\n",
            "  content-rank 41: talk               p≈1.845137e-03\n",
            "  content-rank 42: call               p≈1.795998e-03\n",
            "  content-rank 43: find               p≈1.790662e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 23: especially         p≈8.445737e-04\n",
            "  content-rank 24: man                p≈8.119832e-04\n",
            "  content-rank 25: bell               p≈8.011041e-04\n",
            "  content-rank 26: voices             p≈7.925263e-04\n",
            "  content-rank 27: except             p≈7.780815e-04\n",
            "  content-rank 28: hear               p≈7.706788e-04\n",
            "  content-rank 29: whatever           p≈7.622582e-04\n",
            "  content-rank 30: thunder            p≈7.181269e-04\n",
            "  content-rank 31: drums              p≈7.039256e-04\n",
            "  content-rank 32: drum               p≈7.035497e-04\n",
            "  content-rank 33: music              p≈6.690922e-04\n",
            "  content-rank 34: anything           p≈6.425080e-04\n",
            "  content-rank 35: boom               p≈6.402278e-04\n",
            "  content-rank 36: another            p≈6.381698e-04\n",
            "  content-rank 37: making             p≈6.370023e-04\n",
            "  content-rank 38: make               p≈6.181580e-04\n",
            "  content-rank 39: suddenly           p≈6.173096e-04\n",
            "  content-rank 40: whether            p≈6.116744e-04\n",
            "  content-rank 41: thus               p≈6.074470e-04\n",
            "  content-rank 42: comes              p≈5.746456e-04\n",
            "  content-rank 43: saying             p≈5.694043e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  content-rank 23: words              p≈8.481996e-04\n",
            "  content-rank 24: loud               p≈7.721767e-04\n",
            "  content-rank 25: sometimes          p≈7.600429e-04\n",
            "  content-rank 26: suddenly           p≈6.847791e-04\n",
            "  content-rank 27: click              p≈6.808356e-04\n",
            "  content-rank 28: lines              p≈6.778864e-04\n",
            "  content-rank 29: right              p≈6.388007e-04\n",
            "  content-rank 30: especially         p≈6.213757e-04\n",
            "  content-rank 31: back               p≈5.950598e-04\n",
            "  content-rank 32: three              p≈5.911096e-04\n",
            "  content-rank 33: almost             p≈5.804333e-04\n",
            "  content-rank 34: players            p≈5.770511e-04\n",
            "  content-rank 35: shots              p≈5.628113e-04\n",
            "  content-rank 36: sound              p≈5.179089e-04\n",
            "  content-rank 37: make               p≈5.107009e-04\n",
            "  content-rank 38: high               p≈5.000061e-04\n",
            "  content-rank 39: voice              p≈4.881217e-04\n",
            "  content-rank 40: saying             p≈4.783411e-04\n",
            "  content-rank 41: using              p≈4.661814e-04\n",
            "  content-rank 42: making             p≈4.493976e-04\n",
            "  content-rank 43: look               p≈4.490891e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  content-rank 23: sea                p≈2.954793e-03\n",
            "  content-rank 24: explosion          p≈2.944599e-03\n",
            "  content-rank 25: rain               p≈2.916806e-03\n",
            "  content-rank 26: horn               p≈2.768032e-03\n",
            "  content-rank 27: dog                p≈2.678287e-03\n",
            "  content-rank 28: trumpet            p≈2.674713e-03\n",
            "  content-rank 29: crowd              p≈2.597807e-03\n",
            "  content-rank 30: drums              p≈2.584719e-03\n",
            "  content-rank 31: earth              p≈2.546045e-03\n",
            "  content-rank 32: world              p≈2.486914e-03\n",
            "  content-rank 33: two                p≈2.482724e-03\n",
            "  content-rank 34: ocean              p≈2.313941e-03\n",
            "  content-rank 35: moon               p≈2.293256e-03\n",
            "  content-rank 36: police             p≈2.292609e-03\n",
            "  content-rank 37: war                p≈2.288816e-03\n",
            "  content-rank 38: ground             p≈2.261478e-03\n",
            "  content-rank 39: birds              p≈2.244084e-03\n",
            "  content-rank 40: ball               p≈2.242715e-03\n",
            "  content-rank 41: metal              p≈2.232489e-03\n",
            "  content-rank 42: machine            p≈2.177432e-03\n",
            "  content-rank 43: engines            p≈2.110439e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  content-rank 23: amount             p≈2.584317e-03\n",
            "  content-rank 24: class              p≈2.573162e-03\n",
            "  content-rank 25: colors             p≈2.523835e-03\n",
            "  content-rank 26: level              p≈2.499404e-03\n",
            "  content-rank 27: things             p≈2.476701e-03\n",
            "  content-rank 28: game               p≈2.450089e-03\n",
            "  content-rank 29: order              p≈2.272021e-03\n",
            "  content-rank 30: spirit             p≈2.106830e-03\n",
            "  content-rank 31: quality            p≈2.095240e-03\n",
            "  content-rank 32: group              p≈2.061293e-03\n",
            "  content-rank 33: flavor             p≈1.974508e-03\n",
            "  content-rank 34: product            p≈1.892228e-03\n",
            "  content-rank 35: week               p≈1.775009e-03\n",
            "  content-rank 36: basic              p≈1.770018e-03\n",
            "  content-rank 37: effect             p≈1.725379e-03\n",
            "  content-rank 38: style              p≈1.708703e-03\n",
            "  content-rank 39: brand              p≈1.682135e-03\n",
            "  content-rank 40: problem            p≈1.677892e-03\n",
            "  content-rank 41: design             p≈1.664263e-03\n",
            "  content-rank 42: age                p≈1.656220e-03\n",
            "  content-rank 43: number             p≈1.626219e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 23: spot               p≈7.919451e-03\n",
            "  content-rank 24: light              p≈7.382416e-03\n",
            "  content-rank 25: bones              p≈7.025083e-03\n",
            "  content-rank 26: toe                p≈6.820642e-03\n",
            "  content-rank 27: black              p≈6.659084e-03\n",
            "  content-rank 28: metal              p≈6.508104e-03\n",
            "  content-rank 29: white              p≈6.092657e-03\n",
            "  content-rank 30: pocket             p≈5.747414e-03\n",
            "  content-rank 31: blue               p≈5.241311e-03\n",
            "  content-rank 32: throat             p≈4.876651e-03\n",
            "  content-rank 33: wood               p≈4.485320e-03\n",
            "  content-rank 34: spots              p≈4.084523e-03\n",
            "  content-rank 35: dirt               p≈3.824895e-03\n",
            "  content-rank 36: hole               p≈3.581033e-03\n",
            "  content-rank 37: areas              p≈3.390169e-03\n",
            "  content-rank 38: body               p≈3.274578e-03\n",
            "  content-rank 39: shoulder           p≈3.245726e-03\n",
            "  content-rank 40: ground             p≈3.207961e-03\n",
            "  content-rank 41: front              p≈3.181297e-03\n",
            "  content-rank 42: middle             p≈3.166405e-03\n",
            "  content-rank 43: palms              p≈3.099362e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 23: now                p≈1.437430e-03\n",
            "  content-rank 24: set                p≈1.430986e-03\n",
            "  content-rank 25: try                p≈1.419568e-03\n",
            "  content-rank 26: right              p≈1.371721e-03\n",
            "  content-rank 27: call               p≈1.316256e-03\n",
            "  content-rank 28: show               p≈1.271823e-03\n",
            "  content-rank 29: hear               p≈1.264190e-03\n",
            "  content-rank 30: check              p≈1.210429e-03\n",
            "  content-rank 31: both               p≈1.183318e-03\n",
            "  content-rank 32: instead            p≈1.062137e-03\n",
            "  content-rank 33: usually            p≈1.045231e-03\n",
            "  content-rank 34: expect             p≈9.945022e-04\n",
            "  content-rank 35: choose             p≈9.844168e-04\n",
            "  content-rank 36: audio              p≈9.584341e-04\n",
            "  content-rank 37: start              p≈9.532637e-04\n",
            "  content-rank 38: gets               p≈9.491778e-04\n",
            "  content-rank 39: take               p≈9.398748e-04\n",
            "  content-rank 40: like               p≈9.378548e-04\n",
            "  content-rank 41: select             p≈9.150188e-04\n",
            "  content-rank 42: next               p≈8.801395e-04\n",
            "  content-rank 43: says               p≈8.754116e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  content-rank 23: like               p≈1.640816e-03\n",
            "  content-rank 24: little             p≈1.581682e-03\n",
            "  content-rank 25: actually           p≈1.518363e-03\n",
            "  content-rank 26: said               p≈1.488893e-03\n",
            "  content-rank 27: whether            p≈1.460708e-03\n",
            "  content-rank 28: according          p≈1.359070e-03\n",
            "  content-rank 29: certainly          p≈1.333516e-03\n",
            "  content-rank 30: especially         p≈1.288520e-03\n",
            "  content-rank 31: despite            p≈1.172254e-03\n",
            "  content-rank 32: quite              p≈1.166855e-03\n",
            "  content-rank 33: apparently         p≈1.056976e-03\n",
            "  content-rank 34: probably           p≈1.052117e-03\n",
            "  content-rank 35: aside              p≈1.035734e-03\n",
            "  content-rank 36: says               p≈1.012583e-03\n",
            "  content-rank 37: right              p≈1.008051e-03\n",
            "  content-rank 38: maybe              p≈1.003830e-03\n",
            "  content-rank 39: obviously          p≈9.602609e-04\n",
            "  content-rank 40: instead            p≈9.083664e-04\n",
            "  content-rank 41: sir                p≈9.031835e-04\n",
            "  content-rank 42: mind               p≈8.988871e-04\n",
            "  content-rank 43: now                p≈8.827596e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 23: Everything         p≈1.206515e-04\n",
            "  content-rank 24: However            p≈1.183251e-04\n",
            "  content-rank 25: Whether            p≈1.168592e-04\n",
            "  content-rank 26: name               p≈1.163042e-04\n",
            "  content-rank 27: dll                p≈1.156132e-04\n",
            "  content-rank 28: put                p≈1.148229e-04\n",
            "  content-rank 29: list               p≈1.147538e-04\n",
            "  content-rank 30: Please             p≈1.147109e-04\n",
            "  content-rank 31: Sometimes          p≈1.124226e-04\n",
            "  content-rank 32: said               p≈1.123104e-04\n",
            "  content-rank 33: Remember           p≈1.114695e-04\n",
            "  content-rank 34: Rem                p≈1.112172e-04\n",
            "  content-rank 35: demon              p≈1.086127e-04\n",
            "  content-rank 36: asc                p≈1.069321e-04\n",
            "  content-rank 37: Come               p≈1.049078e-04\n",
            "  content-rank 38: get                p≈1.032223e-04\n",
            "  content-rank 39: Maybe              p≈1.012992e-04\n",
            "  content-rank 40: Another            p≈9.957208e-05\n",
            "  content-rank 41: put                p≈9.941116e-05\n",
            "  content-rank 42: text               p≈9.457480e-05\n",
            "  content-rank 43: Take               p≈9.084559e-05\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "=== NEW POEM (CONTENT-WINDOW FILTER) ===\n",
            "One must have a mind of language\n",
            "To regard the frost and the effect\n",
            "Of the pine-trees crusted with berries;\n",
            "And have been cold a long minute\n",
            "To behold the junipers shagged with put,\n",
            "The spruces rough in the distant twilight\n",
            "Of the January sun; and not to bring\n",
            "Of any misery in the sound of the suddenly,\n",
            "In the sound of a few voice,\n",
            "Which is the sound of the birds\n",
            "Full of the same brand\n",
            "That is blowing in the same bare shoulder\n",
            "For the listener, who listens in the take,\n",
            "And, nothing himself, obviously\n",
            "Nothing that is not there and the nothing that Maybe.\n",
            "\n",
            "Saved to: PX_poem_semantic_r23_43.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "#This script: CODE 4\n",
        "# Semantic CONTENT-WORD ranks 150–160 per line (GPT-2)\n",
        "# Variant 1: filter out function words (articles/pronouns/conjunctions/etc.)\n",
        "#\n",
        "# IMPORTANT:\n",
        "# - GPT-2 doesn't output tags, so \"nouns/verbs/adjectives\" is approximated by:\n",
        "#   (a) keep WORDLIKE tokens, (b) remove common function words via STOPWORDS + heuristics.\n",
        "# - The ranks 150–160 are computed among CONTENT-WORD candidates only.\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---- Remove last word per line (each line = one phrase) ----\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line); removed.append(last_word)\n",
        "    return new_lines, removed\n",
        "\n",
        "# ---- Word-like tokens (single \"word\") ----\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# ---- Function-word filter ----\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # (extra common function words—optional but improves “semantic” feel)\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def content_rank_window(prompt: str, tokenizer, model, start_rank: int = 150, end_rank: int = 160, max_wordlike_scan: int = 200000):\n",
        "    \"\"\"\n",
        "    Build CONTENT-WORD ranking (semantic-ish):\n",
        "    - sort all next tokens by probability\n",
        "    - keep WORDLIKE tokens\n",
        "    - keep only those passing is_content_word\n",
        "    - assign ranks among content words only\n",
        "    - return those in [start_rank, end_rank]\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# ---- Load model ----\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# ---- Run per line ----\n",
        "lines, removed = remove_last_word_per_line(poem)\n",
        "START_R, END_R = 150, 160\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(lines):\n",
        "    print(f\"{i}: {l}\")\n",
        "\n",
        "print(f\"\\n=== CONTENT-WORD ranks {START_R}–{END_R} per line ===\")\n",
        "for i, line in enumerate(lines):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = content_rank_window(\n",
        "        line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=200000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "    else:\n",
        "        for r, w, p in window:\n",
        "            print(f\"  content-rank {r:>3}: {w:<18} p≈{p:.6e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzRM9JsuftGX",
        "outputId": "f8e3f246-39b5-4a41-eee8-657b6da2266a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "0: One must have a mind of\n",
            "1: To regard the frost and the\n",
            "2: Of the pine-trees crusted with ;\n",
            "3: And have been cold a long\n",
            "4: To behold the junipers shagged with ,\n",
            "5: The spruces rough in the distant\n",
            "6: Of the January sun; and not to\n",
            "7: Of any misery in the sound of the ,\n",
            "8: In the sound of a few ,\n",
            "9: Which is the sound of the\n",
            "10: Full of the same\n",
            "11: That is blowing in the same bare\n",
            "12: For the listener, who listens in the ,\n",
            "13: And, nothing himself,\n",
            "14: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== CONTENT-WORD ranks 150–160 per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 0 prompt: 'One must have a mind of'\n",
            "  content-rank 150: clear              p≈2.116131e-04\n",
            "  content-rank 151: proportion         p≈2.112066e-04\n",
            "  content-rank 152: open               p≈2.061693e-04\n",
            "  content-rank 153: personal           p≈2.041018e-04\n",
            "  content-rank 154: communication      p≈2.028661e-04\n",
            "  content-rank 155: prophecy           p≈2.015056e-04\n",
            "  content-rank 156: honesty            p≈1.996585e-04\n",
            "  content-rank 157: new                p≈1.989924e-04\n",
            "  content-rank 158: terror             p≈1.989317e-04\n",
            "  content-rank 159: like               p≈1.988588e-04\n",
            "  content-rank 160: certain            p≈1.983891e-04\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'To regard the frost and the'\n",
            "  content-rank 150: river              p≈7.310907e-04\n",
            "  content-rank 151: magic              p≈7.309847e-04\n",
            "  content-rank 152: arrows             p≈7.268804e-04\n",
            "  content-rank 153: changes            p≈7.264868e-04\n",
            "  content-rank 154: final              p≈7.260712e-04\n",
            "  content-rank 155: inf                p≈7.223637e-04\n",
            "  content-rank 156: silence            p≈7.206242e-04\n",
            "  content-rank 157: sharp              p≈7.159061e-04\n",
            "  content-rank 158: end                p≈7.133218e-04\n",
            "  content-rank 159: evil               p≈7.125930e-04\n",
            "  content-rank 160: imp                p≈7.125712e-04\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 150: fruit              p≈2.902135e-04\n",
            "  content-rank 151: leaf               p≈2.883442e-04\n",
            "  content-rank 152: certain            p≈2.879507e-04\n",
            "  content-rank 153: names              p≈2.878452e-04\n",
            "  content-rank 154: pear               p≈2.844830e-04\n",
            "  content-rank 155: roses              p≈2.840146e-04\n",
            "  content-rank 156: gre                p≈2.803077e-04\n",
            "  content-rank 157: plant              p≈2.800854e-04\n",
            "  content-rank 158: anything           p≈2.788125e-04\n",
            "  content-rank 159: who                p≈2.778675e-04\n",
            "  content-rank 160: put                p≈2.777129e-04\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'And have been cold a long'\n",
            "  content-rank 150: growing            p≈8.817743e-06\n",
            "  content-rank 151: black              p≈8.784103e-06\n",
            "  content-rank 152: beating            p≈8.776399e-06\n",
            "  content-rank 153: handful            p≈8.671868e-06\n",
            "  content-rank 154: range              p≈8.620153e-06\n",
            "  content-rank 155: sorry              p≈8.620120e-06\n",
            "  content-rank 156: holiday            p≈8.588544e-06\n",
            "  content-rank 157: like               p≈8.429080e-06\n",
            "  content-rank 158: gone               p≈8.382584e-06\n",
            "  content-rank 159: thousand           p≈8.319477e-06\n",
            "  content-rank 160: state              p≈8.317510e-06\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 150: nearly             p≈2.414468e-04\n",
            "  content-rank 151: sharp              p≈2.390056e-04\n",
            "  content-rank 152: shot               p≈2.353738e-04\n",
            "  content-rank 153: glass              p≈2.342666e-04\n",
            "  content-rank 154: signs              p≈2.336615e-04\n",
            "  content-rank 155: thus               p≈2.336472e-04\n",
            "  content-rank 156: thunder            p≈2.317971e-04\n",
            "  content-rank 157: give               p≈2.272583e-04\n",
            "  content-rank 158: wood               p≈2.231724e-04\n",
            "  content-rank 159: arms               p≈2.226095e-04\n",
            "  content-rank 160: come               p≈2.212735e-04\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 150: tree               p≈8.241981e-04\n",
            "  content-rank 151: gloom              p≈8.230293e-04\n",
            "  content-rank 152: mist               p≈8.124732e-04\n",
            "  content-rank 153: bow                p≈8.033385e-04\n",
            "  content-rank 154: areas              p≈8.006706e-04\n",
            "  content-rank 155: road               p≈7.734240e-04\n",
            "  content-rank 156: rocks              p≈7.725336e-04\n",
            "  content-rank 157: street             p≈7.716676e-04\n",
            "  content-rank 158: fire               p≈7.673174e-04\n",
            "  content-rank 159: purple             p≈7.580250e-04\n",
            "  content-rank 160: next               p≈7.506127e-04\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 150: fright             p≈5.939722e-04\n",
            "  content-rank 151: seem               p≈5.932431e-04\n",
            "  content-rank 152: hope               p≈5.908716e-04\n",
            "  content-rank 153: despise            p≈5.878097e-04\n",
            "  content-rank 154: smoke              p≈5.864569e-04\n",
            "  content-rank 155: laugh              p≈5.690991e-04\n",
            "  content-rank 156: celebrate          p≈5.661629e-04\n",
            "  content-rank 157: reflect            p≈5.628123e-04\n",
            "  content-rank 158: end                p≈5.606095e-04\n",
            "  content-rank 159: wear               p≈5.604555e-04\n",
            "  content-rank 160: help               p≈5.600752e-04\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 150: next               p≈2.142303e-04\n",
            "  content-rank 151: drop               p≈2.132779e-04\n",
            "  content-rank 152: till               p≈2.129706e-04\n",
            "  content-rank 153: said               p≈2.101990e-04\n",
            "  content-rank 154: door               p≈2.098208e-04\n",
            "  content-rank 155: syll               p≈2.094561e-04\n",
            "  content-rank 156: note               p≈2.092868e-04\n",
            "  content-rank 157: read               p≈2.079594e-04\n",
            "  content-rank 158: low                p≈2.051481e-04\n",
            "  content-rank 159: name               p≈2.048540e-04\n",
            "  content-rank 160: following          p≈2.041644e-04\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'In the sound of a few ,'\n",
            "  content-rank 150: quite              p≈2.083779e-04\n",
            "  content-rank 151: cut                p≈2.075481e-04\n",
            "  content-rank 152: note               p≈2.069962e-04\n",
            "  content-rank 153: various            p≈2.066774e-04\n",
            "  content-rank 154: usually            p≈2.045565e-04\n",
            "  content-rank 155: come               p≈2.009830e-04\n",
            "  content-rank 156: local              p≈1.990967e-04\n",
            "  content-rank 157: notes              p≈1.960099e-04\n",
            "  content-rank 158: think              p≈1.957141e-04\n",
            "  content-rank 159: moments            p≈1.948366e-04\n",
            "  content-rank 160: white              p≈1.939808e-04\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'Which is the sound of the'\n",
            "  content-rank 150: bomb               p≈8.750494e-04\n",
            "  content-rank 151: pipe               p≈8.707540e-04\n",
            "  content-rank 152: street             p≈8.695855e-04\n",
            "  content-rank 153: gunshots           p≈8.687764e-04\n",
            "  content-rank 154: waters             p≈8.648151e-04\n",
            "  content-rank 155: falling            p≈8.614501e-04\n",
            "  content-rank 156: baby               p≈8.594676e-04\n",
            "  content-rank 157: elevator           p≈8.589759e-04\n",
            "  content-rank 158: breeze             p≈8.541791e-04\n",
            "  content-rank 159: white              p≈8.371212e-04\n",
            "  content-rank 160: moment             p≈8.358512e-04\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Full of the same'\n",
            "  content-rank 150: vintage            p≈6.356910e-04\n",
            "  content-rank 151: film               p≈6.321315e-04\n",
            "  content-rank 152: two                p≈6.290621e-04\n",
            "  content-rank 153: liquid             p≈6.272505e-04\n",
            "  content-rank 154: scope              p≈6.266621e-04\n",
            "  content-rank 155: look               p≈6.265904e-04\n",
            "  content-rank 156: skin               p≈6.255634e-04\n",
            "  content-rank 157: goes               p≈6.236002e-04\n",
            "  content-rank 158: hair               p≈6.217000e-04\n",
            "  content-rank 159: picture            p≈6.214535e-04\n",
            "  content-rank 160: metal              p≈6.166220e-04\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 150: color              p≈7.760141e-04\n",
            "  content-rank 151: scale              p≈7.741809e-04\n",
            "  content-rank 152: darkness           p≈7.723874e-04\n",
            "  content-rank 153: side               p≈7.475392e-04\n",
            "  content-rank 154: path               p≈7.356521e-04\n",
            "  content-rank 155: fist               p≈7.328345e-04\n",
            "  content-rank 156: shade              p≈7.303673e-04\n",
            "  content-rank 157: walls              p≈7.282307e-04\n",
            "  content-rank 158: little             p≈7.128607e-04\n",
            "  content-rank 159: shadow             p≈7.093885e-04\n",
            "  content-rank 160: sand               p≈7.049858e-04\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 150: input              p≈2.849209e-04\n",
            "  content-rank 151: back               p≈2.831700e-04\n",
            "  content-rank 152: runs               p≈2.821650e-04\n",
            "  content-rank 153: ask                p≈2.790543e-04\n",
            "  content-rank 154: left               p≈2.779473e-04\n",
            "  content-rank 155: maybe              p≈2.777099e-04\n",
            "  content-rank 156: test               p≈2.749817e-04\n",
            "  content-rank 157: inspect            p≈2.747049e-04\n",
            "  content-rank 158: stream             p≈2.742798e-04\n",
            "  content-rank 159: perform            p≈2.731500e-04\n",
            "  content-rank 160: sort               p≈2.707722e-04\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'And, nothing himself,'\n",
            "  content-rank 150: free               p≈1.521024e-04\n",
            "  content-rank 151: honestly           p≈1.515695e-04\n",
            "  content-rank 152: true               p≈1.492606e-04\n",
            "  content-rank 153: three              p≈1.466330e-04\n",
            "  content-rank 154: Michael            p≈1.451592e-04\n",
            "  content-rank 155: basically          p≈1.436280e-04\n",
            "  content-rank 156: Thomas             p≈1.424016e-04\n",
            "  content-rank 157: mere               p≈1.418431e-04\n",
            "  content-rank 158: somehow            p≈1.410005e-04\n",
            "  content-rank 159: Professor          p≈1.396217e-04\n",
            "  content-rank 160: thanks             p≈1.392154e-04\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 150: wav                p≈3.226620e-05\n",
            "  content-rank 151: Except             p≈3.216666e-05\n",
            "  content-rank 152: info               p≈3.211222e-05\n",
            "  content-rank 153: close              p≈3.147574e-05\n",
            "  content-rank 154: Tell               p≈3.116177e-05\n",
            "  content-rank 155: Obviously          p≈3.111995e-05\n",
            "  content-rank 156: List               p≈3.071519e-05\n",
            "  content-rank 157: isn                p≈3.064964e-05\n",
            "  content-rank 158: Find               p≈3.052503e-05\n",
            "  content-rank 159: Suppose            p≈3.025192e-05\n",
            "  content-rank 160: David              p≈3.023853e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ranks 150–160 per line (GPT-2)\n",
        "# Choose by CONTENT-RANK number (150..160)\n",
        "# Rebuild line correctly (word BEFORE punctuation)\n",
        "# Save to PX_poem_r150_160.txt\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Split each line into: before + last_word + trailing punctuation\n",
        "#    Build prompts like your original: prompt = before + trailing\n",
        "# -----------------------------------------------------\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(prompts_lines, start=1):\n",
        "    print(f\"Line {i}: {l}\")\n",
        "\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Word-like + stopword filter (semantic-ish)\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # extra common function words\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Content-rank window 150..160 (among content words only)\n",
        "# -----------------------------------------------------\n",
        "def content_rank_window(prompt: str, tokenizer, model, start_rank: int = 150, end_rank: int = 160, max_wordlike_scan: int = 200000):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Load model\n",
        "# -----------------------------------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive: choose by CONTENT-RANK number 150..160\n",
        "# -----------------------------------------------------\n",
        "START_R, END_R = 150, 160\n",
        "new_lines = []\n",
        "\n",
        "print(f\"\\n=== Choose by CONTENT-RANK number ({START_R}–{END_R}) ===\")\n",
        "\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = content_rank_window(\n",
        "        prompt_line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=200000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "        # fallback: keep original line\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    # show all available ranks in 150..160\n",
        "    rank_to_word = {}\n",
        "    for r, w, p in window:\n",
        "        rank_to_word[r] = (w, p)\n",
        "        print(f\"  content-rank {r:>3}: {w:<18} p≈{p:.6e}\")\n",
        "\n",
        "    valid_ranks = sorted(rank_to_word.keys())\n",
        "\n",
        "    while True:\n",
        "        raw = input(f\"Type the CONTENT-RANK you want ({START_R}–{END_R}): \").strip()\n",
        "        if raw.isdigit():\n",
        "            chosen_rank = int(raw)\n",
        "            if chosen_rank in rank_to_word:\n",
        "                chosen_word = rank_to_word[chosen_rank][0]\n",
        "                break\n",
        "        print(f\"Invalid. Choose one of these ranks: {valid_ranks}\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (CONTENT-RANK 150–160 WINDOW) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"PX_poem_semantic_r150_160.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRIFHicsBjz9",
        "outputId": "51f46262-cd83-4e8a-8dff-a2df5e655d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "Line 1: One must have a mind of\n",
            "Line 2: To regard the frost and the\n",
            "Line 3: Of the pine-trees crusted with ;\n",
            "Line 4: And have been cold a long\n",
            "Line 5: To behold the junipers shagged with ,\n",
            "Line 6: The spruces rough in the distant\n",
            "Line 7: Of the January sun; and not to\n",
            "Line 8: Of any misery in the sound of the ,\n",
            "Line 9: In the sound of a few ,\n",
            "Line 10: Which is the sound of the\n",
            "Line 11: Full of the same\n",
            "Line 12: That is blowing in the same bare\n",
            "Line 13: For the listener, who listens in the ,\n",
            "Line 14: And, nothing himself,\n",
            "Line 15: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== Choose by CONTENT-RANK number (150–160) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  content-rank 150: clear              p≈2.116131e-04\n",
            "  content-rank 151: proportion         p≈2.112066e-04\n",
            "  content-rank 152: open               p≈2.061693e-04\n",
            "  content-rank 153: personal           p≈2.041018e-04\n",
            "  content-rank 154: communication      p≈2.028661e-04\n",
            "  content-rank 155: prophecy           p≈2.015056e-04\n",
            "  content-rank 156: honesty            p≈1.996585e-04\n",
            "  content-rank 157: new                p≈1.989924e-04\n",
            "  content-rank 158: terror             p≈1.989317e-04\n",
            "  content-rank 159: like               p≈1.988588e-04\n",
            "  content-rank 160: certain            p≈1.983891e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  content-rank 150: river              p≈7.310907e-04\n",
            "  content-rank 151: magic              p≈7.309847e-04\n",
            "  content-rank 152: arrows             p≈7.268804e-04\n",
            "  content-rank 153: changes            p≈7.264868e-04\n",
            "  content-rank 154: final              p≈7.260712e-04\n",
            "  content-rank 155: inf                p≈7.223637e-04\n",
            "  content-rank 156: silence            p≈7.206242e-04\n",
            "  content-rank 157: sharp              p≈7.159061e-04\n",
            "  content-rank 158: end                p≈7.133218e-04\n",
            "  content-rank 159: evil               p≈7.125930e-04\n",
            "  content-rank 160: imp                p≈7.125712e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 150: fruit              p≈2.902135e-04\n",
            "  content-rank 151: leaf               p≈2.883442e-04\n",
            "  content-rank 152: certain            p≈2.879507e-04\n",
            "  content-rank 153: names              p≈2.878452e-04\n",
            "  content-rank 154: pear               p≈2.844830e-04\n",
            "  content-rank 155: roses              p≈2.840146e-04\n",
            "  content-rank 156: gre                p≈2.803077e-04\n",
            "  content-rank 157: plant              p≈2.800854e-04\n",
            "  content-rank 158: anything           p≈2.788125e-04\n",
            "  content-rank 159: who                p≈2.778675e-04\n",
            "  content-rank 160: put                p≈2.777129e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  content-rank 150: growing            p≈8.817743e-06\n",
            "  content-rank 151: black              p≈8.784103e-06\n",
            "  content-rank 152: beating            p≈8.776399e-06\n",
            "  content-rank 153: handful            p≈8.671868e-06\n",
            "  content-rank 154: range              p≈8.620153e-06\n",
            "  content-rank 155: sorry              p≈8.620120e-06\n",
            "  content-rank 156: holiday            p≈8.588544e-06\n",
            "  content-rank 157: like               p≈8.429080e-06\n",
            "  content-rank 158: gone               p≈8.382584e-06\n",
            "  content-rank 159: thousand           p≈8.319477e-06\n",
            "  content-rank 160: state              p≈8.317510e-06\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 150: nearly             p≈2.414468e-04\n",
            "  content-rank 151: sharp              p≈2.390056e-04\n",
            "  content-rank 152: shot               p≈2.353738e-04\n",
            "  content-rank 153: glass              p≈2.342666e-04\n",
            "  content-rank 154: signs              p≈2.336615e-04\n",
            "  content-rank 155: thus               p≈2.336472e-04\n",
            "  content-rank 156: thunder            p≈2.317971e-04\n",
            "  content-rank 157: give               p≈2.272583e-04\n",
            "  content-rank 158: wood               p≈2.231724e-04\n",
            "  content-rank 159: arms               p≈2.226095e-04\n",
            "  content-rank 160: come               p≈2.212735e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 150: tree               p≈8.241981e-04\n",
            "  content-rank 151: gloom              p≈8.230293e-04\n",
            "  content-rank 152: mist               p≈8.124732e-04\n",
            "  content-rank 153: bow                p≈8.033385e-04\n",
            "  content-rank 154: areas              p≈8.006706e-04\n",
            "  content-rank 155: road               p≈7.734240e-04\n",
            "  content-rank 156: rocks              p≈7.725336e-04\n",
            "  content-rank 157: street             p≈7.716676e-04\n",
            "  content-rank 158: fire               p≈7.673174e-04\n",
            "  content-rank 159: purple             p≈7.580250e-04\n",
            "  content-rank 160: next               p≈7.506127e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 150: fright             p≈5.939722e-04\n",
            "  content-rank 151: seem               p≈5.932431e-04\n",
            "  content-rank 152: hope               p≈5.908716e-04\n",
            "  content-rank 153: despise            p≈5.878097e-04\n",
            "  content-rank 154: smoke              p≈5.864569e-04\n",
            "  content-rank 155: laugh              p≈5.690991e-04\n",
            "  content-rank 156: celebrate          p≈5.661629e-04\n",
            "  content-rank 157: reflect            p≈5.628123e-04\n",
            "  content-rank 158: end                p≈5.606095e-04\n",
            "  content-rank 159: wear               p≈5.604555e-04\n",
            "  content-rank 160: help               p≈5.600752e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 150: next               p≈2.142303e-04\n",
            "  content-rank 151: drop               p≈2.132779e-04\n",
            "  content-rank 152: till               p≈2.129706e-04\n",
            "  content-rank 153: said               p≈2.101990e-04\n",
            "  content-rank 154: door               p≈2.098208e-04\n",
            "  content-rank 155: syll               p≈2.094561e-04\n",
            "  content-rank 156: note               p≈2.092868e-04\n",
            "  content-rank 157: read               p≈2.079594e-04\n",
            "  content-rank 158: low                p≈2.051481e-04\n",
            "  content-rank 159: name               p≈2.048540e-04\n",
            "  content-rank 160: following          p≈2.041644e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  content-rank 150: quite              p≈2.083779e-04\n",
            "  content-rank 151: cut                p≈2.075481e-04\n",
            "  content-rank 152: note               p≈2.069962e-04\n",
            "  content-rank 153: various            p≈2.066774e-04\n",
            "  content-rank 154: usually            p≈2.045565e-04\n",
            "  content-rank 155: come               p≈2.009830e-04\n",
            "  content-rank 156: local              p≈1.990967e-04\n",
            "  content-rank 157: notes              p≈1.960099e-04\n",
            "  content-rank 158: think              p≈1.957141e-04\n",
            "  content-rank 159: moments            p≈1.948366e-04\n",
            "  content-rank 160: white              p≈1.939808e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  content-rank 150: bomb               p≈8.750494e-04\n",
            "  content-rank 151: pipe               p≈8.707540e-04\n",
            "  content-rank 152: street             p≈8.695855e-04\n",
            "  content-rank 153: gunshots           p≈8.687764e-04\n",
            "  content-rank 154: waters             p≈8.648151e-04\n",
            "  content-rank 155: falling            p≈8.614501e-04\n",
            "  content-rank 156: baby               p≈8.594676e-04\n",
            "  content-rank 157: elevator           p≈8.589759e-04\n",
            "  content-rank 158: breeze             p≈8.541791e-04\n",
            "  content-rank 159: white              p≈8.371212e-04\n",
            "  content-rank 160: moment             p≈8.358512e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  content-rank 150: vintage            p≈6.356910e-04\n",
            "  content-rank 151: film               p≈6.321315e-04\n",
            "  content-rank 152: two                p≈6.290621e-04\n",
            "  content-rank 153: liquid             p≈6.272505e-04\n",
            "  content-rank 154: scope              p≈6.266621e-04\n",
            "  content-rank 155: look               p≈6.265904e-04\n",
            "  content-rank 156: skin               p≈6.255634e-04\n",
            "  content-rank 157: goes               p≈6.236002e-04\n",
            "  content-rank 158: hair               p≈6.217000e-04\n",
            "  content-rank 159: picture            p≈6.214535e-04\n",
            "  content-rank 160: metal              p≈6.166220e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 150: color              p≈7.760141e-04\n",
            "  content-rank 151: scale              p≈7.741809e-04\n",
            "  content-rank 152: darkness           p≈7.723874e-04\n",
            "  content-rank 153: side               p≈7.475392e-04\n",
            "  content-rank 154: path               p≈7.356521e-04\n",
            "  content-rank 155: fist               p≈7.328345e-04\n",
            "  content-rank 156: shade              p≈7.303673e-04\n",
            "  content-rank 157: walls              p≈7.282307e-04\n",
            "  content-rank 158: little             p≈7.128607e-04\n",
            "  content-rank 159: shadow             p≈7.093885e-04\n",
            "  content-rank 160: sand               p≈7.049858e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 150: input              p≈2.849209e-04\n",
            "  content-rank 151: back               p≈2.831700e-04\n",
            "  content-rank 152: runs               p≈2.821650e-04\n",
            "  content-rank 153: ask                p≈2.790543e-04\n",
            "  content-rank 154: left               p≈2.779473e-04\n",
            "  content-rank 155: maybe              p≈2.777099e-04\n",
            "  content-rank 156: test               p≈2.749817e-04\n",
            "  content-rank 157: inspect            p≈2.747049e-04\n",
            "  content-rank 158: stream             p≈2.742798e-04\n",
            "  content-rank 159: perform            p≈2.731500e-04\n",
            "  content-rank 160: sort               p≈2.707722e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  content-rank 150: free               p≈1.521024e-04\n",
            "  content-rank 151: honestly           p≈1.515695e-04\n",
            "  content-rank 152: true               p≈1.492606e-04\n",
            "  content-rank 153: three              p≈1.466330e-04\n",
            "  content-rank 154: Michael            p≈1.451592e-04\n",
            "  content-rank 155: basically          p≈1.436280e-04\n",
            "  content-rank 156: Thomas             p≈1.424016e-04\n",
            "  content-rank 157: mere               p≈1.418431e-04\n",
            "  content-rank 158: somehow            p≈1.410005e-04\n",
            "  content-rank 159: Professor          p≈1.396217e-04\n",
            "  content-rank 160: thanks             p≈1.392154e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 150: wav                p≈3.226620e-05\n",
            "  content-rank 151: Except             p≈3.216666e-05\n",
            "  content-rank 152: info               p≈3.211222e-05\n",
            "  content-rank 153: close              p≈3.147574e-05\n",
            "  content-rank 154: Tell               p≈3.116177e-05\n",
            "  content-rank 155: Obviously          p≈3.111995e-05\n",
            "  content-rank 156: List               p≈3.071519e-05\n",
            "  content-rank 157: isn                p≈3.064964e-05\n",
            "  content-rank 158: Find               p≈3.052503e-05\n",
            "  content-rank 159: Suppose            p≈3.025192e-05\n",
            "  content-rank 160: David              p≈3.023853e-05\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "=== NEW POEM (CONTENT-RANK 150–160 WINDOW) ===\n",
            "One must have a mind of communication\n",
            "To regard the frost and the final\n",
            "Of the pine-trees crusted with pear;\n",
            "And have been cold a long range\n",
            "To behold the junipers shagged with signs,\n",
            "The spruces rough in the distant areas\n",
            "Of the January sun; and not to smoke\n",
            "Of any misery in the sound of the door,\n",
            "In the sound of a few usually,\n",
            "Which is the sound of the waters\n",
            "Full of the same scope\n",
            "That is blowing in the same bare path\n",
            "For the listener, who listens in the left,\n",
            "And, nothing himself, Michael\n",
            "Nothing that is not there and the nothing that Tell.\n",
            "\n",
            "Saved to: PX_poem_semantic_r150_160.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# P+7 NOUN REPLACER — STRICT “COMPLETE NOUN WORDS”\n",
        "# - candidate must start a new word (token begins with space)\n",
        "# - candidate must be NOUN/PROPN in CONTEXT (spaCy)\n",
        "# - candidate must match singular/plural in CONTEXT\n",
        "# - candidate must be a common enough word (wordfreq)\n",
        "# - prints ranks 1..7\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch spacy wordfreq\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "import re\n",
        "import torch\n",
        "import spacy\n",
        "from wordfreq import zipf_frequency\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste your poem/text here ----\n",
        "text = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "WORDLIKE = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "VOWEL = re.compile(r\"[aeiouy]\", re.IGNORECASE)\n",
        "\n",
        "STOPWORDS = {\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"over\",\"under\",\n",
        "    \"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"have\",\"has\",\"had\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"also\",\"just\",\"only\",\"even\",\"then\",\"there\",\"here\",\"as\"\n",
        "}\n",
        "\n",
        "def next_token_probs(prompt: str):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    return torch.softmax(logits, dim=-1)\n",
        "\n",
        "def noun_number(tok) -> str:\n",
        "    nums = tok.morph.get(\"Number\")\n",
        "    return nums[0] if nums else \"\"  # 'Sing'/'Plur'/''\n",
        "\n",
        "def match_capitalization(src: str, cand: str) -> str:\n",
        "    if src.isupper(): return cand.upper()\n",
        "    if src.istitle(): return cand.capitalize()\n",
        "    return cand.lower() if src.islower() else cand\n",
        "\n",
        "def candidate_is_noun_in_context(context: str, piece: str):\n",
        "    \"\"\"\n",
        "    Check POS + number of the LAST token when appending piece to context.\n",
        "    \"\"\"\n",
        "    doc = nlp(context + piece)\n",
        "    if not doc:\n",
        "        return False, \"\", \"\"\n",
        "    last = doc[-1]\n",
        "    return (last.pos_ in {\"NOUN\",\"PROPN\"}), noun_number(last), last.text\n",
        "\n",
        "def is_common_enough(word: str, min_zipf: float = 3.0) -> bool:\n",
        "    \"\"\"\n",
        "    zipf_frequency ~ 3.0 = reasonably common word\n",
        "    Raise to 3.5/4.0 if you want to be stricter.\n",
        "    \"\"\"\n",
        "    return zipf_frequency(word.lower(), \"en\") >= min_zipf\n",
        "\n",
        "def top7_complete_noun_candidates(context: str, target_number: str, k: int = 7,\n",
        "                                 min_zipf: float = 3.0, overscan: int = 200000):\n",
        "    probs = next_token_probs(context)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])  # keep raw (may start with space)\n",
        "\n",
        "        # Require NEW WORD boundary once we have context\n",
        "        if context.strip() != \"\" and not piece.startswith(\" \"):\n",
        "            continue\n",
        "\n",
        "        cand = piece.strip()\n",
        "        if not cand:\n",
        "            continue\n",
        "\n",
        "        # Word-shape filters\n",
        "        if not WORDLIKE.match(cand):\n",
        "            continue\n",
        "        if len(cand) < 3:\n",
        "            continue\n",
        "        if not VOWEL.search(cand):         # kills many fragments like \"ut\", \"cwm\"-like chunks\n",
        "            continue\n",
        "        if cand.lower() in STOPWORDS:\n",
        "            continue\n",
        "        if cand.lower() in seen:\n",
        "            continue\n",
        "\n",
        "        # Must be a noun when placed in context\n",
        "        ok, cand_num, last_text = candidate_is_noun_in_context(context, piece)\n",
        "        if not ok:\n",
        "            continue\n",
        "\n",
        "        # Must match number if available\n",
        "        if target_number in {\"Sing\",\"Plur\"} and cand_num != target_number:\n",
        "            continue\n",
        "\n",
        "        # Must be a common enough English word\n",
        "        if not is_common_enough(cand, min_zipf=min_zipf):\n",
        "            continue\n",
        "\n",
        "        seen.add(cand.lower())\n",
        "        out.append((cand, float(probs[tid].cpu()), cand_num, zipf_frequency(cand.lower(), \"en\")))\n",
        "\n",
        "        if len(out) == k:\n",
        "            break\n",
        "\n",
        "        if len(seen) > overscan:\n",
        "            break\n",
        "\n",
        "    return out\n",
        "\n",
        "def p7_replace_nouns_strict(text: str, k: int = 7, min_zipf: float = 3.0):\n",
        "    doc = nlp(text)\n",
        "    out = []\n",
        "    context = \"\"\n",
        "\n",
        "    for tok in doc:\n",
        "        src = tok.text\n",
        "        ws = tok.whitespace_\n",
        "\n",
        "        if tok.pos_ in {\"NOUN\",\"PROPN\"} and src.strip():\n",
        "            target_num = noun_number(tok)\n",
        "\n",
        "            cands = top7_complete_noun_candidates(\n",
        "                context,\n",
        "                target_number=target_num,\n",
        "                k=k,\n",
        "                min_zipf=min_zipf\n",
        "            )\n",
        "\n",
        "            print(\"\\n\" + \"=\"*85)\n",
        "            print(f\"NOUN FOUND: '{src}'   (target Number={target_num or 'Unknown'})\")\n",
        "            print(\"Top-7 COMPLETE NOUN candidates (rank 1→7):\")\n",
        "            for i, (w, p, num, z) in enumerate(cands, start=1):\n",
        "                print(f\"  {i}. {w:<18} p≈{p:.6f}   (Number={num or 'Unknown'}, zipf={z:.2f})\")\n",
        "\n",
        "            if len(cands) >= k:\n",
        "                chosen = match_capitalization(src, cands[k-1][0])\n",
        "                print(f\"→ P+{k} chosen replacement: {chosen}\")\n",
        "            else:\n",
        "                chosen = src\n",
        "                print(f\"→ Only found {len(cands)} valid candidates; keeping original.\")\n",
        "\n",
        "            out.append(chosen + ws)\n",
        "            context += chosen + ws\n",
        "        else:\n",
        "            out.append(src + ws)\n",
        "            context += src + ws\n",
        "\n",
        "    return \"\".join(out)\n",
        "\n",
        "# ---- Run ----\n",
        "mutated = p7_replace_nouns_strict(text, k=7, min_zipf=3.0)\n",
        "\n",
        "print(\"\\n=== ORIGINAL ===\")\n",
        "print(text)\n",
        "print(\"\\n=== P+7 NOUN MUTATION (STRICT) ===\")\n",
        "print(mutated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BG_K6GOOONl",
        "outputId": "2aaa34f7-2eff-4443-b173-2473be75fc32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Using device: cuda\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'mind'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. Reply              p≈0.000014   (Number=Sing, zipf=4.50)\n",
            "  2. kind               p≈0.000010   (Number=Sing, zipf=5.45)\n",
            "  3. Pond               p≈0.000009   (Number=Sing, zipf=3.98)\n",
            "  4. IST                p≈0.000009   (Number=Sing, zipf=3.35)\n",
            "  5. today              p≈0.000008   (Number=Sing, zipf=5.55)\n",
            "  6. fucking            p≈0.000008   (Number=Sing, zipf=5.33)\n",
            "  7. thinking           p≈0.000008   (Number=Sing, zipf=5.24)\n",
            "→ P+7 chosen replacement: thinking\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'winter'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. nature             p≈0.000047   (Number=Sing, zipf=4.98)\n",
            "  2. Reply              p≈0.000046   (Number=Sing, zipf=4.50)\n",
            "  3. kind               p≈0.000025   (Number=Sing, zipf=5.45)\n",
            "  4. Major              p≈0.000013   (Number=Sing, zipf=5.30)\n",
            "  5. Salman             p≈0.000013   (Number=Sing, zipf=3.34)\n",
            "  6. Hook               p≈0.000012   (Number=Sing, zipf=4.37)\n",
            "  7. Hutchinson         p≈0.000012   (Number=Sing, zipf=3.42)\n",
            "→ P+7 chosen replacement: hutchinson\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'frost'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. Hutchinson         p≈0.000063   (Number=Sing, zipf=3.42)\n",
            "  2. Pond               p≈0.000022   (Number=Sing, zipf=3.98)\n",
            "  3. helpless           p≈0.000021   (Number=Sing, zipf=3.69)\n",
            "  4. slippery           p≈0.000016   (Number=Sing, zipf=3.61)\n",
            "  5. Reply              p≈0.000015   (Number=Sing, zipf=4.50)\n",
            "  6. Russell            p≈0.000014   (Number=Sing, zipf=4.33)\n",
            "  7. mart               p≈0.000014   (Number=Sing, zipf=3.69)\n",
            "→ P+7 chosen replacement: mart\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'boughs'   (target Number=Plur)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. kinds              p≈0.000003   (Number=Plur, zipf=4.51)\n",
            "  2. lives              p≈0.000002   (Number=Plur, zipf=5.14)\n",
            "  3. Riders             p≈0.000002   (Number=Plur, zipf=3.99)\n",
            "  4. ropes              p≈0.000002   (Number=Plur, zipf=3.66)\n",
            "  5. men                p≈0.000002   (Number=Plur, zipf=5.51)\n",
            "  6. Moines             p≈0.000002   (Number=Plur, zipf=3.39)\n",
            "  7. charges            p≈0.000002   (Number=Plur, zipf=4.68)\n",
            "→ P+7 chosen replacement: charges\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'pine'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. mart               p≈0.000108   (Number=Sing, zipf=3.69)\n",
            "  2. Hutchinson         p≈0.000010   (Number=Sing, zipf=3.42)\n",
            "  3. Negro              p≈0.000008   (Number=Sing, zipf=3.73)\n",
            "  4. Pond               p≈0.000007   (Number=Sing, zipf=3.98)\n",
            "  5. Reply              p≈0.000007   (Number=Sing, zipf=4.50)\n",
            "  6. Institution        p≈0.000007   (Number=Sing, zipf=4.41)\n",
            "  7. helpless           p≈0.000006   (Number=Sing, zipf=3.69)\n",
            "→ P+7 chosen replacement: helpless\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'trees'   (target Number=Plur)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. men                p≈0.001131   (Number=Plur, zipf=5.51)\n",
            "  2. bodies             p≈0.000572   (Number=Plur, zipf=4.69)\n",
            "  3. people             p≈0.000402   (Number=Plur, zipf=6.25)\n",
            "  4. children           p≈0.000336   (Number=Plur, zipf=5.47)\n",
            "  5. prisoners          p≈0.000328   (Number=Plur, zipf=4.37)\n",
            "  6. creatures          p≈0.000242   (Number=Plur, zipf=4.21)\n",
            "  7. selves             p≈0.000222   (Number=Plur, zipf=3.42)\n",
            "→ P+7 chosen replacement: selves\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'snow'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. mart               p≈0.000009   (Number=Sing, zipf=3.69)\n",
            "  2. powder             p≈0.000009   (Number=Sing, zipf=4.25)\n",
            "  3. tal                p≈0.000008   (Number=Sing, zipf=3.26)\n",
            "  4. wax                p≈0.000006   (Number=Sing, zipf=3.92)\n",
            "  5. Hutchinson         p≈0.000006   (Number=Sing, zipf=3.42)\n",
            "  6. Reply              p≈0.000006   (Number=Sing, zipf=4.50)\n",
            "  7. ric                p≈0.000006   (Number=Sing, zipf=3.14)\n",
            "→ P+7 chosen replacement: ric\n",
            "\n",
            "=====================================================================================\n",
            "NOUN FOUND: 'time'   (target Number=Sing)\n",
            "Top-7 COMPLETE NOUN candidates (rank 1→7):\n",
            "  1. Hutchinson         p≈0.000038   (Number=Sing, zipf=3.42)\n",
            "  2. mist               p≈0.000021   (Number=Sing, zipf=3.67)\n",
            "  3. mart               p≈0.000019   (Number=Sing, zipf=3.69)\n",
            "  4. Institution        p≈0.000015   (Number=Sing, zipf=4.41)\n",
            "  5. nature             p≈0.000014   (Number=Sing, zipf=4.98)\n",
            "  6. aug                p≈0.000012   (Number=Sing, zipf=4.33)\n",
            "  7. tha                p≈0.000011   (Number=Sing, zipf=3.62)\n",
            "→ P+7 chosen replacement: tha\n",
            "\n",
            "=== ORIGINAL ===\n",
            "One must have a mind of winter\n",
            "To regard the frost and the boughs\n",
            "Of the pine-trees crusted with snow;\n",
            "And have been cold a long time\n",
            "\n",
            "=== P+7 NOUN MUTATION (STRICT) ===\n",
            "One must have a thinking of hutchinson\n",
            "To regard the mart and the charges\n",
            "Of the helpless-selves crusted with ric;\n",
            "And have been cold a long tha\n"
          ]
        }
      ]
    }
  ]
}