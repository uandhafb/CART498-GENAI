{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aacsl2leO090",
        "outputId": "1c965505-8805-4fdd-da33-2984d06f1b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Original ===\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá;\n",
            "As aves, que aqui gorjeiam,\n",
            "Não gorjeiam como lá.\n",
            "\n",
            "Nosso céu tem mais estrelas,\n",
            "Nossas várzeas têm mais flores,\n",
            "Nossos bosques têm mais vida,\n",
            "Nossa vida mais amores.\n",
            "\n",
            "Em  cismar, sozinho, à noite,\n",
            "Mais prazer eu encontro lá;\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá.\n",
            "\n",
            "Minha terra tem primores,\n",
            "Que tais não encontro eu cá;\n",
            "Em cismar –sozinho, à noite–\n",
            "Mais prazer eu encontro lá;\n",
            "Minha terra tem palmeiras,\n",
            "Onde canta o Sabiá.\n",
            "\n",
            "Não permita Deus que eu morra,\n",
            "Sem que eu volte para lá;\n",
            "Sem que disfrute os primores\n",
            "Que não encontro por cá;\n",
            "Sem qu'inda aviste as palmeiras,\n",
            "Onde canta o Sabiá. \n",
            "\n",
            "=== Without last word per line ===\n",
            "Minha terra tem ,\n",
            "Onde canta o ;\n",
            "As aves, que aqui ,\n",
            "Não gorjeiam como .\n",
            "\n",
            "Nosso céu tem mais ,\n",
            "Nossas várzeas têm mais ,\n",
            "Nossos bosques têm mais ,\n",
            "Nossa vida mais .\n",
            "\n",
            "Em  cismar, sozinho, à ,\n",
            "Mais prazer eu encontro ;\n",
            "Minha terra tem ,\n",
            "Onde canta o .\n",
            "\n",
            "Minha terra tem ,\n",
            "Que tais não encontro eu ;\n",
            "Em cismar –sozinho, à –\n",
            "Mais prazer eu encontro ;\n",
            "Minha terra tem ,\n",
            "Onde canta o .\n",
            "\n",
            "Não permita Deus que eu ,\n",
            "Sem que eu volte para ;\n",
            "Sem que disfrute os\n",
            "Que não encontro por ;\n",
            "Sem qu'inda aviste as ,\n",
            "Onde canta o .\n",
            "\n",
            "=== Removed last words ===\n",
            "['palmeiras', 'Sabiá', 'gorjeiam', 'lá', '', 'estrelas', 'flores', 'vida', 'amores', '', 'noite', 'lá', 'palmeiras', 'Sabiá', '', 'primores', 'cá', 'noite', 'lá', 'palmeiras', 'Sabiá', '', 'morra', 'lá', 'primores', 'cá', 'palmeiras', 'Sabiá']\n"
          ]
        }
      ],
      "source": [
        "# --- Coded with @ChatGPT ---\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "def remove_last_word_per_line(poem: str) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Treat each line as a phrase.\n",
        "    Removes the last word of each non-empty line.\n",
        "    Returns (new_poem, removed_words).\n",
        "\n",
        "    Notes:\n",
        "    - If line ends with punctuation, we remove the last word but keep trailing punctuation.\n",
        "      Example: \"hello, world!\" -> \"hello, !\" (you can change this behavior below)\n",
        "    - Lines with 0 or 1 word become \"\" (or just punctuation if it existed).\n",
        "    \"\"\"\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    # Pattern: capture everything up to last \"word\", then that last word, then trailing non-word chars\n",
        "    # \"word\" here = letters/digits/underscore; works well for most poems.\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)   # keep blank line as-is\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            # If nothing matches (e.g., line is only punctuation), keep as-is\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        # Remove possible extra spaces before trailing punctuation nicely\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "\n",
        "# --- Paste the poem here ---\n",
        "poem = \"\"\"Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá;\n",
        "As aves, que aqui gorjeiam,\n",
        "Não gorjeiam como lá.\n",
        "\n",
        "Nosso céu tem mais estrelas,\n",
        "Nossas várzeas têm mais flores,\n",
        "Nossos bosques têm mais vida,\n",
        "Nossa vida mais amores.\n",
        "\n",
        "Em  cismar, sozinho, à noite,\n",
        "Mais prazer eu encontro lá;\n",
        "Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá.\n",
        "\n",
        "Minha terra tem primores,\n",
        "Que tais não encontro eu cá;\n",
        "Em cismar –sozinho, à noite–\n",
        "Mais prazer eu encontro lá;\n",
        "Minha terra tem palmeiras,\n",
        "Onde canta o Sabiá.\n",
        "\n",
        "Não permita Deus que eu morra,\n",
        "Sem que eu volte para lá;\n",
        "Sem que disfrute os primores\n",
        "Que não encontro por cá;\n",
        "Sem qu'inda aviste as palmeiras,\n",
        "Onde canta o Sabiá. \"\"\"\n",
        "\n",
        "new_poem, removed_words = remove_last_word_per_line(poem)\n",
        "\n",
        "print(\"=== Original ===\")\n",
        "print(poem)\n",
        "print(\"\\n=== Without last word per line ===\")\n",
        "print(new_poem)\n",
        "print(\"\\n=== Removed last words ===\")\n",
        "print(removed_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HF03skkVHUb",
        "outputId": "4c08dec1-d678-4256-cab4-cc7c4c368cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (for reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 next-word predictions per line ===\n",
            "\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. their   (p≈0.327742)\n",
            "  2. its   (p≈0.134323)\n",
            "  3. his   (p≈0.130412)\n",
            "  4. your   (p≈0.024782)\n",
            "  5. a   (p≈0.020237)\n",
            "  6. our   (p≈0.016856)\n",
            "  7. her   (p≈0.016227)\n",
            "\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold   (p≈0.019574)\n",
            "  2. snow   (p≈0.015065)\n",
            "  3. frost   (p≈0.011847)\n",
            "  4. ice   (p≈0.011417)\n",
            "  5. fire   (p≈0.009118)\n",
            "  6. wind   (p≈0.007472)\n",
            "  7. death   (p≈0.006405)\n",
            "\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. the   (p≈0.115517)\n",
            "  2. and   (p≈0.036429)\n",
            "  3. the   (p≈0.015668)\n",
            "  4. a   (p≈0.015343)\n",
            "  5. but   (p≈0.011335)\n",
            "  6. he   (p≈0.008077)\n",
            "  7. it   (p≈0.007911)\n",
            "\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time   (p≈0.923336)\n",
            "  2. while   (p≈0.044233)\n",
            "  3. enough   (p≈0.002422)\n",
            "  4. long   (p≈0.002420)\n",
            "  5. day   (p≈0.001997)\n",
            "  6. way   (p≈0.001524)\n",
            "  7. few   (p≈0.000694)\n",
            "\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. and   (p≈0.084944)\n",
            "  2. the   (p≈0.055765)\n",
            "  3. they   (p≈0.026530)\n",
            "  4. a   (p≈0.022741)\n",
            "  5. which   (p≈0.014570)\n",
            "  6. as   (p≈0.013563)\n",
            "  7. I   (p≈0.012816)\n",
            "\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills   (p≈0.063551)\n",
            "  2. past   (p≈0.058286)\n",
            "  3. mountains   (p≈0.029670)\n",
            "  4. sky   (p≈0.024388)\n",
            "  5. future   (p≈0.019752)\n",
            "  6. horizon   (p≈0.019710)\n",
            "  7. night   (p≈0.014906)\n",
            "\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. be   (p≈0.163062)\n",
            "  2. mention   (p≈0.082309)\n",
            "  3. the   (p≈0.048059)\n",
            "  4. say   (p≈0.046895)\n",
            "  5. forget   (p≈0.024347)\n",
            "  6. speak   (p≈0.021671)\n",
            "  7. have   (p≈0.012935)\n",
            "\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. the   (p≈0.055677)\n",
            "  2. and   (p≈0.030254)\n",
            "  3. you   (p≈0.024980)\n",
            "  4. it   (p≈0.022849)\n",
            "  5. I   (p≈0.022692)\n",
            "  6. or   (p≈0.020128)\n",
            "  7. which   (p≈0.015042)\n",
            "\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. the   (p≈0.098786)\n",
            "  2. you   (p≈0.064024)\n",
            "  3. I   (p≈0.061768)\n",
            "  4. it   (p≈0.042075)\n",
            "  5. a   (p≈0.029483)\n",
            "  6. there   (p≈0.024765)\n",
            "  7. we   (p≈0.019941)\n",
            "\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind   (p≈0.011728)\n",
            "  2. car   (p≈0.010731)\n",
            "  3. door   (p≈0.009443)\n",
            "  4. engine   (p≈0.008490)\n",
            "  5. water   (p≈0.008186)\n",
            "  6. sound   (p≈0.007511)\n",
            "  7. voice   (p≈0.007308)\n",
            "\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind   (p≈0.017899)\n",
            "  2. name   (p≈0.015471)\n",
            "  3. thing   (p≈0.014833)\n",
            "  4. type   (p≈0.014472)\n",
            "  5. day   (p≈0.011899)\n",
            "  6. material   (p≈0.009552)\n",
            "  7. story   (p≈0.009409)\n",
            "\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot   (p≈0.033189)\n",
            "  2. feet   (p≈0.028551)\n",
            "  3. chest   (p≈0.028061)\n",
            "  4. hands   (p≈0.027312)\n",
            "  5. air   (p≈0.021669)\n",
            "  6. shoulders   (p≈0.019035)\n",
            "  7. footed   (p≈0.018051)\n",
            "\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. the   (p≈0.107719)\n",
            "  2. you   (p≈0.094248)\n",
            "  3. it   (p≈0.061220)\n",
            "  4. listen   (p≈0.033752)\n",
            "  5. then   (p≈0.031616)\n",
            "  6. and   (p≈0.024582)\n",
            "  7. this   (p≈0.020407)\n",
            "\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. but   (p≈0.144305)\n",
            "  2. nothing   (p≈0.068906)\n",
            "  3. except   (p≈0.050083)\n",
            "  4. no   (p≈0.032543)\n",
            "  5. and   (p≈0.031650)\n",
            "  6. he   (p≈0.027037)\n",
            "  7. I   (p≈0.023098)\n",
            "\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. It   (p≈0.007830)\n",
            "  2. I   (p≈0.006189)\n",
            "  3. The   (p≈0.004710)\n",
            "  4. That   (p≈0.004307)\n",
            "  5. You   (p≈0.003553)\n",
            "  6. This   (p≈0.003549)\n",
            "  7. And   (p≈0.003511)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# This script: CODE 1\n",
        "\n",
        "# 1. Takes a poem\n",
        "\n",
        "# 2. Treats each line as a phrase\n",
        "\n",
        "# 3. Removes the last word of each line, but keep the punctution\n",
        "\n",
        "# 4. Asks GPT-2:“Given this incomplete line, what is the most likely next word?”\n",
        "\n",
        "# 5. Prints the top 7 most probable next words per line, according to GPT-2\n",
        "\n",
        "#This is a \"probabilistic poetry\".\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "#re: regular expressions (used to manipulate text)\n",
        "\n",
        "#AutoTokenizer: converts text → tokens (numbers)\n",
        "\n",
        "#AutoModelForCausalLM: GPT-2 model that predicts the next token\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste the poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove the last word of each line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "\n",
        "        # keep trailing punctuation (if any) but remove the last word\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (for reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# --- 3) Load GPT-2 (\"openai-community/gpt2\") ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- 4) Get the 7 highest-probability \"next-word\" candidates per line ---\n",
        "# Note: GPT-2 predicts next *token*, so it filters for \"word-like\" tokens and return 7 of them.\n",
        "word_like = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "def top7_next_words(prompt: str, k: int = 7):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "        logits = out.logits[0, -1, :]  # next-token logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    candidates = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])  # decoded token string (often begins with a space)\n",
        "        candidate = piece.strip()\n",
        "\n",
        "        # filter for word-like candidates\n",
        "        if word_like.match(candidate):\n",
        "            candidates.append((candidate, float(probs[tid].cpu())))\n",
        "            if len(candidates) == k:\n",
        "                break\n",
        "\n",
        "    return candidates\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 next-word predictions per line ===\")\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"\\nLine {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    preds = top7_next_words(line, k=7)\n",
        "    print(f\"\\nLine {i} prompt: {line!r}\")\n",
        "    for rank, (w, p) in enumerate(preds, start=1):\n",
        "        print(f\"  {rank}. {w}   (p≈{p:.6f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDKNn8o6EsN",
        "outputId": "70f301b6-13d9-4eb2-81e0-d1747a44a120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (for reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 next-word predictions per line (and choose 1-7) ===\n",
            "\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. their   (p≈0.327742)\n",
            "  2. its   (p≈0.134323)\n",
            "  3. his   (p≈0.130412)\n",
            "  4. your   (p≈0.024782)\n",
            "  5. a   (p≈0.020237)\n",
            "  6. our   (p≈0.016856)\n",
            "  7. her   (p≈0.016227)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold   (p≈0.019574)\n",
            "  2. snow   (p≈0.015065)\n",
            "  3. frost   (p≈0.011847)\n",
            "  4. ice   (p≈0.011417)\n",
            "  5. fire   (p≈0.009118)\n",
            "  6. wind   (p≈0.007472)\n",
            "  7. death   (p≈0.006405)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. the   (p≈0.115517)\n",
            "  2. and   (p≈0.036429)\n",
            "  3. the   (p≈0.015668)\n",
            "  4. a   (p≈0.015343)\n",
            "  5. but   (p≈0.011335)\n",
            "  6. he   (p≈0.008077)\n",
            "  7. it   (p≈0.007911)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time   (p≈0.923336)\n",
            "  2. while   (p≈0.044233)\n",
            "  3. enough   (p≈0.002422)\n",
            "  4. long   (p≈0.002420)\n",
            "  5. day   (p≈0.001997)\n",
            "  6. way   (p≈0.001524)\n",
            "  7. few   (p≈0.000694)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. and   (p≈0.084944)\n",
            "  2. the   (p≈0.055765)\n",
            "  3. they   (p≈0.026530)\n",
            "  4. a   (p≈0.022741)\n",
            "  5. which   (p≈0.014570)\n",
            "  6. as   (p≈0.013563)\n",
            "  7. I   (p≈0.012816)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills   (p≈0.063551)\n",
            "  2. past   (p≈0.058286)\n",
            "  3. mountains   (p≈0.029670)\n",
            "  4. sky   (p≈0.024388)\n",
            "  5. future   (p≈0.019752)\n",
            "  6. horizon   (p≈0.019710)\n",
            "  7. night   (p≈0.014906)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. be   (p≈0.163062)\n",
            "  2. mention   (p≈0.082309)\n",
            "  3. the   (p≈0.048059)\n",
            "  4. say   (p≈0.046895)\n",
            "  5. forget   (p≈0.024347)\n",
            "  6. speak   (p≈0.021671)\n",
            "  7. have   (p≈0.012935)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. the   (p≈0.055677)\n",
            "  2. and   (p≈0.030254)\n",
            "  3. you   (p≈0.024980)\n",
            "  4. it   (p≈0.022849)\n",
            "  5. I   (p≈0.022692)\n",
            "  6. or   (p≈0.020128)\n",
            "  7. which   (p≈0.015042)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. the   (p≈0.098786)\n",
            "  2. you   (p≈0.064024)\n",
            "  3. I   (p≈0.061768)\n",
            "  4. it   (p≈0.042075)\n",
            "  5. a   (p≈0.029483)\n",
            "  6. there   (p≈0.024765)\n",
            "  7. we   (p≈0.019941)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind   (p≈0.011728)\n",
            "  2. car   (p≈0.010731)\n",
            "  3. door   (p≈0.009443)\n",
            "  4. engine   (p≈0.008490)\n",
            "  5. water   (p≈0.008186)\n",
            "  6. sound   (p≈0.007511)\n",
            "  7. voice   (p≈0.007308)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind   (p≈0.017899)\n",
            "  2. name   (p≈0.015471)\n",
            "  3. thing   (p≈0.014833)\n",
            "  4. type   (p≈0.014472)\n",
            "  5. day   (p≈0.011899)\n",
            "  6. material   (p≈0.009552)\n",
            "  7. story   (p≈0.009409)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot   (p≈0.033189)\n",
            "  2. feet   (p≈0.028551)\n",
            "  3. chest   (p≈0.028061)\n",
            "  4. hands   (p≈0.027312)\n",
            "  5. air   (p≈0.021669)\n",
            "  6. shoulders   (p≈0.019035)\n",
            "  7. footed   (p≈0.018051)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. the   (p≈0.107719)\n",
            "  2. you   (p≈0.094248)\n",
            "  3. it   (p≈0.061220)\n",
            "  4. listen   (p≈0.033752)\n",
            "  5. then   (p≈0.031616)\n",
            "  6. and   (p≈0.024582)\n",
            "  7. this   (p≈0.020407)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. but   (p≈0.144305)\n",
            "  2. nothing   (p≈0.068906)\n",
            "  3. except   (p≈0.050083)\n",
            "  4. no   (p≈0.032543)\n",
            "  5. and   (p≈0.031650)\n",
            "  6. he   (p≈0.027037)\n",
            "  7. I   (p≈0.023098)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. It   (p≈0.007830)\n",
            "  2. I   (p≈0.006189)\n",
            "  3. The   (p≈0.004710)\n",
            "  4. That   (p≈0.004307)\n",
            "  5. You   (p≈0.003553)\n",
            "  6. This   (p≈0.003549)\n",
            "  7. And   (p≈0.003511)\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "=== NEW POEM ===\n",
            "One must have a mind of her\n",
            "To regard the frost and the death\n",
            "Of the pine-trees crusted with it;\n",
            "And have been cold a long few\n",
            "To behold the junipers shagged with I,\n",
            "The spruces rough in the distant night\n",
            "Of the January sun; and not to have\n",
            "Of any misery in the sound of the which,\n",
            "In the sound of a few we,\n",
            "Which is the sound of the voice\n",
            "Full of the same story\n",
            "That is blowing in the same bare footed\n",
            "For the listener, who listens in the this,\n",
            "And, nothing himself, I\n",
            "Nothing that is not there and the nothing that And.\n",
            "\n",
            "Saved to: P7_poem_probabilistic.txt\n"
          ]
        }
      ],
      "source": [
        "#Choose and print P7.txt\n",
        "#This is a \"probabilistic poetry\".\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Build prompts AND keep structured parts per line:\n",
        "#    before (everything before last word),\n",
        "#    last_word (removed),\n",
        "#    trailing (punctuation after last word)\n",
        "# -----------------------------------------------------\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []  # list of dicts: {original, before, last_word, trailing}\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "# Prompt must be EXACTLY \"before + trailing\" (this matches your original logic/output)\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(\"\\n\".join(prompts_lines))\n",
        "print(\"\\n=== Removed last words (for reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Load GPT-2\n",
        "# -----------------------------------------------------\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Top-7 predictions (word-like tokens)\n",
        "# -----------------------------------------------------\n",
        "word_like = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "def top7_next_words(prompt: str, k: int = 7):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "        logits = out.logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    candidates = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        candidate = tokenizer.decode([tid]).strip()\n",
        "        if word_like.match(candidate):\n",
        "            candidates.append((candidate, float(probs[tid].cpu())))\n",
        "            if len(candidates) == k:\n",
        "                break\n",
        "    return candidates\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild CORRECTLY:\n",
        "#    [before] + chosen_word + [trailing]\n",
        "#    (word goes BEFORE punctuation)\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Interactive: print top-7, choose 1-7, rebuild poem, save txt\n",
        "# -----------------------------------------------------\n",
        "new_lines = []\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 next-word predictions per line (and choose 1-7) ===\")\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"\\nLine {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    preds = top7_next_words(prompt_line, k=7)\n",
        "\n",
        "    print(f\"\\nLine {i} prompt: {prompt_line!r}\")\n",
        "    for rank, (w, p) in enumerate(preds, start=1):\n",
        "        print(f\"  {rank}. {w}   (p≈{p:.6f})\")\n",
        "\n",
        "    while True:\n",
        "        raw = input(\"Choose an option (1-7): \").strip()\n",
        "        if raw.isdigit():\n",
        "            n = int(raw)\n",
        "            if 1 <= n <= 7:\n",
        "                chosen_word = preds[n - 1][0]\n",
        "                break\n",
        "        print(\"Invalid choice. Type a number from 1 to 7.\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"P7_poem_probabilistic.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vRbTJoaDdv",
        "outputId": "cc34aba0-391c-4afa-ccb0-e50be1fd0d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. their              p≈0.327749\n",
            "  2. its                p≈0.134322\n",
            "  3. his                p≈0.130409\n",
            "  4. your               p≈0.024783\n",
            "  5. a                  p≈0.020238\n",
            "  6. our                p≈0.016856\n",
            "  7. her                p≈0.016227\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. uncom              p≈0.000121\n",
            "  2. pra                p≈0.000046\n",
            "  3. locom              p≈0.000032\n",
            "  4. Com                p≈0.000031\n",
            "  5. unique             p≈0.000024\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007471\n",
            "  7. death              p≈0.006405\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.115519\n",
            "  2. and                p≈0.036429\n",
            "  3. the                p≈0.015668\n",
            "  4. a                  p≈0.015343\n",
            "  5. but                p≈0.011335\n",
            "  6. he                 p≈0.008078\n",
            "  7. it                 p≈0.007911\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000496\n",
            "  2. com                p≈0.000330\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. time               p≈0.923361\n",
            "  2. while              p≈0.044236\n",
            "  3. enough             p≈0.002422\n",
            "  4. long               p≈0.002420\n",
            "  5. day                p≈0.001997\n",
            "  6. way                p≈0.001524\n",
            "  7. few                p≈0.000694\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. que                p≈0.000001\n",
            "  2. com                p≈0.000001\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. and                p≈0.084944\n",
            "  2. the                p≈0.055764\n",
            "  3. they               p≈0.026530\n",
            "  4. a                  p≈0.022741\n",
            "  5. which              p≈0.014570\n",
            "  6. as                 p≈0.013563\n",
            "  7. I                  p≈0.012816\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000110\n",
            "  2. com                p≈0.000093\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058288\n",
            "  3. mountains          p≈0.029669\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014907\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. pra                p≈0.000168\n",
            "  2. com                p≈0.000078\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. be                 p≈0.163060\n",
            "  2. mention            p≈0.082306\n",
            "  3. the                p≈0.048059\n",
            "  4. say                p≈0.046896\n",
            "  5. forget             p≈0.024347\n",
            "  6. speak              p≈0.021670\n",
            "  7. have               p≈0.012935\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000172\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.055678\n",
            "  2. and                p≈0.030254\n",
            "  3. you                p≈0.024981\n",
            "  4. it                 p≈0.022850\n",
            "  5. I                  p≈0.022692\n",
            "  6. or                 p≈0.020128\n",
            "  7. which              p≈0.015042\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000079\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.098783\n",
            "  2. you                p≈0.064026\n",
            "  3. I                  p≈0.061768\n",
            "  4. it                 p≈0.042074\n",
            "  5. a                  p≈0.029483\n",
            "  6. there              p≈0.024766\n",
            "  7. we                 p≈0.019942\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000068\n",
            "  2. Pokémon            p≈0.000066\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. locom              p≈0.000224\n",
            "  2. sque               p≈0.000129\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. technique          p≈0.000413\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028549\n",
            "  3. chest              p≈0.028062\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019036\n",
            "  7. footed             p≈0.018051\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. the                p≈0.107716\n",
            "  2. you                p≈0.094248\n",
            "  3. it                 p≈0.061221\n",
            "  4. listen             p≈0.033752\n",
            "  5. then               p≈0.031615\n",
            "  6. and                p≈0.024581\n",
            "  7. this               p≈0.020407\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.000036\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. but                p≈0.144313\n",
            "  2. nothing            p≈0.068909\n",
            "  3. except             p≈0.050082\n",
            "  4. no                 p≈0.032543\n",
            "  5. and                p≈0.031649\n",
            "  6. he                 p≈0.027037\n",
            "  7. I                  p≈0.023098\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  (none found — try increasing top_n)\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "\n",
            "Top-7 (English-ish) next words:\n",
            "  1. It                 p≈0.007830\n",
            "  2. I                  p≈0.006189\n",
            "  3. The                p≈0.004710\n",
            "  4. That               p≈0.004307\n",
            "  5. You                p≈0.003553\n",
            "  6. This               p≈0.003549\n",
            "  7. And                p≈0.003511\n",
            "\n",
            "Top-7 (Portuguese-ish) next words:\n",
            "  1. com                p≈0.001090\n",
            "  2. Com                p≈0.000080\n",
            "  3. COM                p≈0.000056\n",
            "  4. com                p≈0.000040\n",
            "  5. Com                p≈0.000015\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# VERSION 1 — For each line: show TOP-7 next-word candidates in ENGLISH + TOP-7 in PORTUGUESE\n",
        "# (same GPT-2 model; we just filter the ranked next-token list into 2 language buckets)\n",
        "#NOTE: discovered that GPT-2 model does not work in Portuguese\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove the last word of each line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines = []\n",
        "    removed = []\n",
        "\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "\n",
        "        # keep trailing punctuation (if any) but remove the last word\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "\n",
        "# --- 3) Load GPT-2 ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# --- 4) Language-ish filters (heuristics) ---\n",
        "# \"word-like\": letters (incl. accents) + optional internal - or '\n",
        "WORDLIKE = re.compile(r\"^[A-Za-zÀ-ÖØ-öø-ÿ]+(?:[-'][A-Za-zÀ-ÖØ-öø-ÿ]+)*$\")\n",
        "\n",
        "# English-ish: only basic Latin letters (no accents)\n",
        "ENGLISHISH = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# Portuguese-ish: either has a Portuguese diacritic or contains common PT letter combos\n",
        "# (still a heuristic; GPT-2 is not a Portuguese-specialized model)\n",
        "PT_DIACRITIC = re.compile(r\"[áàâãéêíóôõúçÁÀÂÃÉÊÍÓÔÕÚÇ]\")\n",
        "PT_COMBOS = re.compile(r\"(nh|lh|ção|ções|mente|ões|ões|que|pra|não|uma|uma|para|com|dos|das|ção)$\", re.IGNORECASE)\n",
        "\n",
        "def is_portugueseish(word: str) -> bool:\n",
        "    return bool(WORDLIKE.match(word) and (PT_DIACRITIC.search(word) or PT_COMBOS.search(word)))\n",
        "\n",
        "def is_englishish(word: str) -> bool:\n",
        "    return bool(ENGLISHISH.match(word))\n",
        "\n",
        "# --- 5) Get ranked next-token list once, then filter into EN/PT buckets ---\n",
        "def get_ranked_next_tokens(prompt: str, top_n: int = 500):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:top_n]\n",
        "\n",
        "    ranked = []\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])\n",
        "        candidate = piece.strip()\n",
        "        if candidate and WORDLIKE.match(candidate):\n",
        "            ranked.append((candidate, float(probs[tid].cpu())))\n",
        "    return ranked\n",
        "\n",
        "def pick_top_k_by_lang(ranked, k=7):\n",
        "    en = []\n",
        "    pt = []\n",
        "    for w, p in ranked:\n",
        "        if len(en) < k and is_englishish(w):\n",
        "            en.append((w, p))\n",
        "        if len(pt) < k and is_portugueseish(w):\n",
        "            pt.append((w, p))\n",
        "        if len(en) >= k and len(pt) >= k:\n",
        "            break\n",
        "    return en, pt\n",
        "\n",
        "# --- Run ---\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    ranked = get_ranked_next_tokens(line, top_n=1500)  # increase if PT bucket is too sparse\n",
        "    top_en, top_pt = pick_top_k_by_lang(ranked, k=7)\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "\n",
        "    print(\"\\nTop-7 (English-ish) next words:\")\n",
        "    if top_en:\n",
        "        for r, (w, p) in enumerate(top_en, start=1):\n",
        "            print(f\"  {r}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (none found — try increasing top_n)\")\n",
        "\n",
        "    print(\"\\nTop-7 (Portuguese-ish) next words:\")\n",
        "    if top_pt:\n",
        "        for r, (w, p) in enumerate(top_pt, start=1):\n",
        "            print(f\"  {r}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (none found — try increasing top_n)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Gznc2oawu9",
        "outputId": "68bfcfd2-338e-4790-b1d6-ecdf2e3d02ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. balance            p≈0.005845\n",
            "  2. good               p≈0.003427\n",
            "  3. steel              p≈0.002962\n",
            "  4. self               p≈0.002643\n",
            "  5. order              p≈0.002605\n",
            "  6. thy                p≈0.002361\n",
            "  7. humility           p≈0.002285\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007471\n",
            "  7. death              p≈0.006405\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. other              p≈0.003645\n",
            "  2. leaves             p≈0.003549\n",
            "  3. red                p≈0.001984\n",
            "  4. pine               p≈0.001740\n",
            "  5. black              p≈0.001731\n",
            "  6. fruit              p≈0.001649\n",
            "  7. all                p≈0.001644\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time               p≈0.923361\n",
            "  2. enough             p≈0.002422\n",
            "  3. long               p≈0.002420\n",
            "  4. day                p≈0.001997\n",
            "  5. way                p≈0.001524\n",
            "  6. moment             p≈0.000526\n",
            "  7. year               p≈0.000512\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. like               p≈0.011911\n",
            "  2. all                p≈0.003200\n",
            "  3. two                p≈0.002965\n",
            "  4. who                p≈0.002274\n",
            "  5. black              p≈0.001814\n",
            "  6. saw                p≈0.001649\n",
            "  7. said               p≈0.001444\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058288\n",
            "  3. mountains          p≈0.029669\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014907\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. mention            p≈0.082306\n",
            "  2. say                p≈0.046896\n",
            "  3. forget             p≈0.024347\n",
            "  4. speak              p≈0.021670\n",
            "  5. think              p≈0.012622\n",
            "  6. look               p≈0.009680\n",
            "  7. take               p≈0.008001\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. like               p≈0.003123\n",
            "  2. who                p≈0.003045\n",
            "  3. voice              p≈0.002840\n",
            "  4. let                p≈0.002243\n",
            "  5. sound              p≈0.001899\n",
            "  6. all                p≈0.001682\n",
            "  7. well               p≈0.001651\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. people             p≈0.004512\n",
            "  2. all                p≈0.002143\n",
            "  3. let                p≈0.001983\n",
            "  4. two                p≈0.001953\n",
            "  5. well               p≈0.001833\n",
            "  6. please             p≈0.001478\n",
            "  7. sounds             p≈0.001393\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028549\n",
            "  3. chest              p≈0.028062\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019036\n",
            "  7. footed             p≈0.018051\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. listen             p≈0.033752\n",
            "  2. who                p≈0.008925\n",
            "  3. listens            p≈0.006015\n",
            "  4. see                p≈0.005703\n",
            "  5. please             p≈0.004795\n",
            "  6. listening          p≈0.003307\n",
            "  7. watch              p≈0.002817\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. except             p≈0.050082\n",
            "  2. however            p≈0.014229\n",
            "  3. really             p≈0.007516\n",
            "  4. save               p≈0.005937\n",
            "  5. let                p≈0.004823\n",
            "  6. nobody             p≈0.004076\n",
            "  7. other              p≈0.003865\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. com                p≈0.001090\n",
            "  2. org                p≈0.000582\n",
            "  3. Now                p≈0.000570\n",
            "  4. Let                p≈0.000488\n",
            "  5. All                p≈0.000423\n",
            "  6. Well               p≈0.000420\n",
            "  7. gov                p≈0.000381\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# This script: CODE 2\n",
        "# TOP-7 \"SEMANTIC\" next-word candidates per line (GPT-2)\n",
        "# Variant 1: filter out function words (articles, pronouns, conjunctions, etc.)\n",
        "# NOTE: GPT-2 doesn't provide POS (Part-of-Speech tags) tags,\n",
        "#so we use a strong stopword (remove very common function words as I, you, of, in, on,and, or, but, etc)\n",
        "#+ heuristic filter (Keep only tokens that look like real words removing very short tokensnumbers or symbols) .\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# --- 2) Remove last word per line (each line = one phrase) ---\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line)\n",
        "            removed.append(\"\")\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line)\n",
        "        removed.append(last_word)\n",
        "\n",
        "    return \"\\n\".join(new_lines), removed\n",
        "\n",
        "prompts_poem, removed_words = remove_last_word_per_line(poem)\n",
        "prompts_lines = prompts_poem.splitlines()\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(prompts_poem)\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# --- 3) Load GPT-2 ---\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# --- 4) Filters: word-like + \"content word\" heuristic ---\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")  # keep simple English word forms\n",
        "\n",
        "# A compact but strong English stopword set to remove function words.\n",
        "# (Includes: articles, pronouns, conjunctions, auxiliaries, prepositions, etc.)\n",
        "STOPWORDS = {\n",
        "    # articles / determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # common prepositions\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\"before\",\"after\",\n",
        "    \"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    # auxiliaries / modals / copulas (often non-content)\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\n",
        "    \"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    # misc function-ish\n",
        "    \"not\",\"no\",\"yes\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\n",
        "    \"as\",\"up\",\"down\",\"out\",\"off\",\"again\",\"more\",\"most\",\"less\",\"least\"\n",
        "}\n",
        "\n",
        "# Additional heuristic: reject very short tokens & common suffix-only tokens that slip in\n",
        "def is_content_word(w: str) -> bool:\n",
        "    w_low = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(w_low) < 3:\n",
        "        return False\n",
        "    if w_low in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def top_k_content_words(prompt: str, k: int = 7, oversample: int = 5000):\n",
        "    \"\"\"\n",
        "    GPT-2 predicts next TOKEN. We'll rank all tokens by probability, then filter\n",
        "    to \"content words\" and return the first k.\n",
        "    oversample: how many top tokens to scan to find enough content words.\n",
        "    \"\"\"\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]  # next-token logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:oversample]\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for tid in sorted_ids.tolist():\n",
        "        cand = tokenizer.decode([tid]).strip()\n",
        "        if not cand:\n",
        "            continue\n",
        "\n",
        "        # keep unique lowercase words (avoid repeats with casing)\n",
        "        key = cand.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "\n",
        "        if is_content_word(cand):\n",
        "            out.append((cand, float(probs[tid].cpu())))\n",
        "            seen.add(key)\n",
        "            if len(out) == k:\n",
        "                break\n",
        "\n",
        "    return out\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line ===\")\n",
        "for i, line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    preds = top_k_content_words(line, k=7, oversample=20000)\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if preds:\n",
        "        for rank, (w, p) in enumerate(preds, start=1):\n",
        "            print(f\"  {rank}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (No content-word candidates found; try increasing oversample.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlmRnZXb7pEN",
        "outputId": "79c2a161-50b4-479d-c2dd-9d2314cf695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (each line missing last word) ===\n",
            "One must have a mind of\n",
            "To regard the frost and the\n",
            "Of the pine-trees crusted with ;\n",
            "And have been cold a long\n",
            "To behold the junipers shagged with ,\n",
            "The spruces rough in the distant\n",
            "Of the January sun; and not to\n",
            "Of any misery in the sound of the ,\n",
            "In the sound of a few ,\n",
            "Which is the sound of the\n",
            "Full of the same\n",
            "That is blowing in the same bare\n",
            "For the listener, who listens in the ,\n",
            "And, nothing himself,\n",
            "Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line (choose 1-7) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  1. balance            p≈0.005845\n",
            "  2. good               p≈0.003427\n",
            "  3. steel              p≈0.002962\n",
            "  4. self               p≈0.002643\n",
            "  5. order              p≈0.002605\n",
            "  6. thy                p≈0.002361\n",
            "  7. humility           p≈0.002285\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  1. cold               p≈0.019574\n",
            "  2. snow               p≈0.015065\n",
            "  3. frost              p≈0.011847\n",
            "  4. ice                p≈0.011417\n",
            "  5. fire               p≈0.009118\n",
            "  6. wind               p≈0.007472\n",
            "  7. death              p≈0.006405\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  1. other              p≈0.003645\n",
            "  2. leaves             p≈0.003549\n",
            "  3. red                p≈0.001984\n",
            "  4. pine               p≈0.001740\n",
            "  5. black              p≈0.001731\n",
            "  6. fruit              p≈0.001649\n",
            "  7. all                p≈0.001644\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  1. time               p≈0.923336\n",
            "  2. enough             p≈0.002422\n",
            "  3. long               p≈0.002420\n",
            "  4. day                p≈0.001997\n",
            "  5. way                p≈0.001524\n",
            "  6. moment             p≈0.000526\n",
            "  7. year               p≈0.000512\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  1. like               p≈0.011912\n",
            "  2. all                p≈0.003200\n",
            "  3. two                p≈0.002965\n",
            "  4. who                p≈0.002274\n",
            "  5. black              p≈0.001814\n",
            "  6. saw                p≈0.001649\n",
            "  7. said               p≈0.001444\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  1. hills              p≈0.063551\n",
            "  2. past               p≈0.058286\n",
            "  3. mountains          p≈0.029670\n",
            "  4. sky                p≈0.024388\n",
            "  5. future             p≈0.019752\n",
            "  6. horizon            p≈0.019710\n",
            "  7. night              p≈0.014906\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  1. mention            p≈0.082309\n",
            "  2. say                p≈0.046895\n",
            "  3. forget             p≈0.024347\n",
            "  4. speak              p≈0.021671\n",
            "  5. think              p≈0.012622\n",
            "  6. look               p≈0.009681\n",
            "  7. take               p≈0.008001\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  1. like               p≈0.003123\n",
            "  2. who                p≈0.003045\n",
            "  3. voice              p≈0.002840\n",
            "  4. let                p≈0.002243\n",
            "  5. sound              p≈0.001899\n",
            "  6. all                p≈0.001682\n",
            "  7. well               p≈0.001651\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  1. people             p≈0.004512\n",
            "  2. all                p≈0.002143\n",
            "  3. let                p≈0.001983\n",
            "  4. two                p≈0.001952\n",
            "  5. well               p≈0.001833\n",
            "  6. please             p≈0.001478\n",
            "  7. sounds             p≈0.001393\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  1. wind               p≈0.011728\n",
            "  2. car                p≈0.010731\n",
            "  3. door               p≈0.009443\n",
            "  4. engine             p≈0.008490\n",
            "  5. water              p≈0.008186\n",
            "  6. sound              p≈0.007511\n",
            "  7. voice              p≈0.007308\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  1. kind               p≈0.017899\n",
            "  2. name               p≈0.015471\n",
            "  3. thing              p≈0.014833\n",
            "  4. type               p≈0.014472\n",
            "  5. day                p≈0.011899\n",
            "  6. material           p≈0.009552\n",
            "  7. story              p≈0.009409\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  1. foot               p≈0.033189\n",
            "  2. feet               p≈0.028551\n",
            "  3. chest              p≈0.028061\n",
            "  4. hands              p≈0.027312\n",
            "  5. air                p≈0.021669\n",
            "  6. shoulders          p≈0.019035\n",
            "  7. footed             p≈0.018051\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  1. listen             p≈0.033752\n",
            "  2. who                p≈0.008925\n",
            "  3. listens            p≈0.006015\n",
            "  4. see                p≈0.005703\n",
            "  5. please             p≈0.004795\n",
            "  6. listening          p≈0.003307\n",
            "  7. watch              p≈0.002817\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  1. except             p≈0.050083\n",
            "  2. however            p≈0.014230\n",
            "  3. really             p≈0.007516\n",
            "  4. save               p≈0.005937\n",
            "  5. let                p≈0.004823\n",
            "  6. nobody             p≈0.004076\n",
            "  7. other              p≈0.003865\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  1. com                p≈0.001090\n",
            "  2. org                p≈0.000582\n",
            "  3. Now                p≈0.000570\n",
            "  4. Let                p≈0.000488\n",
            "  5. All                p≈0.000423\n",
            "  6. Well               p≈0.000420\n",
            "  7. gov                p≈0.000381\n",
            "Choose an option (1-7): 7\n",
            "\n",
            "=== NEW POEM (SEMANTIC FILTER) ===\n",
            "One must have a mind of humility\n",
            "To regard the frost and the death\n",
            "Of the pine-trees crusted with all;\n",
            "And have been cold a long year\n",
            "To behold the junipers shagged with said,\n",
            "The spruces rough in the distant night\n",
            "Of the January sun; and not to take\n",
            "Of any misery in the sound of the well,\n",
            "In the sound of a few sounds,\n",
            "Which is the sound of the voice\n",
            "Full of the same story\n",
            "That is blowing in the same bare footed\n",
            "For the listener, who listens in the watch,\n",
            "And, nothing himself, other\n",
            "Nothing that is not there and the nothing that gov.\n",
            "\n",
            "Saved to: P7_poem_semantic.txt\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# TOP-7 \"SEMANTIC\" next-word candidates per line (GPT-2)\n",
        "# + choose 1..7 for each line\n",
        "# + rebuild line correctly (word BEFORE punctuation)\n",
        "# + save new poem to P7_poem_semantic.txt\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 1) Paste your poem here ---\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Split each line into: before + last_word + trailing punctuation\n",
        "#    Build prompts exactly like your original: prompt = before + trailing\n",
        "# -----------------------------------------------------\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    pat = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        m = pat.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (each line missing last word) ===\")\n",
        "print(\"\\n\".join(prompts_lines))\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Load GPT-2\n",
        "# -----------------------------------------------------\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Filters: word-like + \"content word\" heuristic\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles / determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # common prepositions\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\"before\",\"after\",\n",
        "    \"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    # auxiliaries / modals / copulas\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\n",
        "    \"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    # misc function-ish\n",
        "    \"not\",\"no\",\"yes\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\n",
        "    \"as\",\"up\",\"down\",\"out\",\"off\",\"again\",\"more\",\"most\",\"less\",\"least\"\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    w_low = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(w_low) < 3:\n",
        "        return False\n",
        "    if w_low in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def top_k_content_words(prompt: str, k: int = 7, oversample: int = 20000):\n",
        "    if prompt.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)[:oversample]\n",
        "\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for tid in sorted_ids.tolist():\n",
        "        cand = tokenizer.decode([tid]).strip()\n",
        "        if not cand:\n",
        "            continue\n",
        "\n",
        "        key = cand.lower()\n",
        "        if key in seen:\n",
        "            continue\n",
        "\n",
        "        if is_content_word(cand):\n",
        "            out.append((cand, float(probs[tid].cpu())))\n",
        "            seen.add(key)\n",
        "            if len(out) == k:\n",
        "                break\n",
        "\n",
        "    return out\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Rebuild line correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive choose 1..7, build poem, save txt\n",
        "# -----------------------------------------------------\n",
        "new_lines = []\n",
        "\n",
        "print(\"\\n=== GPT-2 top-7 CONTENT-WORD (semantic-ish) predictions per line (choose 1-7) ===\")\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    preds = top_k_content_words(prompt_line, k=7, oversample=20000)\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "    if preds:\n",
        "        for rank, (w, p) in enumerate(preds, start=1):\n",
        "            print(f\"  {rank}. {w:<18} p≈{p:.6f}\")\n",
        "    else:\n",
        "        print(\"  (No content-word candidates found; try increasing oversample.)\")\n",
        "        # keep original line if nothing found\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    while True:\n",
        "        raw = input(\"Choose an option (1-7): \").strip()\n",
        "        if raw.isdigit():\n",
        "            n = int(raw)\n",
        "            if 1 <= n <= 7:\n",
        "                chosen_word = preds[n - 1][0]\n",
        "                break\n",
        "        print(\"Invalid choice. Type a number from 1 to 7.\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (SEMANTIC FILTER) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"P7_poem_semantic.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jGyRvbjfVsw",
        "outputId": "6a14034d-a546-4873-d258-6ead12ff0bbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "0: One must have a mind of\n",
            "1: To regard the frost and the\n",
            "2: Of the pine-trees crusted with ;\n",
            "3: And have been cold a long\n",
            "4: To behold the junipers shagged with ,\n",
            "5: The spruces rough in the distant\n",
            "6: Of the January sun; and not to\n",
            "7: Of any misery in the sound of the ,\n",
            "8: In the sound of a few ,\n",
            "9: Which is the sound of the\n",
            "10: Full of the same\n",
            "11: That is blowing in the same bare\n",
            "12: For the listener, who listens in the ,\n",
            "13: And, nothing himself,\n",
            "14: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== CONTENT-WORD ranks 23–43 per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 0 prompt: 'One must have a mind of'\n",
            "  content-rank 23: integrity          p≈1.157843e-03\n",
            "  content-rank 24: common             p≈1.150411e-03\n",
            "  content-rank 25: humour             p≈1.136575e-03\n",
            "  content-rank 26: power              p≈1.088183e-03\n",
            "  content-rank 27: two                p≈1.083188e-03\n",
            "  content-rank 28: stone              p≈1.028237e-03\n",
            "  content-rank 29: matter             p≈9.090302e-04\n",
            "  content-rank 30: trust              p≈8.565321e-04\n",
            "  content-rank 31: transparency       p≈8.288884e-04\n",
            "  content-rank 32: harmony            p≈8.119575e-04\n",
            "  content-rank 33: peace              p≈7.843328e-04\n",
            "  content-rank 34: hard               p≈7.420420e-04\n",
            "  content-rank 35: mastery            p≈6.565556e-04\n",
            "  content-rank 36: flux               p≈6.524560e-04\n",
            "  content-rank 37: control            p≈6.425612e-04\n",
            "  content-rank 38: style              p≈6.351526e-04\n",
            "  content-rank 39: language           p≈6.303926e-04\n",
            "  content-rank 40: scale              p≈6.288986e-04\n",
            "  content-rank 41: action             p≈6.042109e-04\n",
            "  content-rank 42: gratitude          p≈6.024526e-04\n",
            "  content-rank 43: love               p≈6.002870e-04\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'To regard the frost and the'\n",
            "  content-rank 23: light              p≈2.565519e-03\n",
            "  content-rank 24: loss               p≈2.564619e-03\n",
            "  content-rank 25: lightning          p≈2.564580e-03\n",
            "  content-rank 26: weather            p≈2.524396e-03\n",
            "  content-rank 27: thunder            p≈2.411223e-03\n",
            "  content-rank 28: smoke              p≈2.401126e-03\n",
            "  content-rank 29: burning            p≈2.293549e-03\n",
            "  content-rank 30: fact               p≈2.262802e-03\n",
            "  content-rank 31: winter             p≈2.249153e-03\n",
            "  content-rank 32: chill              p≈2.229744e-03\n",
            "  content-rank 33: great              p≈2.218240e-03\n",
            "  content-rank 34: falling            p≈2.154212e-03\n",
            "  content-rank 35: ensuing            p≈2.051427e-03\n",
            "  content-rank 36: moon               p≈2.027775e-03\n",
            "  content-rank 37: war                p≈2.017944e-03\n",
            "  content-rank 38: fog                p≈1.972537e-03\n",
            "  content-rank 39: effect             p≈1.920401e-03\n",
            "  content-rank 40: consequ            p≈1.909866e-03\n",
            "  content-rank 41: black              p≈1.904206e-03\n",
            "  content-rank 42: rising             p≈1.826095e-03\n",
            "  content-rank 43: earth              p≈1.819948e-03\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 23: wood               p≈9.734706e-04\n",
            "  content-rank 24: three              p≈9.640399e-04\n",
            "  content-rank 25: words              p≈9.610656e-04\n",
            "  content-rank 26: branches           p≈8.977617e-04\n",
            "  content-rank 27: fire               p≈8.953265e-04\n",
            "  content-rank 28: poison             p≈8.852806e-04\n",
            "  content-rank 29: seeds              p≈8.509309e-04\n",
            "  content-rank 30: frost              p≈7.817165e-04\n",
            "  content-rank 31: like               p≈7.812633e-04\n",
            "  content-rank 32: green              p≈7.705723e-04\n",
            "  content-rank 33: ung                p≈7.601437e-04\n",
            "  content-rank 34: see                p≈7.405266e-04\n",
            "  content-rank 35: man                p≈7.067286e-04\n",
            "  content-rank 36: tobacco            p≈7.066315e-04\n",
            "  content-rank 37: rocks              p≈6.849221e-04\n",
            "  content-rank 38: ter                p≈6.650254e-04\n",
            "  content-rank 39: berries            p≈6.611401e-04\n",
            "  content-rank 40: grains             p≈6.564056e-04\n",
            "  content-rank 41: ing                p≈6.536371e-04\n",
            "  content-rank 42: notes              p≈6.363995e-04\n",
            "  content-rank 43: note               p≈6.309318e-04\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'And have been cold a long'\n",
            "  content-rank 23: term               p≈1.281507e-04\n",
            "  content-rank 24: winter             p≈1.232879e-04\n",
            "  content-rank 25: longer             p≈1.229863e-04\n",
            "  content-rank 26: haul               p≈1.079022e-04\n",
            "  content-rank 27: month              p≈1.076407e-04\n",
            "  content-rank 28: amount             p≈1.057397e-04\n",
            "  content-rank 29: wait               p≈1.045477e-04\n",
            "  content-rank 30: rest               p≈8.839200e-05\n",
            "  content-rank 31: Time               p≈8.501581e-05\n",
            "  content-rank 32: run                p≈8.098321e-05\n",
            "  content-rank 33: whilst             p≈7.479872e-05\n",
            "  content-rank 34: distance           p≈7.223074e-05\n",
            "  content-rank 35: little             p≈7.160415e-05\n",
            "  content-rank 36: fucking            p≈6.991077e-05\n",
            "  content-rank 37: summer             p≈6.987371e-05\n",
            "  content-rank 38: weekend            p≈6.295993e-05\n",
            "  content-rank 39: minute             p≈5.838366e-05\n",
            "  content-rank 40: career             p≈5.533013e-05\n",
            "  content-rank 41: morning            p≈5.366566e-05\n",
            "  content-rank 42: shot               p≈5.040480e-05\n",
            "  content-rank 43: bunch              p≈4.933626e-05\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 23: four               p≈9.007804e-04\n",
            "  content-rank 24: like               p≈8.807870e-04\n",
            "  content-rank 25: leaving            p≈8.667679e-04\n",
            "  content-rank 26: another            p≈8.471932e-04\n",
            "  content-rank 27: see                p≈8.464567e-04\n",
            "  content-rank 28: fire               p≈7.996319e-04\n",
            "  content-rank 29: most               p≈7.849496e-04\n",
            "  content-rank 30: ten                p≈7.491185e-04\n",
            "  content-rank 31: both               p≈7.188061e-04\n",
            "  content-rank 32: great              p≈6.673890e-04\n",
            "  content-rank 33: look               p≈6.336283e-04\n",
            "  content-rank 34: long               p≈5.995823e-04\n",
            "  content-rank 35: until              p≈5.839930e-04\n",
            "  content-rank 36: rose               p≈5.817074e-04\n",
            "  content-rank 37: blood              p≈5.776254e-04\n",
            "  content-rank 38: other              p≈5.761641e-04\n",
            "  content-rank 39: put                p≈5.746847e-04\n",
            "  content-rank 40: looking            p≈5.669676e-04\n",
            "  content-rank 41: along              p≈5.619978e-04\n",
            "  content-rank 42: out                p≈5.597897e-04\n",
            "  content-rank 43: suddenly           p≈5.424798e-04\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 23: north              p≈5.338973e-03\n",
            "  content-rank 24: blue               p≈5.140398e-03\n",
            "  content-rank 25: days               p≈4.798145e-03\n",
            "  content-rank 26: summer             p≈4.789331e-03\n",
            "  content-rank 27: dark               p≈4.757429e-03\n",
            "  content-rank 28: south              p≈4.624022e-03\n",
            "  content-rank 29: memory             p≈4.617958e-03\n",
            "  content-rank 30: skies              p≈4.493122e-03\n",
            "  content-rank 31: evening            p≈4.228182e-03\n",
            "  content-rank 32: wind               p≈4.197647e-03\n",
            "  content-rank 33: stars              p≈3.981111e-03\n",
            "  content-rank 34: black              p≈3.895184e-03\n",
            "  content-rank 35: world              p≈3.893401e-03\n",
            "  content-rank 36: fields             p≈3.550558e-03\n",
            "  content-rank 37: years              p≈3.535016e-03\n",
            "  content-rank 38: star               p≈3.496685e-03\n",
            "  content-rank 39: twilight           p≈3.292309e-03\n",
            "  content-rank 40: shadow             p≈3.151193e-03\n",
            "  content-rank 41: middle             p≈3.140896e-03\n",
            "  content-rank 42: darkness           p≈3.125787e-03\n",
            "  content-rank 43: countryside        p≈3.048049e-03\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 23: let                p≈3.104745e-03\n",
            "  content-rank 24: know               p≈3.072416e-03\n",
            "  content-rank 25: exceed             p≈2.852337e-03\n",
            "  content-rank 26: add                p≈2.846967e-03\n",
            "  content-rank 27: wonder             p≈2.815173e-03\n",
            "  content-rank 28: use                p≈2.749708e-03\n",
            "  content-rank 29: lose               p≈2.667997e-03\n",
            "  content-rank 30: light              p≈2.596983e-03\n",
            "  content-rank 31: return             p≈2.571275e-03\n",
            "  content-rank 32: ask                p≈2.288964e-03\n",
            "  content-rank 33: keep               p≈2.256160e-03\n",
            "  content-rank 34: write              p≈2.196594e-03\n",
            "  content-rank 35: blame              p≈2.167544e-03\n",
            "  content-rank 36: set                p≈2.137068e-03\n",
            "  content-rank 37: show               p≈2.075968e-03\n",
            "  content-rank 38: come               p≈2.058054e-03\n",
            "  content-rank 39: bring              p≈2.019726e-03\n",
            "  content-rank 40: disturb            p≈1.887381e-03\n",
            "  content-rank 41: talk               p≈1.845137e-03\n",
            "  content-rank 42: call               p≈1.795998e-03\n",
            "  content-rank 43: find               p≈1.790662e-03\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 23: especially         p≈8.445737e-04\n",
            "  content-rank 24: man                p≈8.119832e-04\n",
            "  content-rank 25: bell               p≈8.011041e-04\n",
            "  content-rank 26: voices             p≈7.925263e-04\n",
            "  content-rank 27: except             p≈7.780815e-04\n",
            "  content-rank 28: hear               p≈7.706788e-04\n",
            "  content-rank 29: whatever           p≈7.622582e-04\n",
            "  content-rank 30: thunder            p≈7.181269e-04\n",
            "  content-rank 31: drums              p≈7.039256e-04\n",
            "  content-rank 32: drum               p≈7.035497e-04\n",
            "  content-rank 33: music              p≈6.690922e-04\n",
            "  content-rank 34: anything           p≈6.425080e-04\n",
            "  content-rank 35: boom               p≈6.402278e-04\n",
            "  content-rank 36: another            p≈6.381698e-04\n",
            "  content-rank 37: making             p≈6.370023e-04\n",
            "  content-rank 38: make               p≈6.181580e-04\n",
            "  content-rank 39: suddenly           p≈6.173096e-04\n",
            "  content-rank 40: whether            p≈6.116744e-04\n",
            "  content-rank 41: thus               p≈6.074470e-04\n",
            "  content-rank 42: comes              p≈5.746456e-04\n",
            "  content-rank 43: saying             p≈5.694043e-04\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'In the sound of a few ,'\n",
            "  content-rank 23: words              p≈8.481996e-04\n",
            "  content-rank 24: loud               p≈7.721767e-04\n",
            "  content-rank 25: sometimes          p≈7.600429e-04\n",
            "  content-rank 26: suddenly           p≈6.847791e-04\n",
            "  content-rank 27: click              p≈6.808356e-04\n",
            "  content-rank 28: lines              p≈6.778864e-04\n",
            "  content-rank 29: right              p≈6.388007e-04\n",
            "  content-rank 30: especially         p≈6.213757e-04\n",
            "  content-rank 31: back               p≈5.950598e-04\n",
            "  content-rank 32: three              p≈5.911096e-04\n",
            "  content-rank 33: almost             p≈5.804333e-04\n",
            "  content-rank 34: players            p≈5.770511e-04\n",
            "  content-rank 35: shots              p≈5.628113e-04\n",
            "  content-rank 36: sound              p≈5.179089e-04\n",
            "  content-rank 37: make               p≈5.107009e-04\n",
            "  content-rank 38: high               p≈5.000061e-04\n",
            "  content-rank 39: voice              p≈4.881217e-04\n",
            "  content-rank 40: saying             p≈4.783411e-04\n",
            "  content-rank 41: using              p≈4.661814e-04\n",
            "  content-rank 42: making             p≈4.493976e-04\n",
            "  content-rank 43: look               p≈4.490891e-04\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'Which is the sound of the'\n",
            "  content-rank 23: sea                p≈2.954793e-03\n",
            "  content-rank 24: explosion          p≈2.944599e-03\n",
            "  content-rank 25: rain               p≈2.916806e-03\n",
            "  content-rank 26: horn               p≈2.768032e-03\n",
            "  content-rank 27: dog                p≈2.678287e-03\n",
            "  content-rank 28: trumpet            p≈2.674713e-03\n",
            "  content-rank 29: crowd              p≈2.597807e-03\n",
            "  content-rank 30: drums              p≈2.584719e-03\n",
            "  content-rank 31: earth              p≈2.546045e-03\n",
            "  content-rank 32: world              p≈2.486914e-03\n",
            "  content-rank 33: two                p≈2.482724e-03\n",
            "  content-rank 34: ocean              p≈2.313941e-03\n",
            "  content-rank 35: moon               p≈2.293256e-03\n",
            "  content-rank 36: police             p≈2.292609e-03\n",
            "  content-rank 37: war                p≈2.288816e-03\n",
            "  content-rank 38: ground             p≈2.261478e-03\n",
            "  content-rank 39: birds              p≈2.244084e-03\n",
            "  content-rank 40: ball               p≈2.242715e-03\n",
            "  content-rank 41: metal              p≈2.232489e-03\n",
            "  content-rank 42: machine            p≈2.177432e-03\n",
            "  content-rank 43: engines            p≈2.110439e-03\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Full of the same'\n",
            "  content-rank 23: amount             p≈2.584317e-03\n",
            "  content-rank 24: class              p≈2.573162e-03\n",
            "  content-rank 25: colors             p≈2.523835e-03\n",
            "  content-rank 26: level              p≈2.499404e-03\n",
            "  content-rank 27: things             p≈2.476701e-03\n",
            "  content-rank 28: game               p≈2.450089e-03\n",
            "  content-rank 29: order              p≈2.272021e-03\n",
            "  content-rank 30: spirit             p≈2.106830e-03\n",
            "  content-rank 31: quality            p≈2.095240e-03\n",
            "  content-rank 32: group              p≈2.061293e-03\n",
            "  content-rank 33: flavor             p≈1.974508e-03\n",
            "  content-rank 34: product            p≈1.892228e-03\n",
            "  content-rank 35: week               p≈1.775009e-03\n",
            "  content-rank 36: basic              p≈1.770018e-03\n",
            "  content-rank 37: effect             p≈1.725379e-03\n",
            "  content-rank 38: style              p≈1.708703e-03\n",
            "  content-rank 39: brand              p≈1.682135e-03\n",
            "  content-rank 40: problem            p≈1.677892e-03\n",
            "  content-rank 41: design             p≈1.664263e-03\n",
            "  content-rank 42: age                p≈1.656220e-03\n",
            "  content-rank 43: number             p≈1.626219e-03\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 23: spot               p≈7.919451e-03\n",
            "  content-rank 24: light              p≈7.382416e-03\n",
            "  content-rank 25: bones              p≈7.025083e-03\n",
            "  content-rank 26: toe                p≈6.820642e-03\n",
            "  content-rank 27: black              p≈6.659084e-03\n",
            "  content-rank 28: metal              p≈6.508104e-03\n",
            "  content-rank 29: white              p≈6.092657e-03\n",
            "  content-rank 30: pocket             p≈5.747414e-03\n",
            "  content-rank 31: blue               p≈5.241311e-03\n",
            "  content-rank 32: throat             p≈4.876651e-03\n",
            "  content-rank 33: wood               p≈4.485320e-03\n",
            "  content-rank 34: spots              p≈4.084523e-03\n",
            "  content-rank 35: dirt               p≈3.824895e-03\n",
            "  content-rank 36: hole               p≈3.581033e-03\n",
            "  content-rank 37: areas              p≈3.390169e-03\n",
            "  content-rank 38: body               p≈3.274578e-03\n",
            "  content-rank 39: shoulder           p≈3.245726e-03\n",
            "  content-rank 40: ground             p≈3.207961e-03\n",
            "  content-rank 41: front              p≈3.181297e-03\n",
            "  content-rank 42: middle             p≈3.166405e-03\n",
            "  content-rank 43: palms              p≈3.099362e-03\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 23: now                p≈1.437430e-03\n",
            "  content-rank 24: set                p≈1.430986e-03\n",
            "  content-rank 25: try                p≈1.419568e-03\n",
            "  content-rank 26: right              p≈1.371721e-03\n",
            "  content-rank 27: call               p≈1.316256e-03\n",
            "  content-rank 28: show               p≈1.271823e-03\n",
            "  content-rank 29: hear               p≈1.264190e-03\n",
            "  content-rank 30: check              p≈1.210429e-03\n",
            "  content-rank 31: both               p≈1.183318e-03\n",
            "  content-rank 32: instead            p≈1.062137e-03\n",
            "  content-rank 33: usually            p≈1.045231e-03\n",
            "  content-rank 34: expect             p≈9.945022e-04\n",
            "  content-rank 35: choose             p≈9.844168e-04\n",
            "  content-rank 36: audio              p≈9.584341e-04\n",
            "  content-rank 37: start              p≈9.532637e-04\n",
            "  content-rank 38: gets               p≈9.491778e-04\n",
            "  content-rank 39: take               p≈9.398748e-04\n",
            "  content-rank 40: like               p≈9.378548e-04\n",
            "  content-rank 41: select             p≈9.150188e-04\n",
            "  content-rank 42: next               p≈8.801395e-04\n",
            "  content-rank 43: says               p≈8.754116e-04\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'And, nothing himself,'\n",
            "  content-rank 23: like               p≈1.640816e-03\n",
            "  content-rank 24: little             p≈1.581682e-03\n",
            "  content-rank 25: actually           p≈1.518363e-03\n",
            "  content-rank 26: said               p≈1.488893e-03\n",
            "  content-rank 27: whether            p≈1.460708e-03\n",
            "  content-rank 28: according          p≈1.359070e-03\n",
            "  content-rank 29: certainly          p≈1.333516e-03\n",
            "  content-rank 30: especially         p≈1.288520e-03\n",
            "  content-rank 31: despite            p≈1.172254e-03\n",
            "  content-rank 32: quite              p≈1.166855e-03\n",
            "  content-rank 33: apparently         p≈1.056976e-03\n",
            "  content-rank 34: probably           p≈1.052117e-03\n",
            "  content-rank 35: aside              p≈1.035734e-03\n",
            "  content-rank 36: says               p≈1.012583e-03\n",
            "  content-rank 37: right              p≈1.008051e-03\n",
            "  content-rank 38: maybe              p≈1.003830e-03\n",
            "  content-rank 39: obviously          p≈9.602609e-04\n",
            "  content-rank 40: instead            p≈9.083664e-04\n",
            "  content-rank 41: sir                p≈9.031835e-04\n",
            "  content-rank 42: mind               p≈8.988871e-04\n",
            "  content-rank 43: now                p≈8.827596e-04\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 23: Everything         p≈1.206515e-04\n",
            "  content-rank 24: However            p≈1.183251e-04\n",
            "  content-rank 25: Whether            p≈1.168592e-04\n",
            "  content-rank 26: name               p≈1.163042e-04\n",
            "  content-rank 27: dll                p≈1.156132e-04\n",
            "  content-rank 28: put                p≈1.148229e-04\n",
            "  content-rank 29: list               p≈1.147538e-04\n",
            "  content-rank 30: Please             p≈1.147109e-04\n",
            "  content-rank 31: Sometimes          p≈1.124226e-04\n",
            "  content-rank 32: said               p≈1.123104e-04\n",
            "  content-rank 33: Remember           p≈1.114695e-04\n",
            "  content-rank 34: Rem                p≈1.112172e-04\n",
            "  content-rank 35: demon              p≈1.086127e-04\n",
            "  content-rank 36: asc                p≈1.069321e-04\n",
            "  content-rank 37: Come               p≈1.049078e-04\n",
            "  content-rank 38: get                p≈1.032223e-04\n",
            "  content-rank 39: Maybe              p≈1.012992e-04\n",
            "  content-rank 40: Another            p≈9.957208e-05\n",
            "  content-rank 41: put                p≈9.941116e-05\n",
            "  content-rank 42: text               p≈9.457480e-05\n",
            "  content-rank 43: Take               p≈9.084559e-05\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# This script: CODE 3\n",
        "#  WORDLIKE ranks 23–43, but ONLY \"content-word\" candidates\n",
        "# (filters out common function words: articles, pronouns, conjunctions, etc.)\n",
        "#\n",
        "# IMPORTANT:\n",
        "# - GPT-2 doesn't output POS tags, so \"nouns/verbs/adjectives\" is approximated by\n",
        "#   removing function words via a stopword list + simple heuristics.\n",
        "# - Ranks here are computed AFTER filtering to word-like tokens, then we keep only\n",
        "#   those that pass the content-word filter, and report the ones whose content-rank\n",
        "#   falls in 23..43.\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---- Remove last word per line (each line = one phrase) ----\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line); removed.append(last_word)\n",
        "    return new_lines, removed\n",
        "\n",
        "# ---- Word-like tokens (single \"word\") ----\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# ---- Function-word filter (remove articles/pronouns/conjunctions + more) ----\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # (extra common function words—optional but improves “semantic” feel)\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def ranked_content_window(prompt: str, tokenizer, model, start_rank: int = 23, end_rank: int = 43, max_wordlike_scan: int = 5000):\n",
        "    \"\"\"\n",
        "    1) Get GPT-2 next-token probabilities\n",
        "    2) Walk tokens by probability, keep WORDLIKE tokens\n",
        "    3) Among WORDLIKE tokens, keep only content-word ones\n",
        "    4) Return those whose *content-word rank* is in [start_rank, end_rank]\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        piece = tokenizer.decode([tid])\n",
        "        w = piece.strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                # scanned a lot but not enough content words\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# ---- Load model ----\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# ---- Run per line ----\n",
        "lines, removed = remove_last_word_per_line(poem)\n",
        "START_R, END_R = 23, 43\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(lines):\n",
        "    print(f\"{i}: {l}\")\n",
        "\n",
        "print(f\"\\n=== CONTENT-WORD ranks {START_R}–{END_R} per line ===\")\n",
        "for i, line in enumerate(lines):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = ranked_content_window(\n",
        "        line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=20000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "    else:\n",
        "        for r, w, p in window:\n",
        "            print(f\"  content-rank {r:>2}: {w:<18} p≈{p:.6e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60mYK8znADCJ",
        "outputId": "4d8369e0-9536-4df6-8ace-5c06b8eb4d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "Line 1: One must have a mind of\n",
            "Line 2: To regard the frost and the\n",
            "Line 3: Of the pine-trees crusted with ;\n",
            "Line 4: And have been cold a long\n",
            "Line 5: To behold the junipers shagged with ,\n",
            "Line 6: The spruces rough in the distant\n",
            "Line 7: Of the January sun; and not to\n",
            "Line 8: Of any misery in the sound of the ,\n",
            "Line 9: In the sound of a few ,\n",
            "Line 10: Which is the sound of the\n",
            "Line 11: Full of the same\n",
            "Line 12: That is blowing in the same bare\n",
            "Line 13: For the listener, who listens in the ,\n",
            "Line 14: And, nothing himself,\n",
            "Line 15: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n",
            "\n",
            "=== Choose by CONTENT-RANK number (23–43) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  content-rank 23: integrity          p≈1.157843e-03\n",
            "  content-rank 24: common             p≈1.150411e-03\n",
            "  content-rank 25: humour             p≈1.136575e-03\n",
            "  content-rank 26: power              p≈1.088183e-03\n",
            "  content-rank 27: two                p≈1.083188e-03\n",
            "  content-rank 28: stone              p≈1.028237e-03\n",
            "  content-rank 29: matter             p≈9.090302e-04\n",
            "  content-rank 30: trust              p≈8.565321e-04\n",
            "  content-rank 31: transparency       p≈8.288884e-04\n",
            "  content-rank 32: harmony            p≈8.119575e-04\n",
            "  content-rank 33: peace              p≈7.843328e-04\n",
            "  content-rank 34: hard               p≈7.420420e-04\n",
            "  content-rank 35: mastery            p≈6.565556e-04\n",
            "  content-rank 36: flux               p≈6.524560e-04\n",
            "  content-rank 37: control            p≈6.425612e-04\n",
            "  content-rank 38: style              p≈6.351526e-04\n",
            "  content-rank 39: language           p≈6.303926e-04\n",
            "  content-rank 40: scale              p≈6.288986e-04\n",
            "  content-rank 41: action             p≈6.042109e-04\n",
            "  content-rank 42: gratitude          p≈6.024526e-04\n",
            "  content-rank 43: love               p≈6.002870e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  content-rank 23: light              p≈2.565519e-03\n",
            "  content-rank 24: loss               p≈2.564619e-03\n",
            "  content-rank 25: lightning          p≈2.564580e-03\n",
            "  content-rank 26: weather            p≈2.524396e-03\n",
            "  content-rank 27: thunder            p≈2.411223e-03\n",
            "  content-rank 28: smoke              p≈2.401126e-03\n",
            "  content-rank 29: burning            p≈2.293549e-03\n",
            "  content-rank 30: fact               p≈2.262802e-03\n",
            "  content-rank 31: winter             p≈2.249153e-03\n",
            "  content-rank 32: chill              p≈2.229744e-03\n",
            "  content-rank 33: great              p≈2.218240e-03\n",
            "  content-rank 34: falling            p≈2.154212e-03\n",
            "  content-rank 35: ensuing            p≈2.051427e-03\n",
            "  content-rank 36: moon               p≈2.027775e-03\n",
            "  content-rank 37: war                p≈2.017944e-03\n",
            "  content-rank 38: fog                p≈1.972537e-03\n",
            "  content-rank 39: effect             p≈1.920401e-03\n",
            "  content-rank 40: consequ            p≈1.909866e-03\n",
            "  content-rank 41: black              p≈1.904206e-03\n",
            "  content-rank 42: rising             p≈1.826095e-03\n",
            "  content-rank 43: earth              p≈1.819948e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 23: wood               p≈9.734706e-04\n",
            "  content-rank 24: three              p≈9.640399e-04\n",
            "  content-rank 25: words              p≈9.610656e-04\n",
            "  content-rank 26: branches           p≈8.977617e-04\n",
            "  content-rank 27: fire               p≈8.953265e-04\n",
            "  content-rank 28: poison             p≈8.852806e-04\n",
            "  content-rank 29: seeds              p≈8.509309e-04\n",
            "  content-rank 30: frost              p≈7.817165e-04\n",
            "  content-rank 31: like               p≈7.812633e-04\n",
            "  content-rank 32: green              p≈7.705723e-04\n",
            "  content-rank 33: ung                p≈7.601437e-04\n",
            "  content-rank 34: see                p≈7.405266e-04\n",
            "  content-rank 35: man                p≈7.067286e-04\n",
            "  content-rank 36: tobacco            p≈7.066315e-04\n",
            "  content-rank 37: rocks              p≈6.849221e-04\n",
            "  content-rank 38: ter                p≈6.650254e-04\n",
            "  content-rank 39: berries            p≈6.611401e-04\n",
            "  content-rank 40: grains             p≈6.564056e-04\n",
            "  content-rank 41: ing                p≈6.536371e-04\n",
            "  content-rank 42: notes              p≈6.363995e-04\n",
            "  content-rank 43: note               p≈6.309318e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  content-rank 23: term               p≈1.281507e-04\n",
            "  content-rank 24: winter             p≈1.232879e-04\n",
            "  content-rank 25: longer             p≈1.229863e-04\n",
            "  content-rank 26: haul               p≈1.079022e-04\n",
            "  content-rank 27: month              p≈1.076407e-04\n",
            "  content-rank 28: amount             p≈1.057397e-04\n",
            "  content-rank 29: wait               p≈1.045477e-04\n",
            "  content-rank 30: rest               p≈8.839200e-05\n",
            "  content-rank 31: Time               p≈8.501581e-05\n",
            "  content-rank 32: run                p≈8.098321e-05\n",
            "  content-rank 33: whilst             p≈7.479872e-05\n",
            "  content-rank 34: distance           p≈7.223074e-05\n",
            "  content-rank 35: little             p≈7.160415e-05\n",
            "  content-rank 36: fucking            p≈6.991077e-05\n",
            "  content-rank 37: summer             p≈6.987371e-05\n",
            "  content-rank 38: weekend            p≈6.295993e-05\n",
            "  content-rank 39: minute             p≈5.838366e-05\n",
            "  content-rank 40: career             p≈5.533013e-05\n",
            "  content-rank 41: morning            p≈5.366566e-05\n",
            "  content-rank 42: shot               p≈5.040480e-05\n",
            "  content-rank 43: bunch              p≈4.933626e-05\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 23: four               p≈9.007804e-04\n",
            "  content-rank 24: like               p≈8.807870e-04\n",
            "  content-rank 25: leaving            p≈8.667679e-04\n",
            "  content-rank 26: another            p≈8.471932e-04\n",
            "  content-rank 27: see                p≈8.464567e-04\n",
            "  content-rank 28: fire               p≈7.996319e-04\n",
            "  content-rank 29: most               p≈7.849496e-04\n",
            "  content-rank 30: ten                p≈7.491185e-04\n",
            "  content-rank 31: both               p≈7.188061e-04\n",
            "  content-rank 32: great              p≈6.673890e-04\n",
            "  content-rank 33: look               p≈6.336283e-04\n",
            "  content-rank 34: long               p≈5.995823e-04\n",
            "  content-rank 35: until              p≈5.839930e-04\n",
            "  content-rank 36: rose               p≈5.817074e-04\n",
            "  content-rank 37: blood              p≈5.776254e-04\n",
            "  content-rank 38: other              p≈5.761641e-04\n",
            "  content-rank 39: put                p≈5.746847e-04\n",
            "  content-rank 40: looking            p≈5.669676e-04\n",
            "  content-rank 41: along              p≈5.619978e-04\n",
            "  content-rank 42: out                p≈5.597897e-04\n",
            "  content-rank 43: suddenly           p≈5.424798e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 23: north              p≈5.338973e-03\n",
            "  content-rank 24: blue               p≈5.140398e-03\n",
            "  content-rank 25: days               p≈4.798145e-03\n",
            "  content-rank 26: summer             p≈4.789331e-03\n",
            "  content-rank 27: dark               p≈4.757429e-03\n",
            "  content-rank 28: south              p≈4.624022e-03\n",
            "  content-rank 29: memory             p≈4.617958e-03\n",
            "  content-rank 30: skies              p≈4.493122e-03\n",
            "  content-rank 31: evening            p≈4.228182e-03\n",
            "  content-rank 32: wind               p≈4.197647e-03\n",
            "  content-rank 33: stars              p≈3.981111e-03\n",
            "  content-rank 34: black              p≈3.895184e-03\n",
            "  content-rank 35: world              p≈3.893401e-03\n",
            "  content-rank 36: fields             p≈3.550558e-03\n",
            "  content-rank 37: years              p≈3.535016e-03\n",
            "  content-rank 38: star               p≈3.496685e-03\n",
            "  content-rank 39: twilight           p≈3.292309e-03\n",
            "  content-rank 40: shadow             p≈3.151193e-03\n",
            "  content-rank 41: middle             p≈3.140896e-03\n",
            "  content-rank 42: darkness           p≈3.125787e-03\n",
            "  content-rank 43: countryside        p≈3.048049e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 23: let                p≈3.104745e-03\n",
            "  content-rank 24: know               p≈3.072416e-03\n",
            "  content-rank 25: exceed             p≈2.852337e-03\n",
            "  content-rank 26: add                p≈2.846967e-03\n",
            "  content-rank 27: wonder             p≈2.815173e-03\n",
            "  content-rank 28: use                p≈2.749708e-03\n",
            "  content-rank 29: lose               p≈2.667997e-03\n",
            "  content-rank 30: light              p≈2.596983e-03\n",
            "  content-rank 31: return             p≈2.571275e-03\n",
            "  content-rank 32: ask                p≈2.288964e-03\n",
            "  content-rank 33: keep               p≈2.256160e-03\n",
            "  content-rank 34: write              p≈2.196594e-03\n",
            "  content-rank 35: blame              p≈2.167544e-03\n",
            "  content-rank 36: set                p≈2.137068e-03\n",
            "  content-rank 37: show               p≈2.075968e-03\n",
            "  content-rank 38: come               p≈2.058054e-03\n",
            "  content-rank 39: bring              p≈2.019726e-03\n",
            "  content-rank 40: disturb            p≈1.887381e-03\n",
            "  content-rank 41: talk               p≈1.845137e-03\n",
            "  content-rank 42: call               p≈1.795998e-03\n",
            "  content-rank 43: find               p≈1.790662e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 23: especially         p≈8.445737e-04\n",
            "  content-rank 24: man                p≈8.119832e-04\n",
            "  content-rank 25: bell               p≈8.011041e-04\n",
            "  content-rank 26: voices             p≈7.925263e-04\n",
            "  content-rank 27: except             p≈7.780815e-04\n",
            "  content-rank 28: hear               p≈7.706788e-04\n",
            "  content-rank 29: whatever           p≈7.622582e-04\n",
            "  content-rank 30: thunder            p≈7.181269e-04\n",
            "  content-rank 31: drums              p≈7.039256e-04\n",
            "  content-rank 32: drum               p≈7.035497e-04\n",
            "  content-rank 33: music              p≈6.690922e-04\n",
            "  content-rank 34: anything           p≈6.425080e-04\n",
            "  content-rank 35: boom               p≈6.402278e-04\n",
            "  content-rank 36: another            p≈6.381698e-04\n",
            "  content-rank 37: making             p≈6.370023e-04\n",
            "  content-rank 38: make               p≈6.181580e-04\n",
            "  content-rank 39: suddenly           p≈6.173096e-04\n",
            "  content-rank 40: whether            p≈6.116744e-04\n",
            "  content-rank 41: thus               p≈6.074470e-04\n",
            "  content-rank 42: comes              p≈5.746456e-04\n",
            "  content-rank 43: saying             p≈5.694043e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  content-rank 23: words              p≈8.481996e-04\n",
            "  content-rank 24: loud               p≈7.721767e-04\n",
            "  content-rank 25: sometimes          p≈7.600429e-04\n",
            "  content-rank 26: suddenly           p≈6.847791e-04\n",
            "  content-rank 27: click              p≈6.808356e-04\n",
            "  content-rank 28: lines              p≈6.778864e-04\n",
            "  content-rank 29: right              p≈6.388007e-04\n",
            "  content-rank 30: especially         p≈6.213757e-04\n",
            "  content-rank 31: back               p≈5.950598e-04\n",
            "  content-rank 32: three              p≈5.911096e-04\n",
            "  content-rank 33: almost             p≈5.804333e-04\n",
            "  content-rank 34: players            p≈5.770511e-04\n",
            "  content-rank 35: shots              p≈5.628113e-04\n",
            "  content-rank 36: sound              p≈5.179089e-04\n",
            "  content-rank 37: make               p≈5.107009e-04\n",
            "  content-rank 38: high               p≈5.000061e-04\n",
            "  content-rank 39: voice              p≈4.881217e-04\n",
            "  content-rank 40: saying             p≈4.783411e-04\n",
            "  content-rank 41: using              p≈4.661814e-04\n",
            "  content-rank 42: making             p≈4.493976e-04\n",
            "  content-rank 43: look               p≈4.490891e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  content-rank 23: sea                p≈2.954793e-03\n",
            "  content-rank 24: explosion          p≈2.944599e-03\n",
            "  content-rank 25: rain               p≈2.916806e-03\n",
            "  content-rank 26: horn               p≈2.768032e-03\n",
            "  content-rank 27: dog                p≈2.678287e-03\n",
            "  content-rank 28: trumpet            p≈2.674713e-03\n",
            "  content-rank 29: crowd              p≈2.597807e-03\n",
            "  content-rank 30: drums              p≈2.584719e-03\n",
            "  content-rank 31: earth              p≈2.546045e-03\n",
            "  content-rank 32: world              p≈2.486914e-03\n",
            "  content-rank 33: two                p≈2.482724e-03\n",
            "  content-rank 34: ocean              p≈2.313941e-03\n",
            "  content-rank 35: moon               p≈2.293256e-03\n",
            "  content-rank 36: police             p≈2.292609e-03\n",
            "  content-rank 37: war                p≈2.288816e-03\n",
            "  content-rank 38: ground             p≈2.261478e-03\n",
            "  content-rank 39: birds              p≈2.244084e-03\n",
            "  content-rank 40: ball               p≈2.242715e-03\n",
            "  content-rank 41: metal              p≈2.232489e-03\n",
            "  content-rank 42: machine            p≈2.177432e-03\n",
            "  content-rank 43: engines            p≈2.110439e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  content-rank 23: amount             p≈2.584317e-03\n",
            "  content-rank 24: class              p≈2.573162e-03\n",
            "  content-rank 25: colors             p≈2.523835e-03\n",
            "  content-rank 26: level              p≈2.499404e-03\n",
            "  content-rank 27: things             p≈2.476701e-03\n",
            "  content-rank 28: game               p≈2.450089e-03\n",
            "  content-rank 29: order              p≈2.272021e-03\n",
            "  content-rank 30: spirit             p≈2.106830e-03\n",
            "  content-rank 31: quality            p≈2.095240e-03\n",
            "  content-rank 32: group              p≈2.061293e-03\n",
            "  content-rank 33: flavor             p≈1.974508e-03\n",
            "  content-rank 34: product            p≈1.892228e-03\n",
            "  content-rank 35: week               p≈1.775009e-03\n",
            "  content-rank 36: basic              p≈1.770018e-03\n",
            "  content-rank 37: effect             p≈1.725379e-03\n",
            "  content-rank 38: style              p≈1.708703e-03\n",
            "  content-rank 39: brand              p≈1.682135e-03\n",
            "  content-rank 40: problem            p≈1.677892e-03\n",
            "  content-rank 41: design             p≈1.664263e-03\n",
            "  content-rank 42: age                p≈1.656220e-03\n",
            "  content-rank 43: number             p≈1.626219e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 23: spot               p≈7.919451e-03\n",
            "  content-rank 24: light              p≈7.382416e-03\n",
            "  content-rank 25: bones              p≈7.025083e-03\n",
            "  content-rank 26: toe                p≈6.820642e-03\n",
            "  content-rank 27: black              p≈6.659084e-03\n",
            "  content-rank 28: metal              p≈6.508104e-03\n",
            "  content-rank 29: white              p≈6.092657e-03\n",
            "  content-rank 30: pocket             p≈5.747414e-03\n",
            "  content-rank 31: blue               p≈5.241311e-03\n",
            "  content-rank 32: throat             p≈4.876651e-03\n",
            "  content-rank 33: wood               p≈4.485320e-03\n",
            "  content-rank 34: spots              p≈4.084523e-03\n",
            "  content-rank 35: dirt               p≈3.824895e-03\n",
            "  content-rank 36: hole               p≈3.581033e-03\n",
            "  content-rank 37: areas              p≈3.390169e-03\n",
            "  content-rank 38: body               p≈3.274578e-03\n",
            "  content-rank 39: shoulder           p≈3.245726e-03\n",
            "  content-rank 40: ground             p≈3.207961e-03\n",
            "  content-rank 41: front              p≈3.181297e-03\n",
            "  content-rank 42: middle             p≈3.166405e-03\n",
            "  content-rank 43: palms              p≈3.099362e-03\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 23: now                p≈1.437430e-03\n",
            "  content-rank 24: set                p≈1.430986e-03\n",
            "  content-rank 25: try                p≈1.419568e-03\n",
            "  content-rank 26: right              p≈1.371721e-03\n",
            "  content-rank 27: call               p≈1.316256e-03\n",
            "  content-rank 28: show               p≈1.271823e-03\n",
            "  content-rank 29: hear               p≈1.264190e-03\n",
            "  content-rank 30: check              p≈1.210429e-03\n",
            "  content-rank 31: both               p≈1.183318e-03\n",
            "  content-rank 32: instead            p≈1.062137e-03\n",
            "  content-rank 33: usually            p≈1.045231e-03\n",
            "  content-rank 34: expect             p≈9.945022e-04\n",
            "  content-rank 35: choose             p≈9.844168e-04\n",
            "  content-rank 36: audio              p≈9.584341e-04\n",
            "  content-rank 37: start              p≈9.532637e-04\n",
            "  content-rank 38: gets               p≈9.491778e-04\n",
            "  content-rank 39: take               p≈9.398748e-04\n",
            "  content-rank 40: like               p≈9.378548e-04\n",
            "  content-rank 41: select             p≈9.150188e-04\n",
            "  content-rank 42: next               p≈8.801395e-04\n",
            "  content-rank 43: says               p≈8.754116e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  content-rank 23: like               p≈1.640816e-03\n",
            "  content-rank 24: little             p≈1.581682e-03\n",
            "  content-rank 25: actually           p≈1.518363e-03\n",
            "  content-rank 26: said               p≈1.488893e-03\n",
            "  content-rank 27: whether            p≈1.460708e-03\n",
            "  content-rank 28: according          p≈1.359070e-03\n",
            "  content-rank 29: certainly          p≈1.333516e-03\n",
            "  content-rank 30: especially         p≈1.288520e-03\n",
            "  content-rank 31: despite            p≈1.172254e-03\n",
            "  content-rank 32: quite              p≈1.166855e-03\n",
            "  content-rank 33: apparently         p≈1.056976e-03\n",
            "  content-rank 34: probably           p≈1.052117e-03\n",
            "  content-rank 35: aside              p≈1.035734e-03\n",
            "  content-rank 36: says               p≈1.012583e-03\n",
            "  content-rank 37: right              p≈1.008051e-03\n",
            "  content-rank 38: maybe              p≈1.003830e-03\n",
            "  content-rank 39: obviously          p≈9.602609e-04\n",
            "  content-rank 40: instead            p≈9.083664e-04\n",
            "  content-rank 41: sir                p≈9.031835e-04\n",
            "  content-rank 42: mind               p≈8.988871e-04\n",
            "  content-rank 43: now                p≈8.827596e-04\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 23: Everything         p≈1.206515e-04\n",
            "  content-rank 24: However            p≈1.183251e-04\n",
            "  content-rank 25: Whether            p≈1.168592e-04\n",
            "  content-rank 26: name               p≈1.163042e-04\n",
            "  content-rank 27: dll                p≈1.156132e-04\n",
            "  content-rank 28: put                p≈1.148229e-04\n",
            "  content-rank 29: list               p≈1.147538e-04\n",
            "  content-rank 30: Please             p≈1.147109e-04\n",
            "  content-rank 31: Sometimes          p≈1.124226e-04\n",
            "  content-rank 32: said               p≈1.123104e-04\n",
            "  content-rank 33: Remember           p≈1.114695e-04\n",
            "  content-rank 34: Rem                p≈1.112172e-04\n",
            "  content-rank 35: demon              p≈1.086127e-04\n",
            "  content-rank 36: asc                p≈1.069321e-04\n",
            "  content-rank 37: Come               p≈1.049078e-04\n",
            "  content-rank 38: get                p≈1.032223e-04\n",
            "  content-rank 39: Maybe              p≈1.012992e-04\n",
            "  content-rank 40: Another            p≈9.957208e-05\n",
            "  content-rank 41: put                p≈9.941116e-05\n",
            "  content-rank 42: text               p≈9.457480e-05\n",
            "  content-rank 43: Take               p≈9.084559e-05\n",
            "Type the CONTENT-RANK you want (23–43): 39\n",
            "\n",
            "=== NEW POEM (CONTENT-WINDOW FILTER) ===\n",
            "One must have a mind of language\n",
            "To regard the frost and the effect\n",
            "Of the pine-trees crusted with berries;\n",
            "And have been cold a long minute\n",
            "To behold the junipers shagged with put,\n",
            "The spruces rough in the distant twilight\n",
            "Of the January sun; and not to bring\n",
            "Of any misery in the sound of the suddenly,\n",
            "In the sound of a few voice,\n",
            "Which is the sound of the birds\n",
            "Full of the same brand\n",
            "That is blowing in the same bare shoulder\n",
            "For the listener, who listens in the take,\n",
            "And, nothing himself, obviously\n",
            "Nothing that is not there and the nothing that Maybe.\n",
            "\n",
            "Saved to: PX_poem_semantic_r23_43.txt\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# CONTENT-WORD window ranks 23–43 per line (GPT-2)\n",
        "# Choose by CONTENT-RANK number (23..43)\n",
        "# Rebuild line word BEFORE punctuation\n",
        "# Save to \"PX_poem_semantic_r23_43.txt\"\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Split each line into: before + last_word + trailing punctuation\n",
        "#    (used to rebuild correctly later)\n",
        "# -----------------------------------------------------\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "# Prompts must match your original logic: prompt = before + trailing (punctuation kept)\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(prompts_lines, start=1):\n",
        "    print(f\"Line {i}: {l}\")\n",
        "\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Word-like + stopword filter (semantic-ish)\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # extra common function words\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Get content-word candidates whose CONTENT-RANK is in [start_rank, end_rank]\n",
        "# -----------------------------------------------------\n",
        "def ranked_content_window(prompt: str, tokenizer, model, start_rank: int = 23, end_rank: int = 43, max_wordlike_scan: int = 20000):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []  # list of (content_rank, word, prob)\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Load model\n",
        "# -----------------------------------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive: choose by CONTENT-RANK number (23..43)\n",
        "# -----------------------------------------------------\n",
        "START_R, END_R = 23, 43\n",
        "new_lines = []\n",
        "\n",
        "print(f\"\\n=== Choose by CONTENT-RANK number ({START_R}–{END_R}) ===\")\n",
        "\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = ranked_content_window(\n",
        "        prompt_line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=20000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    # show all ranks 23..43 that exist\n",
        "    rank_to_word = {}\n",
        "    for r, w, p in window:\n",
        "        rank_to_word[r] = (w, p)\n",
        "        print(f\"  content-rank {r:>2}: {w:<18} p≈{p:.6e}\")\n",
        "\n",
        "    valid_ranks = sorted(rank_to_word.keys())\n",
        "\n",
        "    while True:\n",
        "        raw = input(f\"Type the CONTENT-RANK you want ({valid_ranks[0]}–{valid_ranks[-1]}): \").strip()\n",
        "        if raw.isdigit():\n",
        "            chosen_rank = int(raw)\n",
        "            if chosen_rank in rank_to_word:\n",
        "                chosen_word = rank_to_word[chosen_rank][0]\n",
        "                break\n",
        "        print(f\"Invalid. Choose one of these ranks: {valid_ranks}\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (CONTENT-WINDOW FILTER) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"PX_poem_semantic_r23_43.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzRM9JsuftGX",
        "outputId": "f8e3f246-39b5-4a41-eee8-657b6da2266a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "0: One must have a mind of\n",
            "1: To regard the frost and the\n",
            "2: Of the pine-trees crusted with ;\n",
            "3: And have been cold a long\n",
            "4: To behold the junipers shagged with ,\n",
            "5: The spruces rough in the distant\n",
            "6: Of the January sun; and not to\n",
            "7: Of any misery in the sound of the ,\n",
            "8: In the sound of a few ,\n",
            "9: Which is the sound of the\n",
            "10: Full of the same\n",
            "11: That is blowing in the same bare\n",
            "12: For the listener, who listens in the ,\n",
            "13: And, nothing himself,\n",
            "14: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== CONTENT-WORD ranks 150–160 per line ===\n",
            "\n",
            "================================================================================\n",
            "Line 0 prompt: 'One must have a mind of'\n",
            "  content-rank 150: clear              p≈2.116131e-04\n",
            "  content-rank 151: proportion         p≈2.112066e-04\n",
            "  content-rank 152: open               p≈2.061693e-04\n",
            "  content-rank 153: personal           p≈2.041018e-04\n",
            "  content-rank 154: communication      p≈2.028661e-04\n",
            "  content-rank 155: prophecy           p≈2.015056e-04\n",
            "  content-rank 156: honesty            p≈1.996585e-04\n",
            "  content-rank 157: new                p≈1.989924e-04\n",
            "  content-rank 158: terror             p≈1.989317e-04\n",
            "  content-rank 159: like               p≈1.988588e-04\n",
            "  content-rank 160: certain            p≈1.983891e-04\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'To regard the frost and the'\n",
            "  content-rank 150: river              p≈7.310907e-04\n",
            "  content-rank 151: magic              p≈7.309847e-04\n",
            "  content-rank 152: arrows             p≈7.268804e-04\n",
            "  content-rank 153: changes            p≈7.264868e-04\n",
            "  content-rank 154: final              p≈7.260712e-04\n",
            "  content-rank 155: inf                p≈7.223637e-04\n",
            "  content-rank 156: silence            p≈7.206242e-04\n",
            "  content-rank 157: sharp              p≈7.159061e-04\n",
            "  content-rank 158: end                p≈7.133218e-04\n",
            "  content-rank 159: evil               p≈7.125930e-04\n",
            "  content-rank 160: imp                p≈7.125712e-04\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 150: fruit              p≈2.902135e-04\n",
            "  content-rank 151: leaf               p≈2.883442e-04\n",
            "  content-rank 152: certain            p≈2.879507e-04\n",
            "  content-rank 153: names              p≈2.878452e-04\n",
            "  content-rank 154: pear               p≈2.844830e-04\n",
            "  content-rank 155: roses              p≈2.840146e-04\n",
            "  content-rank 156: gre                p≈2.803077e-04\n",
            "  content-rank 157: plant              p≈2.800854e-04\n",
            "  content-rank 158: anything           p≈2.788125e-04\n",
            "  content-rank 159: who                p≈2.778675e-04\n",
            "  content-rank 160: put                p≈2.777129e-04\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'And have been cold a long'\n",
            "  content-rank 150: growing            p≈8.817743e-06\n",
            "  content-rank 151: black              p≈8.784103e-06\n",
            "  content-rank 152: beating            p≈8.776399e-06\n",
            "  content-rank 153: handful            p≈8.671868e-06\n",
            "  content-rank 154: range              p≈8.620153e-06\n",
            "  content-rank 155: sorry              p≈8.620120e-06\n",
            "  content-rank 156: holiday            p≈8.588544e-06\n",
            "  content-rank 157: like               p≈8.429080e-06\n",
            "  content-rank 158: gone               p≈8.382584e-06\n",
            "  content-rank 159: thousand           p≈8.319477e-06\n",
            "  content-rank 160: state              p≈8.317510e-06\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 150: nearly             p≈2.414468e-04\n",
            "  content-rank 151: sharp              p≈2.390056e-04\n",
            "  content-rank 152: shot               p≈2.353738e-04\n",
            "  content-rank 153: glass              p≈2.342666e-04\n",
            "  content-rank 154: signs              p≈2.336615e-04\n",
            "  content-rank 155: thus               p≈2.336472e-04\n",
            "  content-rank 156: thunder            p≈2.317971e-04\n",
            "  content-rank 157: give               p≈2.272583e-04\n",
            "  content-rank 158: wood               p≈2.231724e-04\n",
            "  content-rank 159: arms               p≈2.226095e-04\n",
            "  content-rank 160: come               p≈2.212735e-04\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 150: tree               p≈8.241981e-04\n",
            "  content-rank 151: gloom              p≈8.230293e-04\n",
            "  content-rank 152: mist               p≈8.124732e-04\n",
            "  content-rank 153: bow                p≈8.033385e-04\n",
            "  content-rank 154: areas              p≈8.006706e-04\n",
            "  content-rank 155: road               p≈7.734240e-04\n",
            "  content-rank 156: rocks              p≈7.725336e-04\n",
            "  content-rank 157: street             p≈7.716676e-04\n",
            "  content-rank 158: fire               p≈7.673174e-04\n",
            "  content-rank 159: purple             p≈7.580250e-04\n",
            "  content-rank 160: next               p≈7.506127e-04\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 150: fright             p≈5.939722e-04\n",
            "  content-rank 151: seem               p≈5.932431e-04\n",
            "  content-rank 152: hope               p≈5.908716e-04\n",
            "  content-rank 153: despise            p≈5.878097e-04\n",
            "  content-rank 154: smoke              p≈5.864569e-04\n",
            "  content-rank 155: laugh              p≈5.690991e-04\n",
            "  content-rank 156: celebrate          p≈5.661629e-04\n",
            "  content-rank 157: reflect            p≈5.628123e-04\n",
            "  content-rank 158: end                p≈5.606095e-04\n",
            "  content-rank 159: wear               p≈5.604555e-04\n",
            "  content-rank 160: help               p≈5.600752e-04\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 150: next               p≈2.142303e-04\n",
            "  content-rank 151: drop               p≈2.132779e-04\n",
            "  content-rank 152: till               p≈2.129706e-04\n",
            "  content-rank 153: said               p≈2.101990e-04\n",
            "  content-rank 154: door               p≈2.098208e-04\n",
            "  content-rank 155: syll               p≈2.094561e-04\n",
            "  content-rank 156: note               p≈2.092868e-04\n",
            "  content-rank 157: read               p≈2.079594e-04\n",
            "  content-rank 158: low                p≈2.051481e-04\n",
            "  content-rank 159: name               p≈2.048540e-04\n",
            "  content-rank 160: following          p≈2.041644e-04\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'In the sound of a few ,'\n",
            "  content-rank 150: quite              p≈2.083779e-04\n",
            "  content-rank 151: cut                p≈2.075481e-04\n",
            "  content-rank 152: note               p≈2.069962e-04\n",
            "  content-rank 153: various            p≈2.066774e-04\n",
            "  content-rank 154: usually            p≈2.045565e-04\n",
            "  content-rank 155: come               p≈2.009830e-04\n",
            "  content-rank 156: local              p≈1.990967e-04\n",
            "  content-rank 157: notes              p≈1.960099e-04\n",
            "  content-rank 158: think              p≈1.957141e-04\n",
            "  content-rank 159: moments            p≈1.948366e-04\n",
            "  content-rank 160: white              p≈1.939808e-04\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'Which is the sound of the'\n",
            "  content-rank 150: bomb               p≈8.750494e-04\n",
            "  content-rank 151: pipe               p≈8.707540e-04\n",
            "  content-rank 152: street             p≈8.695855e-04\n",
            "  content-rank 153: gunshots           p≈8.687764e-04\n",
            "  content-rank 154: waters             p≈8.648151e-04\n",
            "  content-rank 155: falling            p≈8.614501e-04\n",
            "  content-rank 156: baby               p≈8.594676e-04\n",
            "  content-rank 157: elevator           p≈8.589759e-04\n",
            "  content-rank 158: breeze             p≈8.541791e-04\n",
            "  content-rank 159: white              p≈8.371212e-04\n",
            "  content-rank 160: moment             p≈8.358512e-04\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Full of the same'\n",
            "  content-rank 150: vintage            p≈6.356910e-04\n",
            "  content-rank 151: film               p≈6.321315e-04\n",
            "  content-rank 152: two                p≈6.290621e-04\n",
            "  content-rank 153: liquid             p≈6.272505e-04\n",
            "  content-rank 154: scope              p≈6.266621e-04\n",
            "  content-rank 155: look               p≈6.265904e-04\n",
            "  content-rank 156: skin               p≈6.255634e-04\n",
            "  content-rank 157: goes               p≈6.236002e-04\n",
            "  content-rank 158: hair               p≈6.217000e-04\n",
            "  content-rank 159: picture            p≈6.214535e-04\n",
            "  content-rank 160: metal              p≈6.166220e-04\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 150: color              p≈7.760141e-04\n",
            "  content-rank 151: scale              p≈7.741809e-04\n",
            "  content-rank 152: darkness           p≈7.723874e-04\n",
            "  content-rank 153: side               p≈7.475392e-04\n",
            "  content-rank 154: path               p≈7.356521e-04\n",
            "  content-rank 155: fist               p≈7.328345e-04\n",
            "  content-rank 156: shade              p≈7.303673e-04\n",
            "  content-rank 157: walls              p≈7.282307e-04\n",
            "  content-rank 158: little             p≈7.128607e-04\n",
            "  content-rank 159: shadow             p≈7.093885e-04\n",
            "  content-rank 160: sand               p≈7.049858e-04\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 150: input              p≈2.849209e-04\n",
            "  content-rank 151: back               p≈2.831700e-04\n",
            "  content-rank 152: runs               p≈2.821650e-04\n",
            "  content-rank 153: ask                p≈2.790543e-04\n",
            "  content-rank 154: left               p≈2.779473e-04\n",
            "  content-rank 155: maybe              p≈2.777099e-04\n",
            "  content-rank 156: test               p≈2.749817e-04\n",
            "  content-rank 157: inspect            p≈2.747049e-04\n",
            "  content-rank 158: stream             p≈2.742798e-04\n",
            "  content-rank 159: perform            p≈2.731500e-04\n",
            "  content-rank 160: sort               p≈2.707722e-04\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'And, nothing himself,'\n",
            "  content-rank 150: free               p≈1.521024e-04\n",
            "  content-rank 151: honestly           p≈1.515695e-04\n",
            "  content-rank 152: true               p≈1.492606e-04\n",
            "  content-rank 153: three              p≈1.466330e-04\n",
            "  content-rank 154: Michael            p≈1.451592e-04\n",
            "  content-rank 155: basically          p≈1.436280e-04\n",
            "  content-rank 156: Thomas             p≈1.424016e-04\n",
            "  content-rank 157: mere               p≈1.418431e-04\n",
            "  content-rank 158: somehow            p≈1.410005e-04\n",
            "  content-rank 159: Professor          p≈1.396217e-04\n",
            "  content-rank 160: thanks             p≈1.392154e-04\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 150: wav                p≈3.226620e-05\n",
            "  content-rank 151: Except             p≈3.216666e-05\n",
            "  content-rank 152: info               p≈3.211222e-05\n",
            "  content-rank 153: close              p≈3.147574e-05\n",
            "  content-rank 154: Tell               p≈3.116177e-05\n",
            "  content-rank 155: Obviously          p≈3.111995e-05\n",
            "  content-rank 156: List               p≈3.071519e-05\n",
            "  content-rank 157: isn                p≈3.064964e-05\n",
            "  content-rank 158: Find               p≈3.052503e-05\n",
            "  content-rank 159: Suppose            p≈3.025192e-05\n",
            "  content-rank 160: David              p≈3.023853e-05\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "#This script: CODE 4\n",
        "# Semantic CONTENT-WORD ranks 150–160 per line (GPT-2)\n",
        "# Variant 1: filter out function words (articles/pronouns/conjunctions/etc.)\n",
        "#\n",
        "# IMPORTANT:\n",
        "# - GPT-2 doesn't output tags, so \"nouns/verbs/adjectives\" is approximated by:\n",
        "#   (a) keep WORDLIKE tokens, (b) remove common function words via STOPWORDS + heuristics.\n",
        "# - The ranks 150–160 are computed among CONTENT-WORD candidates only.\n",
        "# =========================\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---- Remove last word per line (each line = one phrase) ----\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def remove_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    new_lines, removed = [], []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            new_lines.append(line); removed.append(\"\"); continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        new_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "        new_lines.append(new_line); removed.append(last_word)\n",
        "    return new_lines, removed\n",
        "\n",
        "# ---- Word-like tokens (single \"word\") ----\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "# ---- Function-word filter ----\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # (extra common function words—optional but improves “semantic” feel)\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def content_rank_window(prompt: str, tokenizer, model, start_rank: int = 150, end_rank: int = 160, max_wordlike_scan: int = 200000):\n",
        "    \"\"\"\n",
        "    Build CONTENT-WORD ranking (semantic-ish):\n",
        "    - sort all next tokens by probability\n",
        "    - keep WORDLIKE tokens\n",
        "    - keep only those passing is_content_word\n",
        "    - assign ranks among content words only\n",
        "    - return those in [start_rank, end_rank]\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# ---- Load model ----\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# ---- Run per line ----\n",
        "lines, removed = remove_last_word_per_line(poem)\n",
        "START_R, END_R = 150, 160\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(lines):\n",
        "    print(f\"{i}: {l}\")\n",
        "\n",
        "print(f\"\\n=== CONTENT-WORD ranks {START_R}–{END_R} per line ===\")\n",
        "for i, line in enumerate(lines):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = content_rank_window(\n",
        "        line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=200000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {line!r}\")\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "    else:\n",
        "        for r, w, p in window:\n",
        "            print(f\"  content-rank {r:>3}: {w:<18} p≈{p:.6e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e04643454e3d497290e3d0887a74a951",
            "e6b28ff7cc8842c0a1e070b08d7ecd3f",
            "aa3c5478df394a3289fbea4fe8c0189f",
            "09c99dea5dcd48eeae50543aa9160bcc",
            "cc7af1d7677c47c9bae87a7aedf1adc8",
            "20fdaa5408a744e8a3c9e6345ec97332",
            "1a2368d4b7eb456db0690c7541310758",
            "d6bf5fea15c94ffb93d78df46765a10b",
            "cefc169674494aaa806af41b8a553451",
            "e711c2d7b11242b19d42249b7c4eef72",
            "2eb2656de2a04e6eae76de67b9f25f60",
            "02a851757f644f3ba135c1410fc20d5e",
            "dca611e2fc774d65adb89208e33b0660",
            "d7baa7ed228648c093cc3f12b83f96de",
            "e452a17450c74c8284c67463fc8d7cd9",
            "fbb668e7a2d74231b5f55bac5c271fc5",
            "022a1e72beeb4de3815274ca2e91dda6",
            "4ca1af44488c420caf9f4715903d8d96",
            "b426fc5f2d244a6280fa7c229a1f4201",
            "310464c353984b6fbf64186f0357c155",
            "4ac641ba770c4135b453822c79ff69e6",
            "8e4d892694fd49ffbc0a6187a179ff0a",
            "055537f4172849c0bc02f388a54d800a",
            "85d986f86fef47fd86f304c8fce3e2d4",
            "e9c7de5e78bb45e1a8cecd53fc50da38",
            "2f965dd7c1484556b7a0ab011ba32881",
            "123d4b8a29994d20b5e326ae32cb8e44",
            "d53ed760a815425fb4d5cf248a4c0376",
            "f2b2f2e4eaf548b0bdc45b021712e281",
            "e50b222e5f05443292a4e81957d415c7",
            "320f289a8c0341148cac77c46b65c28e",
            "dec676462add4e128cb971b7851f5c9b",
            "53e50f7a0a1845e6a2411d097e8b2f17",
            "73291be41b35489d87c6c93bae4b4970",
            "66faf75a181d46928ce1dbc4d3aa696b",
            "74e683811ff8417192088b2a0415a943",
            "e4254e8969874aee922cfaaf0fe785a5",
            "70bd74466a89436bbafb55aae44d7e4e",
            "fef00927df4743af890f169eb1ceeb90",
            "6dc3766ecf174b5c917d2502192a93f7",
            "5e53d1f00fc24b8bbfb12cf5d18f9cc8",
            "2ff78fb7e3f44d6e8d1291d6924bd6b2",
            "cf12cdcd39ce433a8b93b92fbcc9c861",
            "d4caf0c197f74385860e7b79f1d2c6f9",
            "0e88340bd9aa40fd9341d3ffd7a5e801",
            "9c97f978d852491dbcddc444bfed6a9b",
            "edef3532b64246219c7ecd32b45db043",
            "8b2138319fbd417bb101ae2e8410ab42",
            "ffb41572e79a465193b8863b0fe66d0e",
            "b54d28bc0720415294b81f99814aeec6",
            "11381acd7b7f420cba14055c9d115023",
            "6910f4c1375548bd95b91715817430a9",
            "c628ad53ee974435abda27ecb975e291",
            "4f7c117783074146b57b6f6469b09e2c",
            "42aa2fdf92a949ccbc9e83b70b0ae4aa",
            "571115dba6f9499d9cc071b6a365c356",
            "de28748ff69c43ff8e22b9b92f2065c2",
            "60d109087c4c49baa6a60467a968573d",
            "25485f5a7d4246a2a2098a1ca2a436c6",
            "eea34904cf314742838ab42e06d80aac",
            "08dd432e5b5c4c408b9dc54ecabc33ab",
            "d1410f07342f4d6492acca06b32abeb9",
            "56b5beff99d942d5af5f290e77522874",
            "38706ac509a9464391af57cce4427a11",
            "2514c7344473487faa59cd3fa110692f",
            "50b639ea7f354ba5a9c1847d6c198d41",
            "582c9b16becf44afb42f30db052bea6a",
            "e8673b165b604edcb70659bc33250fbb",
            "00c283dba58b4b0fb654298f4ee26035",
            "5d72e0eb51254387b1c6487b56fa56d1",
            "9ce8da935faa4d9aa4be0c3eaca7565a",
            "94f8fb1ff35a4cc6adb609dcc6f683b5",
            "747f16417f964e9f900db03c09b17482",
            "7b1c73d8e3e6477fb910560367807c90",
            "aa62f1a483d946de81bf8b391722ed76",
            "37c155759a0f40de9a83637125397834",
            "315e5b485caa462c985bc0be55ce8dd8"
          ]
        },
        "id": "CRIFHicsBjz9",
        "outputId": "936e672a-e4e4-49cf-df97-bb46a3c644c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prompts (missing last word) ===\n",
            "Line 1: One must have a mind of\n",
            "Line 2: To regard the frost and the\n",
            "Line 3: Of the pine-trees crusted with ;\n",
            "Line 4: And have been cold a long\n",
            "Line 5: To behold the junipers shagged with ,\n",
            "Line 6: The spruces rough in the distant\n",
            "Line 7: Of the January sun; and not to\n",
            "Line 8: Of any misery in the sound of the ,\n",
            "Line 9: In the sound of a few ,\n",
            "Line 10: Which is the sound of the\n",
            "Line 11: Full of the same\n",
            "Line 12: That is blowing in the same bare\n",
            "Line 13: For the listener, who listens in the ,\n",
            "Line 14: And, nothing himself,\n",
            "Line 15: Nothing that is not there and the nothing that .\n",
            "\n",
            "=== Removed last words (reference) ===\n",
            "['winter', 'boughs', 'snow', 'time', 'ice', 'glitter', 'think', 'wind', 'leaves', 'land', 'wind', 'place', 'snow', 'beholds', 'is']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e04643454e3d497290e3d0887a74a951"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02a851757f644f3ba135c1410fc20d5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "055537f4172849c0bc02f388a54d800a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73291be41b35489d87c6c93bae4b4970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e88340bd9aa40fd9341d3ffd7a5e801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "571115dba6f9499d9cc071b6a365c356"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "582c9b16becf44afb42f30db052bea6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Choose by CONTENT-RANK number (150–160) ===\n",
            "\n",
            "================================================================================\n",
            "Line 1 prompt: 'One must have a mind of'\n",
            "  content-rank 150: clear              p≈2.116131e-04\n",
            "  content-rank 151: proportion         p≈2.112066e-04\n",
            "  content-rank 152: open               p≈2.061693e-04\n",
            "  content-rank 153: personal           p≈2.041018e-04\n",
            "  content-rank 154: communication      p≈2.028661e-04\n",
            "  content-rank 155: prophecy           p≈2.015056e-04\n",
            "  content-rank 156: honesty            p≈1.996585e-04\n",
            "  content-rank 157: new                p≈1.989924e-04\n",
            "  content-rank 158: terror             p≈1.989317e-04\n",
            "  content-rank 159: like               p≈1.988588e-04\n",
            "  content-rank 160: certain            p≈1.983891e-04\n",
            "Type the CONTENT-RANK you want (150–160): 153\n",
            "\n",
            "================================================================================\n",
            "Line 2 prompt: 'To regard the frost and the'\n",
            "  content-rank 150: river              p≈7.310907e-04\n",
            "  content-rank 151: magic              p≈7.309847e-04\n",
            "  content-rank 152: arrows             p≈7.268804e-04\n",
            "  content-rank 153: changes            p≈7.264868e-04\n",
            "  content-rank 154: final              p≈7.260712e-04\n",
            "  content-rank 155: inf                p≈7.223637e-04\n",
            "  content-rank 156: silence            p≈7.206242e-04\n",
            "  content-rank 157: sharp              p≈7.159061e-04\n",
            "  content-rank 158: end                p≈7.133218e-04\n",
            "  content-rank 159: evil               p≈7.125930e-04\n",
            "  content-rank 160: imp                p≈7.125712e-04\n",
            "Type the CONTENT-RANK you want (150–160): 151\n",
            "\n",
            "================================================================================\n",
            "Line 3 prompt: 'Of the pine-trees crusted with ;'\n",
            "  content-rank 150: fruit              p≈2.902135e-04\n",
            "  content-rank 151: leaf               p≈2.883442e-04\n",
            "  content-rank 152: certain            p≈2.879507e-04\n",
            "  content-rank 153: names              p≈2.878452e-04\n",
            "  content-rank 154: pear               p≈2.844830e-04\n",
            "  content-rank 155: roses              p≈2.840146e-04\n",
            "  content-rank 156: gre                p≈2.803077e-04\n",
            "  content-rank 157: plant              p≈2.800854e-04\n",
            "  content-rank 158: anything           p≈2.788125e-04\n",
            "  content-rank 159: who                p≈2.778675e-04\n",
            "  content-rank 160: put                p≈2.777129e-04\n",
            "Type the CONTENT-RANK you want (150–160): 160\n",
            "\n",
            "================================================================================\n",
            "Line 4 prompt: 'And have been cold a long'\n",
            "  content-rank 150: growing            p≈8.817743e-06\n",
            "  content-rank 151: black              p≈8.784103e-06\n",
            "  content-rank 152: beating            p≈8.776399e-06\n",
            "  content-rank 153: handful            p≈8.671868e-06\n",
            "  content-rank 154: range              p≈8.620153e-06\n",
            "  content-rank 155: sorry              p≈8.620120e-06\n",
            "  content-rank 156: holiday            p≈8.588544e-06\n",
            "  content-rank 157: like               p≈8.429080e-06\n",
            "  content-rank 158: gone               p≈8.382584e-06\n",
            "  content-rank 159: thousand           p≈8.319477e-06\n",
            "  content-rank 160: state              p≈8.317510e-06\n",
            "Type the CONTENT-RANK you want (150–160): 158\n",
            "\n",
            "================================================================================\n",
            "Line 5 prompt: 'To behold the junipers shagged with ,'\n",
            "  content-rank 150: nearly             p≈2.414468e-04\n",
            "  content-rank 151: sharp              p≈2.390056e-04\n",
            "  content-rank 152: shot               p≈2.353738e-04\n",
            "  content-rank 153: glass              p≈2.342666e-04\n",
            "  content-rank 154: signs              p≈2.336615e-04\n",
            "  content-rank 155: thus               p≈2.336472e-04\n",
            "  content-rank 156: thunder            p≈2.317971e-04\n",
            "  content-rank 157: give               p≈2.272583e-04\n",
            "  content-rank 158: wood               p≈2.231724e-04\n",
            "  content-rank 159: arms               p≈2.226095e-04\n",
            "  content-rank 160: come               p≈2.212735e-04\n",
            "Type the CONTENT-RANK you want (150–160): 157\n",
            "\n",
            "================================================================================\n",
            "Line 6 prompt: 'The spruces rough in the distant'\n",
            "  content-rank 150: tree               p≈8.241981e-04\n",
            "  content-rank 151: gloom              p≈8.230293e-04\n",
            "  content-rank 152: mist               p≈8.124732e-04\n",
            "  content-rank 153: bow                p≈8.033385e-04\n",
            "  content-rank 154: areas              p≈8.006706e-04\n",
            "  content-rank 155: road               p≈7.734240e-04\n",
            "  content-rank 156: rocks              p≈7.725336e-04\n",
            "  content-rank 157: street             p≈7.716676e-04\n",
            "  content-rank 158: fire               p≈7.673174e-04\n",
            "  content-rank 159: purple             p≈7.580250e-04\n",
            "  content-rank 160: next               p≈7.506127e-04\n",
            "Type the CONTENT-RANK you want (150–160): 159\n",
            "\n",
            "================================================================================\n",
            "Line 7 prompt: 'Of the January sun; and not to'\n",
            "  content-rank 150: fright             p≈5.939722e-04\n",
            "  content-rank 151: seem               p≈5.932431e-04\n",
            "  content-rank 152: hope               p≈5.908716e-04\n",
            "  content-rank 153: despise            p≈5.878097e-04\n",
            "  content-rank 154: smoke              p≈5.864569e-04\n",
            "  content-rank 155: laugh              p≈5.690991e-04\n",
            "  content-rank 156: celebrate          p≈5.661629e-04\n",
            "  content-rank 157: reflect            p≈5.628123e-04\n",
            "  content-rank 158: end                p≈5.606095e-04\n",
            "  content-rank 159: wear               p≈5.604555e-04\n",
            "  content-rank 160: help               p≈5.600752e-04\n",
            "Type the CONTENT-RANK you want (150–160): 153\n",
            "\n",
            "================================================================================\n",
            "Line 8 prompt: 'Of any misery in the sound of the ,'\n",
            "  content-rank 150: next               p≈2.142303e-04\n",
            "  content-rank 151: drop               p≈2.132779e-04\n",
            "  content-rank 152: till               p≈2.129706e-04\n",
            "  content-rank 153: said               p≈2.101990e-04\n",
            "  content-rank 154: door               p≈2.098208e-04\n",
            "  content-rank 155: syll               p≈2.094561e-04\n",
            "  content-rank 156: note               p≈2.092868e-04\n",
            "  content-rank 157: read               p≈2.079594e-04\n",
            "  content-rank 158: low                p≈2.051481e-04\n",
            "  content-rank 159: name               p≈2.048540e-04\n",
            "  content-rank 160: following          p≈2.041644e-04\n",
            "Type the CONTENT-RANK you want (150–160): 152\n",
            "\n",
            "================================================================================\n",
            "Line 9 prompt: 'In the sound of a few ,'\n",
            "  content-rank 150: quite              p≈2.083779e-04\n",
            "  content-rank 151: cut                p≈2.075481e-04\n",
            "  content-rank 152: note               p≈2.069962e-04\n",
            "  content-rank 153: various            p≈2.066774e-04\n",
            "  content-rank 154: usually            p≈2.045565e-04\n",
            "  content-rank 155: come               p≈2.009830e-04\n",
            "  content-rank 156: local              p≈1.990967e-04\n",
            "  content-rank 157: notes              p≈1.960099e-04\n",
            "  content-rank 158: think              p≈1.957141e-04\n",
            "  content-rank 159: moments            p≈1.948366e-04\n",
            "  content-rank 160: white              p≈1.939808e-04\n",
            "Type the CONTENT-RANK you want (150–160): 155\n",
            "\n",
            "================================================================================\n",
            "Line 10 prompt: 'Which is the sound of the'\n",
            "  content-rank 150: bomb               p≈8.750494e-04\n",
            "  content-rank 151: pipe               p≈8.707540e-04\n",
            "  content-rank 152: street             p≈8.695855e-04\n",
            "  content-rank 153: gunshots           p≈8.687764e-04\n",
            "  content-rank 154: waters             p≈8.648151e-04\n",
            "  content-rank 155: falling            p≈8.614501e-04\n",
            "  content-rank 156: baby               p≈8.594676e-04\n",
            "  content-rank 157: elevator           p≈8.589759e-04\n",
            "  content-rank 158: breeze             p≈8.541791e-04\n",
            "  content-rank 159: white              p≈8.371212e-04\n",
            "  content-rank 160: moment             p≈8.358512e-04\n",
            "Type the CONTENT-RANK you want (150–160): 156\n",
            "\n",
            "================================================================================\n",
            "Line 11 prompt: 'Full of the same'\n",
            "  content-rank 150: vintage            p≈6.356910e-04\n",
            "  content-rank 151: film               p≈6.321315e-04\n",
            "  content-rank 152: two                p≈6.290621e-04\n",
            "  content-rank 153: liquid             p≈6.272505e-04\n",
            "  content-rank 154: scope              p≈6.266621e-04\n",
            "  content-rank 155: look               p≈6.265904e-04\n",
            "  content-rank 156: skin               p≈6.255634e-04\n",
            "  content-rank 157: goes               p≈6.236002e-04\n",
            "  content-rank 158: hair               p≈6.217000e-04\n",
            "  content-rank 159: picture            p≈6.214535e-04\n",
            "  content-rank 160: metal              p≈6.166220e-04\n",
            "Type the CONTENT-RANK you want (150–160): 151\n",
            "\n",
            "================================================================================\n",
            "Line 12 prompt: 'That is blowing in the same bare'\n",
            "  content-rank 150: color              p≈7.760141e-04\n",
            "  content-rank 151: scale              p≈7.741809e-04\n",
            "  content-rank 152: darkness           p≈7.723874e-04\n",
            "  content-rank 153: side               p≈7.475392e-04\n",
            "  content-rank 154: path               p≈7.356521e-04\n",
            "  content-rank 155: fist               p≈7.328345e-04\n",
            "  content-rank 156: shade              p≈7.303673e-04\n",
            "  content-rank 157: walls              p≈7.282307e-04\n",
            "  content-rank 158: little             p≈7.128607e-04\n",
            "  content-rank 159: shadow             p≈7.093885e-04\n",
            "  content-rank 160: sand               p≈7.049858e-04\n",
            "Type the CONTENT-RANK you want (150–160): 150\n",
            "\n",
            "================================================================================\n",
            "Line 13 prompt: 'For the listener, who listens in the ,'\n",
            "  content-rank 150: input              p≈2.849209e-04\n",
            "  content-rank 151: back               p≈2.831700e-04\n",
            "  content-rank 152: runs               p≈2.821650e-04\n",
            "  content-rank 153: ask                p≈2.790543e-04\n",
            "  content-rank 154: left               p≈2.779473e-04\n",
            "  content-rank 155: maybe              p≈2.777099e-04\n",
            "  content-rank 156: test               p≈2.749817e-04\n",
            "  content-rank 157: inspect            p≈2.747049e-04\n",
            "  content-rank 158: stream             p≈2.742798e-04\n",
            "  content-rank 159: perform            p≈2.731500e-04\n",
            "  content-rank 160: sort               p≈2.707722e-04\n",
            "Type the CONTENT-RANK you want (150–160): 154\n",
            "\n",
            "================================================================================\n",
            "Line 14 prompt: 'And, nothing himself,'\n",
            "  content-rank 150: free               p≈1.521024e-04\n",
            "  content-rank 151: honestly           p≈1.515695e-04\n",
            "  content-rank 152: true               p≈1.492606e-04\n",
            "  content-rank 153: three              p≈1.466330e-04\n",
            "  content-rank 154: Michael            p≈1.451592e-04\n",
            "  content-rank 155: basically          p≈1.436280e-04\n",
            "  content-rank 156: Thomas             p≈1.424016e-04\n",
            "  content-rank 157: mere               p≈1.418431e-04\n",
            "  content-rank 158: somehow            p≈1.410005e-04\n",
            "  content-rank 159: Professor          p≈1.396217e-04\n",
            "  content-rank 160: thanks             p≈1.392154e-04\n",
            "Type the CONTENT-RANK you want (150–160): 157\n",
            "\n",
            "================================================================================\n",
            "Line 15 prompt: 'Nothing that is not there and the nothing that .'\n",
            "  content-rank 150: wav                p≈3.226620e-05\n",
            "  content-rank 151: Except             p≈3.216666e-05\n",
            "  content-rank 152: info               p≈3.211222e-05\n",
            "  content-rank 153: close              p≈3.147574e-05\n",
            "  content-rank 154: Tell               p≈3.116177e-05\n",
            "  content-rank 155: Obviously          p≈3.111995e-05\n",
            "  content-rank 156: List               p≈3.071519e-05\n",
            "  content-rank 157: isn                p≈3.064964e-05\n",
            "  content-rank 158: Find               p≈3.052503e-05\n",
            "  content-rank 159: Suppose            p≈3.025192e-05\n",
            "  content-rank 160: David              p≈3.023853e-05\n",
            "Type the CONTENT-RANK you want (150–160): 158\n",
            "\n",
            "=== NEW POEM (CONTENT-RANK 150–160 WINDOW) ===\n",
            "One must have a mind of personal\n",
            "To regard the frost and the magic\n",
            "Of the pine-trees crusted with put;\n",
            "And have been cold a long gone\n",
            "To behold the junipers shagged with give,\n",
            "The spruces rough in the distant purple\n",
            "Of the January sun; and not to despise\n",
            "Of any misery in the sound of the till,\n",
            "In the sound of a few come,\n",
            "Which is the sound of the baby\n",
            "Full of the same film\n",
            "That is blowing in the same bare color\n",
            "For the listener, who listens in the left,\n",
            "And, nothing himself, mere\n",
            "Nothing that is not there and the nothing that Find.\n",
            "\n",
            "Saved to: PX_poem_semantic_r150_160.txt\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# ranks 150–160 per line (GPT-2)\n",
        "# Choose by CONTENT-RANK number (150..160)\n",
        "# Rebuild line correctly (word BEFORE punctuation)\n",
        "# Save to PX_poem_r150_160.txt\n",
        "# =========================\n",
        "\n",
        "!pip -q install transformers torch\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---- Paste poem here ----\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "MODEL_NAME = \"openai-community/gpt2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1) Split each line into: before + last_word + trailing punctuation\n",
        "#    Build prompts like your original: prompt = before + trailing\n",
        "# -----------------------------------------------------\n",
        "pat_remove = re.compile(r\"^(.*?)(\\b[\\w']+\\b)([^\\w']*)$\")\n",
        "\n",
        "def split_last_word_per_line(poem: str):\n",
        "    lines = poem.splitlines()\n",
        "    parts = []\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        m = pat_remove.match(line)\n",
        "        if not m:\n",
        "            parts.append({\"original\": line, \"before\": line, \"last_word\": \"\", \"trailing\": \"\"})\n",
        "            continue\n",
        "        before, last_word, trailing = m.group(1), m.group(2), m.group(3)\n",
        "        parts.append({\"original\": line, \"before\": before, \"last_word\": last_word, \"trailing\": trailing})\n",
        "    return parts\n",
        "\n",
        "parts = split_last_word_per_line(poem)\n",
        "\n",
        "prompts_lines = []\n",
        "removed_words = []\n",
        "for d in parts:\n",
        "    before, trailing = d[\"before\"], d[\"trailing\"]\n",
        "    prompt_line = (before.rstrip() + (\" \" if trailing and not before.rstrip().endswith((\" \", \"\\t\")) else \"\") + trailing).rstrip()\n",
        "    prompts_lines.append(prompt_line)\n",
        "    removed_words.append(d[\"last_word\"])\n",
        "\n",
        "print(\"=== Prompts (missing last word) ===\")\n",
        "for i, l in enumerate(prompts_lines, start=1):\n",
        "    print(f\"Line {i}: {l}\")\n",
        "\n",
        "print(\"\\n=== Removed last words (reference) ===\")\n",
        "print(removed_words)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2) Word-like + stopword filter (semantic-ish)\n",
        "# -----------------------------------------------------\n",
        "WORDLIKE = re.compile(r\"^[A-Za-z]+(?:[-'][A-Za-z]+)*$\")\n",
        "\n",
        "STOPWORDS = {\n",
        "    # articles/determiners\n",
        "    \"a\",\"an\",\"the\",\"this\",\"that\",\"these\",\"those\",\"some\",\"any\",\"each\",\"every\",\"either\",\"neither\",\n",
        "    \"no\",\"many\",\"much\",\"few\",\"several\",\"such\",\"what\",\"which\",\"whose\",\n",
        "    # pronouns\n",
        "    \"i\",\"me\",\"my\",\"mine\",\"myself\",\"we\",\"us\",\"our\",\"ours\",\"ourselves\",\n",
        "    \"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
        "    \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\n",
        "    \"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\n",
        "    \"one\",\"ones\",\"someone\",\"somebody\",\"anyone\",\"anybody\",\"everyone\",\"everybody\",\"nothing\",\"something\",\n",
        "    # conjunctions\n",
        "    \"and\",\"or\",\"but\",\"nor\",\"so\",\"yet\",\"for\",\"although\",\"though\",\"because\",\"since\",\"unless\",\"while\",\"if\",\"than\",\n",
        "    # extra common function words\n",
        "    \"of\",\"to\",\"in\",\"on\",\"at\",\"by\",\"with\",\"from\",\"into\",\"onto\",\"over\",\"under\",\"between\",\"among\",\"through\",\"during\",\n",
        "    \"before\",\"after\",\"above\",\"below\",\"about\",\"against\",\"around\",\"across\",\"toward\",\"towards\",\"within\",\"without\",\"upon\",\n",
        "    \"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\"having\",\n",
        "    \"can\",\"could\",\"may\",\"might\",\"must\",\"shall\",\"should\",\"will\",\"would\",\n",
        "    \"not\",\"very\",\"too\",\"also\",\"just\",\"only\",\"even\",\"still\",\"then\",\"there\",\"here\",\"when\",\"where\",\"why\",\"how\",\"as\",\n",
        "}\n",
        "\n",
        "def is_content_word(w: str) -> bool:\n",
        "    wl = w.lower()\n",
        "    if not WORDLIKE.match(w):\n",
        "        return False\n",
        "    if len(wl) < 3:\n",
        "        return False\n",
        "    if wl in STOPWORDS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3) Content-rank window 150..160 (among content words only)\n",
        "# -----------------------------------------------------\n",
        "def content_rank_window(prompt: str, tokenizer, model, start_rank: int = 150, end_rank: int = 160, max_wordlike_scan: int = 200000):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits[0, -1, :]\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    sorted_ids = torch.argsort(probs, descending=True)\n",
        "\n",
        "    out = []\n",
        "    content_rank = 0\n",
        "    wordlike_seen = 0\n",
        "\n",
        "    for tid in sorted_ids.tolist():\n",
        "        w = tokenizer.decode([tid]).strip()\n",
        "\n",
        "        if w and WORDLIKE.match(w):\n",
        "            wordlike_seen += 1\n",
        "            if is_content_word(w):\n",
        "                content_rank += 1\n",
        "                if start_rank <= content_rank <= end_rank:\n",
        "                    out.append((content_rank, w, float(probs[tid].cpu())))\n",
        "                if content_rank > end_rank:\n",
        "                    break\n",
        "\n",
        "            if wordlike_seen >= max_wordlike_scan and content_rank < end_rank:\n",
        "                break\n",
        "\n",
        "    return out, content_rank, wordlike_seen\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4) Rebuild correctly: before + chosen_word + trailing\n",
        "# -----------------------------------------------------\n",
        "def rebuild_from_parts(before: str, chosen_word: str, trailing: str):\n",
        "    base = before.rstrip()\n",
        "    if base == \"\":\n",
        "        return f\"{chosen_word}{trailing}\"\n",
        "    return f\"{base} {chosen_word}{trailing}\"\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 5) Load model\n",
        "# -----------------------------------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6) Interactive: choose by CONTENT-RANK number 150..160\n",
        "# -----------------------------------------------------\n",
        "START_R, END_R = 150, 160\n",
        "new_lines = []\n",
        "\n",
        "print(f\"\\n=== Choose by CONTENT-RANK number ({START_R}–{END_R}) ===\")\n",
        "\n",
        "for i, prompt_line in enumerate(prompts_lines, start=1):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    if prompt_line.strip() == \"\":\n",
        "        print(f\"Line {i}: (blank)\")\n",
        "        new_lines.append(prompt_line)\n",
        "        continue\n",
        "\n",
        "    window, total_content_found, total_wordlike_scanned = content_rank_window(\n",
        "        prompt_line, tokenizer, model, start_rank=START_R, end_rank=END_R, max_wordlike_scan=200000\n",
        "    )\n",
        "\n",
        "    print(f\"Line {i} prompt: {prompt_line!r}\")\n",
        "\n",
        "    if not window:\n",
        "        print(f\"  (No content-word candidates in ranks {START_R}–{END_R}. \"\n",
        "              f\"Found {total_content_found} content words after scanning {total_wordlike_scanned} word-like tokens.)\")\n",
        "        # fallback: keep original line\n",
        "        new_lines.append(parts[i - 1][\"original\"])\n",
        "        continue\n",
        "\n",
        "    # show all available ranks in 150..160\n",
        "    rank_to_word = {}\n",
        "    for r, w, p in window:\n",
        "        rank_to_word[r] = (w, p)\n",
        "        print(f\"  content-rank {r:>3}: {w:<18} p≈{p:.6e}\")\n",
        "\n",
        "    valid_ranks = sorted(rank_to_word.keys())\n",
        "\n",
        "    while True:\n",
        "        raw = input(f\"Type the CONTENT-RANK you want ({START_R}–{END_R}): \").strip()\n",
        "        if raw.isdigit():\n",
        "            chosen_rank = int(raw)\n",
        "            if chosen_rank in rank_to_word:\n",
        "                chosen_word = rank_to_word[chosen_rank][0]\n",
        "                break\n",
        "        print(f\"Invalid. Choose one of these ranks: {valid_ranks}\")\n",
        "\n",
        "    before = parts[i - 1][\"before\"]\n",
        "    trailing = parts[i - 1][\"trailing\"]\n",
        "    new_lines.append(rebuild_from_parts(before, chosen_word, trailing))\n",
        "\n",
        "new_poem = \"\\n\".join(new_lines)\n",
        "\n",
        "print(\"\\n=== NEW POEM (CONTENT-RANK 150–160 WINDOW) ===\")\n",
        "print(new_poem)\n",
        "\n",
        "out_path = \"PX_poem_semantic_r150_160.txt\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(new_poem)\n",
        "\n",
        "print(f\"\\nSaved to: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ✅ Treat \"nothing\" as noun-like (spaCy often tags it as PRON)\n",
        "INCLUDE_NOTHING_AS_NOUN = True\n",
        "\n",
        "poem = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "\n",
        "def whitespace_chunks(line: str):\n",
        "    \"\"\"\n",
        "    Return list of (chunk_text, start, end) for each non-space chunk (\\S+).\n",
        "    Keeps hyphenated compounds like 'pine-trees' as one chunk.\n",
        "    \"\"\"\n",
        "    return [(m.group(0), m.start(), m.end()) for m in re.finditer(r\"\\S+\", line)]\n",
        "\n",
        "\n",
        "def extract_noun_chunks(line: str):\n",
        "    \"\"\"\n",
        "    True noun extraction at the CHUNK level:\n",
        "    - Split line into whitespace chunks\n",
        "    - Run spaCy on the line\n",
        "    - If any token overlapping a chunk is NOUN/PROPN, mark the whole chunk for removal\n",
        "    - Optionally also treat 'nothing' as noun-like\n",
        "    Returns list of chunk strings (lowercased, punctuation-trimmed).\n",
        "    \"\"\"\n",
        "    doc = nlp(line)\n",
        "    chunks = whitespace_chunks(line)\n",
        "\n",
        "    noun_chunks = []\n",
        "    for chunk_text, start, end in chunks:\n",
        "        toks = [\n",
        "            t for t in doc\n",
        "            if t.idx < end and (t.idx + len(t)) > start and not t.is_space\n",
        "        ]\n",
        "\n",
        "        is_nouny = any(t.pos_ in {\"NOUN\", \"PROPN\"} for t in toks)\n",
        "        if INCLUDE_NOTHING_AS_NOUN and any(t.lower_ == \"nothing\" for t in toks):\n",
        "            is_nouny = True\n",
        "\n",
        "        if is_nouny:\n",
        "            cleaned = chunk_text.strip(\" ,.;:!?\\\"“”‘’()[]{}\")\n",
        "            cleaned = re.sub(r\"[^A-Za-z\\-']\", \"\", cleaned)  # keep hyphens/apostrophes\n",
        "            if cleaned:\n",
        "                noun_chunks.append(cleaned.lower())\n",
        "\n",
        "    return noun_chunks\n",
        "\n",
        "\n",
        "def remove_words_from_line(line: str, words_to_remove):\n",
        "    \"\"\"\n",
        "    Remove whole-word matches (case-insensitive), including hyphenated chunks like 'pine-trees'.\n",
        "    \"\"\"\n",
        "    cleaned = line\n",
        "    for w in sorted(set(words_to_remove), key=len, reverse=True):\n",
        "        cleaned = re.sub(rf\"\\b{re.escape(w)}\\b\", \"\", cleaned, flags=re.IGNORECASE)\n",
        "\n",
        "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
        "    cleaned = re.sub(r\"\\s+([,.;:!?])\", r\"\\1\", cleaned)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "print(\"=== RESULTS ===\\n\")\n",
        "for i, line in enumerate(poem.splitlines(), start=1):\n",
        "    removed = extract_noun_chunks(line)\n",
        "    cleaned_line = remove_words_from_line(line, removed)\n",
        "\n",
        "    print(f\"LINE {i:02d} ORIGINAL: {line}\")\n",
        "    print(f\"REMOVED NOUNS: {removed}\")\n",
        "    print(f\"LINE WITHOUT NOUNS: {cleaned_line}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT2YNBJYRLDw",
        "outputId": "90d7a680-44df-48a4-fc6d-7245270ca6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:28: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:28: SyntaxWarning: invalid escape sequence '\\S'\n",
            "/tmp/ipython-input-1326098717.py:28: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  Return list of (chunk_text, start, end) for each non-space chunk (\\S+).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RESULTS ===\n",
            "\n",
            "LINE 01 ORIGINAL: One must have a mind of winter\n",
            "REMOVED NOUNS: ['mind', 'winter']\n",
            "LINE WITHOUT NOUNS: One must have a of\n",
            "------------------------------------------------------------\n",
            "LINE 02 ORIGINAL: To regard the frost and the boughs\n",
            "REMOVED NOUNS: ['frost', 'boughs']\n",
            "LINE WITHOUT NOUNS: To regard the and the\n",
            "------------------------------------------------------------\n",
            "LINE 03 ORIGINAL: Of the pine-trees crusted with snow;\n",
            "REMOVED NOUNS: ['pine-trees', 'snow']\n",
            "LINE WITHOUT NOUNS: Of the crusted with;\n",
            "------------------------------------------------------------\n",
            "LINE 04 ORIGINAL: And have been cold a long time\n",
            "REMOVED NOUNS: ['time']\n",
            "LINE WITHOUT NOUNS: And have been cold a long\n",
            "------------------------------------------------------------\n",
            "LINE 05 ORIGINAL: To behold the junipers shagged with ice,\n",
            "REMOVED NOUNS: ['junipers', 'ice']\n",
            "LINE WITHOUT NOUNS: To behold the shagged with,\n",
            "------------------------------------------------------------\n",
            "LINE 06 ORIGINAL: The spruces rough in the distant glitter\n",
            "REMOVED NOUNS: ['spruces', 'glitter']\n",
            "LINE WITHOUT NOUNS: The rough in the distant\n",
            "------------------------------------------------------------\n",
            "LINE 07 ORIGINAL: Of the January sun; and not to think\n",
            "REMOVED NOUNS: ['january', 'sun']\n",
            "LINE WITHOUT NOUNS: Of the; and not to think\n",
            "------------------------------------------------------------\n",
            "LINE 08 ORIGINAL: Of any misery in the sound of the wind,\n",
            "REMOVED NOUNS: ['misery', 'sound', 'wind']\n",
            "LINE WITHOUT NOUNS: Of any in the of the,\n",
            "------------------------------------------------------------\n",
            "LINE 09 ORIGINAL: In the sound of a few leaves,\n",
            "REMOVED NOUNS: ['sound', 'leaves']\n",
            "LINE WITHOUT NOUNS: In the of a few,\n",
            "------------------------------------------------------------\n",
            "LINE 10 ORIGINAL: Which is the sound of the land\n",
            "REMOVED NOUNS: ['sound', 'land']\n",
            "LINE WITHOUT NOUNS: Which is the of the\n",
            "------------------------------------------------------------\n",
            "LINE 11 ORIGINAL: Full of the same wind\n",
            "REMOVED NOUNS: ['wind']\n",
            "LINE WITHOUT NOUNS: Full of the same\n",
            "------------------------------------------------------------\n",
            "LINE 12 ORIGINAL: That is blowing in the same bare place\n",
            "REMOVED NOUNS: ['place']\n",
            "LINE WITHOUT NOUNS: That is blowing in the same bare\n",
            "------------------------------------------------------------\n",
            "LINE 13 ORIGINAL: For the listener, who listens in the snow,\n",
            "REMOVED NOUNS: ['listener', 'snow']\n",
            "LINE WITHOUT NOUNS: For the, who listens in the,\n",
            "------------------------------------------------------------\n",
            "LINE 14 ORIGINAL: And, nothing himself, beholds\n",
            "REMOVED NOUNS: ['nothing']\n",
            "LINE WITHOUT NOUNS: And, himself, beholds\n",
            "------------------------------------------------------------\n",
            "LINE 15 ORIGINAL: Nothing that is not there and the nothing that is.\n",
            "REMOVED NOUNS: ['nothing', 'nothing']\n",
            "LINE WITHOUT NOUNS: that is not there and the that is.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e04643454e3d497290e3d0887a74a951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6b28ff7cc8842c0a1e070b08d7ecd3f",
              "IPY_MODEL_aa3c5478df394a3289fbea4fe8c0189f",
              "IPY_MODEL_09c99dea5dcd48eeae50543aa9160bcc"
            ],
            "layout": "IPY_MODEL_cc7af1d7677c47c9bae87a7aedf1adc8"
          }
        },
        "e6b28ff7cc8842c0a1e070b08d7ecd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20fdaa5408a744e8a3c9e6345ec97332",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2368d4b7eb456db0690c7541310758",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "aa3c5478df394a3289fbea4fe8c0189f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6bf5fea15c94ffb93d78df46765a10b",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cefc169674494aaa806af41b8a553451",
            "value": 26
          }
        },
        "09c99dea5dcd48eeae50543aa9160bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e711c2d7b11242b19d42249b7c4eef72",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb2656de2a04e6eae76de67b9f25f60",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.19kB/s]"
          }
        },
        "cc7af1d7677c47c9bae87a7aedf1adc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20fdaa5408a744e8a3c9e6345ec97332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2368d4b7eb456db0690c7541310758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6bf5fea15c94ffb93d78df46765a10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cefc169674494aaa806af41b8a553451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e711c2d7b11242b19d42249b7c4eef72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb2656de2a04e6eae76de67b9f25f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02a851757f644f3ba135c1410fc20d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dca611e2fc774d65adb89208e33b0660",
              "IPY_MODEL_d7baa7ed228648c093cc3f12b83f96de",
              "IPY_MODEL_e452a17450c74c8284c67463fc8d7cd9"
            ],
            "layout": "IPY_MODEL_fbb668e7a2d74231b5f55bac5c271fc5"
          }
        },
        "dca611e2fc774d65adb89208e33b0660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022a1e72beeb4de3815274ca2e91dda6",
            "placeholder": "​",
            "style": "IPY_MODEL_4ca1af44488c420caf9f4715903d8d96",
            "value": "config.json: 100%"
          }
        },
        "d7baa7ed228648c093cc3f12b83f96de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b426fc5f2d244a6280fa7c229a1f4201",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_310464c353984b6fbf64186f0357c155",
            "value": 665
          }
        },
        "e452a17450c74c8284c67463fc8d7cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac641ba770c4135b453822c79ff69e6",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4d892694fd49ffbc0a6187a179ff0a",
            "value": " 665/665 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "fbb668e7a2d74231b5f55bac5c271fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022a1e72beeb4de3815274ca2e91dda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca1af44488c420caf9f4715903d8d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b426fc5f2d244a6280fa7c229a1f4201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310464c353984b6fbf64186f0357c155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ac641ba770c4135b453822c79ff69e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4d892694fd49ffbc0a6187a179ff0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "055537f4172849c0bc02f388a54d800a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85d986f86fef47fd86f304c8fce3e2d4",
              "IPY_MODEL_e9c7de5e78bb45e1a8cecd53fc50da38",
              "IPY_MODEL_2f965dd7c1484556b7a0ab011ba32881"
            ],
            "layout": "IPY_MODEL_123d4b8a29994d20b5e326ae32cb8e44"
          }
        },
        "85d986f86fef47fd86f304c8fce3e2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d53ed760a815425fb4d5cf248a4c0376",
            "placeholder": "​",
            "style": "IPY_MODEL_f2b2f2e4eaf548b0bdc45b021712e281",
            "value": "vocab.json: "
          }
        },
        "e9c7de5e78bb45e1a8cecd53fc50da38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e50b222e5f05443292a4e81957d415c7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_320f289a8c0341148cac77c46b65c28e",
            "value": 1
          }
        },
        "2f965dd7c1484556b7a0ab011ba32881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec676462add4e128cb971b7851f5c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_53e50f7a0a1845e6a2411d097e8b2f17",
            "value": " 1.04M/? [00:00&lt;00:00, 23.4MB/s]"
          }
        },
        "123d4b8a29994d20b5e326ae32cb8e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53ed760a815425fb4d5cf248a4c0376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b2f2e4eaf548b0bdc45b021712e281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e50b222e5f05443292a4e81957d415c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "320f289a8c0341148cac77c46b65c28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec676462add4e128cb971b7851f5c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e50f7a0a1845e6a2411d097e8b2f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73291be41b35489d87c6c93bae4b4970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66faf75a181d46928ce1dbc4d3aa696b",
              "IPY_MODEL_74e683811ff8417192088b2a0415a943",
              "IPY_MODEL_e4254e8969874aee922cfaaf0fe785a5"
            ],
            "layout": "IPY_MODEL_70bd74466a89436bbafb55aae44d7e4e"
          }
        },
        "66faf75a181d46928ce1dbc4d3aa696b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef00927df4743af890f169eb1ceeb90",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc3766ecf174b5c917d2502192a93f7",
            "value": "merges.txt: "
          }
        },
        "74e683811ff8417192088b2a0415a943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e53d1f00fc24b8bbfb12cf5d18f9cc8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ff78fb7e3f44d6e8d1291d6924bd6b2",
            "value": 1
          }
        },
        "e4254e8969874aee922cfaaf0fe785a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf12cdcd39ce433a8b93b92fbcc9c861",
            "placeholder": "​",
            "style": "IPY_MODEL_d4caf0c197f74385860e7b79f1d2c6f9",
            "value": " 456k/? [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "70bd74466a89436bbafb55aae44d7e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef00927df4743af890f169eb1ceeb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc3766ecf174b5c917d2502192a93f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e53d1f00fc24b8bbfb12cf5d18f9cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2ff78fb7e3f44d6e8d1291d6924bd6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf12cdcd39ce433a8b93b92fbcc9c861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4caf0c197f74385860e7b79f1d2c6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e88340bd9aa40fd9341d3ffd7a5e801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c97f978d852491dbcddc444bfed6a9b",
              "IPY_MODEL_edef3532b64246219c7ecd32b45db043",
              "IPY_MODEL_8b2138319fbd417bb101ae2e8410ab42"
            ],
            "layout": "IPY_MODEL_ffb41572e79a465193b8863b0fe66d0e"
          }
        },
        "9c97f978d852491dbcddc444bfed6a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b54d28bc0720415294b81f99814aeec6",
            "placeholder": "​",
            "style": "IPY_MODEL_11381acd7b7f420cba14055c9d115023",
            "value": "tokenizer.json: "
          }
        },
        "edef3532b64246219c7ecd32b45db043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6910f4c1375548bd95b91715817430a9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c628ad53ee974435abda27ecb975e291",
            "value": 1
          }
        },
        "8b2138319fbd417bb101ae2e8410ab42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7c117783074146b57b6f6469b09e2c",
            "placeholder": "​",
            "style": "IPY_MODEL_42aa2fdf92a949ccbc9e83b70b0ae4aa",
            "value": " 1.36M/? [00:00&lt;00:00, 31.4MB/s]"
          }
        },
        "ffb41572e79a465193b8863b0fe66d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54d28bc0720415294b81f99814aeec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11381acd7b7f420cba14055c9d115023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6910f4c1375548bd95b91715817430a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c628ad53ee974435abda27ecb975e291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f7c117783074146b57b6f6469b09e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42aa2fdf92a949ccbc9e83b70b0ae4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "571115dba6f9499d9cc071b6a365c356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de28748ff69c43ff8e22b9b92f2065c2",
              "IPY_MODEL_60d109087c4c49baa6a60467a968573d",
              "IPY_MODEL_25485f5a7d4246a2a2098a1ca2a436c6"
            ],
            "layout": "IPY_MODEL_eea34904cf314742838ab42e06d80aac"
          }
        },
        "de28748ff69c43ff8e22b9b92f2065c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08dd432e5b5c4c408b9dc54ecabc33ab",
            "placeholder": "​",
            "style": "IPY_MODEL_d1410f07342f4d6492acca06b32abeb9",
            "value": "model.safetensors: 100%"
          }
        },
        "60d109087c4c49baa6a60467a968573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b5beff99d942d5af5f290e77522874",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38706ac509a9464391af57cce4427a11",
            "value": 548105171
          }
        },
        "25485f5a7d4246a2a2098a1ca2a436c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2514c7344473487faa59cd3fa110692f",
            "placeholder": "​",
            "style": "IPY_MODEL_50b639ea7f354ba5a9c1847d6c198d41",
            "value": " 548M/548M [00:04&lt;00:00, 133MB/s]"
          }
        },
        "eea34904cf314742838ab42e06d80aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08dd432e5b5c4c408b9dc54ecabc33ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1410f07342f4d6492acca06b32abeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b5beff99d942d5af5f290e77522874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38706ac509a9464391af57cce4427a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2514c7344473487faa59cd3fa110692f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b639ea7f354ba5a9c1847d6c198d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "582c9b16becf44afb42f30db052bea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8673b165b604edcb70659bc33250fbb",
              "IPY_MODEL_00c283dba58b4b0fb654298f4ee26035",
              "IPY_MODEL_5d72e0eb51254387b1c6487b56fa56d1"
            ],
            "layout": "IPY_MODEL_9ce8da935faa4d9aa4be0c3eaca7565a"
          }
        },
        "e8673b165b604edcb70659bc33250fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f8fb1ff35a4cc6adb609dcc6f683b5",
            "placeholder": "​",
            "style": "IPY_MODEL_747f16417f964e9f900db03c09b17482",
            "value": "generation_config.json: 100%"
          }
        },
        "00c283dba58b4b0fb654298f4ee26035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1c73d8e3e6477fb910560367807c90",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa62f1a483d946de81bf8b391722ed76",
            "value": 124
          }
        },
        "5d72e0eb51254387b1c6487b56fa56d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37c155759a0f40de9a83637125397834",
            "placeholder": "​",
            "style": "IPY_MODEL_315e5b485caa462c985bc0be55ce8dd8",
            "value": " 124/124 [00:00&lt;00:00, 9.73kB/s]"
          }
        },
        "9ce8da935faa4d9aa4be0c3eaca7565a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f8fb1ff35a4cc6adb609dcc6f683b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747f16417f964e9f900db03c09b17482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b1c73d8e3e6477fb910560367807c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa62f1a483d946de81bf8b391722ed76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37c155759a0f40de9a83637125397834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315e5b485caa462c985bc0be55ce8dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
